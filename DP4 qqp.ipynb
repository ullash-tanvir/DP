{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be948b88-1b5e-460d-83be-b204abf2912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tislam/.conda/envs/tfgpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tislam/.conda/envs/tfgpu/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer, Trainer, \n",
    "                        TrainingArguments, DataCollatorWithPadding, default_data_collator)\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    PromptTuningConfig,\n",
    "    PrefixTuningConfig,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    TaskType,\n",
    ")\n",
    "from opacus.privacy_engine import GradSampleModule\n",
    "from opacus.optimizers import DPOptimizer\n",
    "from opacus import PrivacyEngine\n",
    "from transformers import DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c3d767-904e-4c99-9087-8c03512ea5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44f61fd-2f3e-401b-aa36-0a00eecdb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "logging.getLogger(\"torch\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86705d8e-5f20-424a-b097-4b4d81416cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the model and tokenizer\n",
    "def setup_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "        print(f\"Using {n_gpu} GPU(s)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        n_gpu = 0\n",
    "        print(\"Using CPU\")\n",
    "    return device, n_gpu\n",
    "\n",
    "def load_model_and_tokenizer(model_name, num_labels):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=num_labels,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to prepare the dataset\n",
    "def prepare_dataset(dataset_name, tokenizer):\n",
    "    # Load the dataset from Hugging Face Datasets\n",
    "    dataset = load_dataset('glue', dataset_name)\n",
    "\n",
    "    # Tokenization function depending on the dataset\n",
    "    def tokenize_function(examples):\n",
    "        if dataset_name.lower() == \"sst2\":\n",
    "            return tokenizer(\n",
    "                examples[\"sentence\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"qqp\":\n",
    "            return tokenizer(\n",
    "                examples[\"question1\"],\n",
    "                examples[\"question2\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"qnli\":\n",
    "            return tokenizer(\n",
    "                examples[\"question\"],\n",
    "                examples[\"sentence\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"mnli\":\n",
    "            return tokenizer(\n",
    "                examples[\"premise\"],\n",
    "                examples[\"hypothesis\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Dataset {dataset_name} is not supported.\")\n",
    "\n",
    "    # Determine which columns to remove\n",
    "    columns_to_remove = set(dataset[\"train\"].column_names) - {\"label\"}\n",
    "\n",
    "    # Apply the tokenization to the dataset\n",
    "    tokenized_datasets = dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=list(columns_to_remove)  # Remove all columns except 'label'\n",
    "    )\n",
    "\n",
    "    # Rename 'label' to 'labels'\n",
    "    tokenized_datasets = tokenized_datasets.map(\n",
    "        lambda examples: {\"labels\": examples[\"label\"]},\n",
    "        remove_columns=[\"label\"]\n",
    "    )\n",
    "\n",
    "    # Convert the datasets to PyTorch tensors\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "    return tokenized_datasets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to compute metrics during evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Get the predictions by taking the argmax over logits\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Compute accuracy by comparing predictions and labels\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    # Return the accuracy inside a dictionary\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Function to get the PEFT configuration based on the method\n",
    "def get_peft_config(method):\n",
    "    if method == \"soft_prompt\":\n",
    "        peft_config = PromptTuningConfig(\n",
    "            task_type=TaskType.SEQ_CLS, num_virtual_tokens=20\n",
    "        )\n",
    "    elif method == \"prefix\":\n",
    "        peft_config = PrefixTuningConfig(\n",
    "            task_type=TaskType.SEQ_CLS, num_virtual_tokens=20\n",
    "        )\n",
    "    elif method == \"lora\":\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "        )\n",
    "    elif method == \"ia3\":\n",
    "        peft_config = IA3Config(task_type=TaskType.SEQ_CLS)\n",
    "    elif method == \"soft_prompt_lora\":\n",
    "        # Combine Prompt Tuning and LoRA\n",
    "        peft_config = [\n",
    "            PromptTuningConfig(task_type=TaskType.SEQ_CLS, num_virtual_tokens=20),\n",
    "            LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "            ),\n",
    "        ]\n",
    "    elif method == \"prefix_lora\":\n",
    "        # Combine Prefix Tuning and LoRA\n",
    "        peft_config = [\n",
    "            PrefixTuningConfig(task_type=TaskType.SEQ_CLS, num_virtual_tokens=20),\n",
    "            LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "            ),\n",
    "        ]\n",
    "    else:\n",
    "        peft_config = None\n",
    "    return peft_config\n",
    "\n",
    "def get_validation_dataset(tokenized_datasets):\n",
    "    # Check for common validation set names and return the first that exists\n",
    "    for val_name in [\"validation\", \"validation_matched\", \"validation_mismatched\"]:\n",
    "        if val_name in tokenized_datasets:\n",
    "            return tokenized_datasets[val_name]\n",
    "    raise ValueError(\"No valid validation set found.\")\n",
    "\n",
    "\n",
    "def create_dp_optimizer(model, learning_rate, epsilon, delta, expected_batch_size):\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    \n",
    "    # Wrap the model with GradSampleModule\n",
    "    model = GradSampleModule(model)\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Make optimizer differentially private\n",
    "    dp_optimizer = DPOptimizer(\n",
    "        optimizer=optimizer,\n",
    "        noise_multiplier=1.3,\n",
    "        max_grad_norm=1.0,\n",
    "        expected_batch_size=expected_batch_size\n",
    "    )\n",
    "\n",
    "    return model, dp_optimizer\n",
    "\n",
    "def compute_dp_noise_scale(epsilon, delta, sample_rate, steps):\n",
    "    \"\"\"Compute noise scale for DP-SGD.\"\"\"\n",
    "    return np.sqrt(2 * np.log(1.25 / delta)) / (epsilon * np.sqrt(steps * sample_rate))\n",
    "\n",
    "def add_noise_to_grads(model, noise_scale, max_grad_norm):\n",
    "    \"\"\"Add noise to gradients for Differential Privacy.\"\"\"\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** 0.5\n",
    "\n",
    "    clip_coef = max_grad_norm / (total_norm + 1e-6)\n",
    "    clip_coef = min(clip_coef, 1.0)  # Clamp without using torch.clamp\n",
    "\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            p.grad.data.mul_(clip_coef)\n",
    "            noise = torch.randn_like(p.grad) * noise_scale * max_grad_norm\n",
    "            p.grad.data.add_(noise)\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_results_to_file(results, epsilon):\n",
    "    filename = \"peft_experiment_results.txt\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Read existing content\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            existing_content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        existing_content = \"\"\n",
    "    \n",
    "    # Prepare new content\n",
    "    new_content = f\"\\n\\n--- Experiment Results ({timestamp}) ---\\n\"\n",
    "    new_content += f\"Epsilon: {epsilon}\\n\" if epsilon is not None else \"No Differential Privacy\\n\"\n",
    "    new_content += json.dumps(results, indent=2)\n",
    "    \n",
    "    # Combine existing and new content\n",
    "    updated_content = existing_content + new_content\n",
    "    \n",
    "    # Write updated content back to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(updated_content)\n",
    "    \n",
    "    print(f\"\\nResults have been appended to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe3d190-183c-49b9-8923-6d18d7cb158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_peft_experiments(dataset, epsilon=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model_name = \"prajjwal1/bert-tiny\"\n",
    "    # datasets = [\"sst2\", \"qnli\", \"qqp\", \"mnli\"]\n",
    "    methods = [\n",
    "        \"soft_prompt\",\n",
    "        \"prefix\",\n",
    "        \"full_fine_tuning\",\n",
    "        \"lora\",\n",
    "        \"ia3\",\n",
    "        \"single_layer_fine_tuning\",\n",
    "        \"soft_prompt_lora\",\n",
    "        \"prefix_lora\",\n",
    "    ]\n",
    "    \n",
    "    # Dataset-specific parameters\n",
    "    dataset_params = {\n",
    "        \"sst2\": {\"lambda\": 1e-5, \"noise_multiplier\": 0.92, \"num_labels\": 2},\n",
    "        \"qnli\": {\"lambda\": 1e-5, \"noise_multiplier\": 0.83, \"num_labels\": 2},\n",
    "        \"qqp\": {\"lambda\": 1e-6, \"noise_multiplier\": 0.66, \"num_labels\": 2},\n",
    "        \"mnli\": {\"lambda\": 1e-6, \"noise_multiplier\": 0.65, \"num_labels\": 3},\n",
    "    }\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    for dataset_name in dataset:\n",
    "        print(f\"Processing dataset: {dataset_name}\")\n",
    "        \n",
    "        params = dataset_params[dataset_name]\n",
    "        num_labels = params[\"num_labels\"]\n",
    "        \n",
    "        model, tokenizer = load_model_and_tokenizer(model_name, num_labels)\n",
    "        tokenized_dataset = prepare_dataset(dataset_name, tokenizer)\n",
    "        \n",
    "        results_dict[dataset_name] = {}\n",
    "        \n",
    "        for method in methods:\n",
    "            print(f\"  Method: {method}\")\n",
    "            model, tokenizer = load_model_and_tokenizer(model_name, num_labels)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            if method == \"full_fine_tuning\":\n",
    "                peft_model = model\n",
    "            elif method == \"single_layer_fine_tuning\":\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "                model.classifier = torch.nn.Linear(model.config.hidden_size, num_labels).to(device)\n",
    "                peft_model = model\n",
    "            else:\n",
    "                peft_config = get_peft_config(method)\n",
    "                if isinstance(peft_config, list):\n",
    "                    peft_model = model\n",
    "                    for config in peft_config:\n",
    "                        peft_model = get_peft_model(peft_model, config)\n",
    "                else:\n",
    "                    peft_model = get_peft_model(model, peft_config)\n",
    "            peft_model = peft_model.to(device)\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=f\"./results/{dataset_name}_{method}\",\n",
    "                num_train_epochs=50,\n",
    "                per_device_train_batch_size=1024,\n",
    "                per_device_eval_batch_size=1024,\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                save_strategy=\"epoch\",\n",
    "                logging_dir=f\"./logs/{dataset_name}_{method}\",\n",
    "                logging_steps=100,\n",
    "                learning_rate=5e-4,\n",
    "                load_best_model_at_end=False,\n",
    "                save_total_limit=1,\n",
    "            )\n",
    "            \n",
    "            train_dataloader = torch.utils.data.DataLoader(\n",
    "                tokenized_dataset[\"train\"],\n",
    "                batch_size=training_args.per_device_train_batch_size,\n",
    "                shuffle=True,\n",
    "                collate_fn=default_data_collator,\n",
    "            )\n",
    "            \n",
    "            eval_dataloader = torch.utils.data.DataLoader(\n",
    "                get_validation_dataset(tokenized_dataset),\n",
    "                batch_size=training_args.per_device_eval_batch_size,\n",
    "                collate_fn=default_data_collator,\n",
    "            )\n",
    "            \n",
    "            if epsilon is not None:\n",
    "                results = train_with_dp(\n",
    "                    peft_model=peft_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    eval_dataloader=eval_dataloader,\n",
    "                    device=device,\n",
    "                    epsilon=epsilon,\n",
    "                    delta=params[\"lambda\"],\n",
    "                    noise_multiplier=params[\"noise_multiplier\"],\n",
    "                    epochs=int(training_args.num_train_epochs),\n",
    "                    batch_size=training_args.per_device_train_batch_size,\n",
    "                    max_grad_norm=1.0,\n",
    "                    learning_rate=training_args.learning_rate,\n",
    "                    weight_decay=1e-2\n",
    "                )\n",
    "            else:\n",
    "                # Train without differential privacy\n",
    "                results = train_without_dp(\n",
    "                    peft_model=peft_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    eval_dataloader=eval_dataloader,\n",
    "                    device=device,\n",
    "                    epochs=int(training_args.num_train_epochs),\n",
    "                    learning_rate=training_args.learning_rate,\n",
    "                    weight_decay=1e-2\n",
    "                )\n",
    "            \n",
    "            results_dict[dataset_name][method] = results\n",
    "            print(f\"    Final Results: {results}\")\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"=\"*50)\n",
    "    for dataset_name in dataset:\n",
    "        print(f\"\\nResults for {dataset_name}:\")\n",
    "        for method, result in results_dict[dataset_name].items():\n",
    "            accuracy = result.get(\"accuracy\", \"N/A\")\n",
    "            loss = result.get(\"eval_loss\", \"N/A\")\n",
    "            print(f\"  Method: {method}, Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    # Save results to file\n",
    "    save_results_to_file(results_dict, epsilon)\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "def train_with_dp(peft_model, train_dataloader, eval_dataloader, device, epsilon, delta, noise_multiplier, epochs, batch_size, max_grad_norm, learning_rate, weight_decay):\n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        peft_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = peft_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(peft_model.parameters(), max_grad_norm)\n",
    "            \n",
    "            # Add noise to gradients\n",
    "            for param in peft_model.parameters():\n",
    "                if param.requires_grad and param.grad is not None:\n",
    "                    noise = torch.randn_like(param.grad) * noise_multiplier * max_grad_norm\n",
    "                    param.grad.add_(noise)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_results = evaluate(peft_model, eval_dataloader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:  Train Loss: {avg_train_loss:.4f}  Eval Loss: {eval_results['eval_loss']:.4f}   Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "\n",
    "        \n",
    "        if eval_results['accuracy'] > best_accuracy:\n",
    "            best_accuracy = eval_results['accuracy']\n",
    "            # print(f\"  New best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    return {\"eval_loss\": eval_results['eval_loss'], \"accuracy\": eval_results['accuracy'], \"best_accuracy\": best_accuracy}\n",
    "\n",
    "def train_without_dp(peft_model, train_dataloader, eval_dataloader, device, epochs, learning_rate, weight_decay):\n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        peft_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = peft_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_results = evaluate(peft_model, eval_dataloader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:   Train Loss: {avg_train_loss:.4f}   Eval Loss: {eval_results['eval_loss']:.4f}   Accuracy: {eval_results['accuracy']:.4f} \")\n",
    "\n",
    "        \n",
    "        if eval_results['accuracy'] > best_accuracy:\n",
    "            best_accuracy = eval_results['accuracy']\n",
    "            # print(f\"  New best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    return {\"eval_loss\": eval_results['eval_loss'], \"accuracy\": eval_results['accuracy'], \"best_accuracy\": best_accuracy}\n",
    "\n",
    "def evaluate(model, eval_dataloader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_steps = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            eval_loss += outputs.loss.item()\n",
    "            eval_steps += 1\n",
    "            all_preds.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "    \n",
    "    eval_loss = eval_loss / eval_steps\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    return {\"eval_loss\": eval_loss, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd36835-b0a4-47ee-ac08-150a0b0b62d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing dataset: qqp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 363846/363846 [00:31<00:00, 11378.39 examples/s]\n",
      "Map: 100%|██████████| 40430/40430 [00:03<00:00, 12162.28 examples/s]\n",
      "Map: 100%|██████████| 390965/390965 [00:30<00:00, 12773.94 examples/s]\n",
      "Map: 100%|██████████| 363846/363846 [00:19<00:00, 18500.37 examples/s]\n",
      "Map: 100%|██████████| 40430/40430 [00:01<00:00, 23133.85 examples/s]\n",
      "Map: 100%|██████████| 390965/390965 [00:20<00:00, 18962.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Method: soft_prompt\n",
      "Epoch 1:  Train Loss: 0.6634  Eval Loss: 0.6557   Accuracy: 0.6318\n",
      "Epoch 2:  Train Loss: 0.6562  Eval Loss: 0.6536   Accuracy: 0.6318\n",
      "Epoch 3:  Train Loss: 0.6556  Eval Loss: 0.6543   Accuracy: 0.6318\n",
      "Epoch 4:  Train Loss: 0.6544  Eval Loss: 0.6510   Accuracy: 0.6318\n",
      "Epoch 5:  Train Loss: 0.6536  Eval Loss: 0.6503   Accuracy: 0.6318\n",
      "Epoch 6:  Train Loss: 0.6543  Eval Loss: 0.6515   Accuracy: 0.6318\n",
      "Epoch 7:  Train Loss: 0.6543  Eval Loss: 0.6509   Accuracy: 0.6318\n",
      "Epoch 8:  Train Loss: 0.6545  Eval Loss: 0.6509   Accuracy: 0.6318\n",
      "Epoch 9:  Train Loss: 0.6549  Eval Loss: 0.6505   Accuracy: 0.6318\n",
      "Epoch 10:  Train Loss: 0.6550  Eval Loss: 0.6501   Accuracy: 0.6318\n",
      "Epoch 11:  Train Loss: 0.6545  Eval Loss: 0.6489   Accuracy: 0.6318\n",
      "Epoch 12:  Train Loss: 0.6544  Eval Loss: 0.6502   Accuracy: 0.6318\n",
      "Epoch 13:  Train Loss: 0.6536  Eval Loss: 0.6505   Accuracy: 0.6318\n",
      "Epoch 14:  Train Loss: 0.6533  Eval Loss: 0.6498   Accuracy: 0.6318\n",
      "Epoch 15:  Train Loss: 0.6536  Eval Loss: 0.6488   Accuracy: 0.6318\n",
      "Epoch 16:  Train Loss: 0.6534  Eval Loss: 0.6473   Accuracy: 0.6318\n",
      "Epoch 17:  Train Loss: 0.6527  Eval Loss: 0.6465   Accuracy: 0.6318\n",
      "Epoch 18:  Train Loss: 0.6524  Eval Loss: 0.6460   Accuracy: 0.6318\n",
      "Epoch 19:  Train Loss: 0.6517  Eval Loss: 0.6445   Accuracy: 0.6318\n",
      "Epoch 20:  Train Loss: 0.6510  Eval Loss: 0.6452   Accuracy: 0.6318\n",
      "Epoch 21:  Train Loss: 0.6503  Eval Loss: 0.6447   Accuracy: 0.6318\n",
      "Epoch 22:  Train Loss: 0.6508  Eval Loss: 0.6421   Accuracy: 0.6318\n",
      "Epoch 23:  Train Loss: 0.6500  Eval Loss: 0.6416   Accuracy: 0.6318\n",
      "Epoch 24:  Train Loss: 0.6496  Eval Loss: 0.6412   Accuracy: 0.6318\n",
      "Epoch 25:  Train Loss: 0.6498  Eval Loss: 0.6411   Accuracy: 0.6318\n",
      "Epoch 26:  Train Loss: 0.6497  Eval Loss: 0.6412   Accuracy: 0.6318\n",
      "Epoch 27:  Train Loss: 0.6496  Eval Loss: 0.6402   Accuracy: 0.6317\n",
      "Epoch 28:  Train Loss: 0.6484  Eval Loss: 0.6400   Accuracy: 0.6317\n",
      "Epoch 29:  Train Loss: 0.6489  Eval Loss: 0.6398   Accuracy: 0.6317\n",
      "Epoch 30:  Train Loss: 0.6491  Eval Loss: 0.6390   Accuracy: 0.6318\n",
      "Epoch 31:  Train Loss: 0.6496  Eval Loss: 0.6393   Accuracy: 0.6318\n",
      "Epoch 32:  Train Loss: 0.6491  Eval Loss: 0.6389   Accuracy: 0.6318\n",
      "Epoch 33:  Train Loss: 0.6491  Eval Loss: 0.6389   Accuracy: 0.6317\n",
      "Epoch 34:  Train Loss: 0.6501  Eval Loss: 0.6390   Accuracy: 0.6318\n",
      "Epoch 35:  Train Loss: 0.6493  Eval Loss: 0.6381   Accuracy: 0.6317\n",
      "Epoch 36:  Train Loss: 0.6485  Eval Loss: 0.6369   Accuracy: 0.6316\n",
      "Epoch 37:  Train Loss: 0.6483  Eval Loss: 0.6375   Accuracy: 0.6316\n",
      "Epoch 38:  Train Loss: 0.6488  Eval Loss: 0.6362   Accuracy: 0.6318\n",
      "Epoch 39:  Train Loss: 0.6486  Eval Loss: 0.6355   Accuracy: 0.6317\n",
      "Epoch 40:  Train Loss: 0.6487  Eval Loss: 0.6356   Accuracy: 0.6319\n",
      "Epoch 41:  Train Loss: 0.6487  Eval Loss: 0.6360   Accuracy: 0.6313\n",
      "Epoch 42:  Train Loss: 0.6488  Eval Loss: 0.6352   Accuracy: 0.6316\n",
      "Epoch 43:  Train Loss: 0.6487  Eval Loss: 0.6364   Accuracy: 0.6314\n",
      "Epoch 44:  Train Loss: 0.6487  Eval Loss: 0.6355   Accuracy: 0.6320\n",
      "Epoch 45:  Train Loss: 0.6491  Eval Loss: 0.6355   Accuracy: 0.6318\n",
      "Epoch 46:  Train Loss: 0.6494  Eval Loss: 0.6358   Accuracy: 0.6316\n",
      "Epoch 47:  Train Loss: 0.6492  Eval Loss: 0.6362   Accuracy: 0.6318\n",
      "Epoch 48:  Train Loss: 0.6495  Eval Loss: 0.6355   Accuracy: 0.6312\n",
      "Epoch 49:  Train Loss: 0.6499  Eval Loss: 0.6349   Accuracy: 0.6314\n",
      "Epoch 50:  Train Loss: 0.6492  Eval Loss: 0.6345   Accuracy: 0.6314\n",
      "    Final Results: {'eval_loss': 0.6345359817147255, 'accuracy': 0.6313875834776156, 'best_accuracy': 0.6320059361860005}\n",
      "  Method: prefix\n",
      "Epoch 1:  Train Loss: 0.6613  Eval Loss: 0.6414   Accuracy: 0.6322\n",
      "Epoch 2:  Train Loss: 0.6403  Eval Loss: 0.6284   Accuracy: 0.6357\n",
      "Epoch 3:  Train Loss: 0.6362  Eval Loss: 0.6273   Accuracy: 0.6368\n",
      "Epoch 4:  Train Loss: 0.6333  Eval Loss: 0.6225   Accuracy: 0.6422\n",
      "Epoch 5:  Train Loss: 0.6317  Eval Loss: 0.6193   Accuracy: 0.6450\n",
      "Epoch 6:  Train Loss: 0.6301  Eval Loss: 0.6182   Accuracy: 0.6472\n",
      "Epoch 7:  Train Loss: 0.6285  Eval Loss: 0.6185   Accuracy: 0.6485\n",
      "Epoch 8:  Train Loss: 0.6280  Eval Loss: 0.6166   Accuracy: 0.6534\n",
      "Epoch 9:  Train Loss: 0.6264  Eval Loss: 0.6115   Accuracy: 0.6513\n",
      "Epoch 10:  Train Loss: 0.6262  Eval Loss: 0.6136   Accuracy: 0.6534\n",
      "Epoch 11:  Train Loss: 0.6256  Eval Loss: 0.6182   Accuracy: 0.6567\n",
      "Epoch 12:  Train Loss: 0.6257  Eval Loss: 0.6140   Accuracy: 0.6577\n",
      "Epoch 13:  Train Loss: 0.6248  Eval Loss: 0.6100   Accuracy: 0.6552\n",
      "Epoch 14:  Train Loss: 0.6251  Eval Loss: 0.6095   Accuracy: 0.6561\n",
      "Epoch 15:  Train Loss: 0.6248  Eval Loss: 0.6082   Accuracy: 0.6571\n",
      "Epoch 16:  Train Loss: 0.6241  Eval Loss: 0.6092   Accuracy: 0.6601\n",
      "Epoch 17:  Train Loss: 0.6244  Eval Loss: 0.6084   Accuracy: 0.6607\n",
      "Epoch 18:  Train Loss: 0.6255  Eval Loss: 0.6077   Accuracy: 0.6619\n",
      "Epoch 19:  Train Loss: 0.6237  Eval Loss: 0.6060   Accuracy: 0.6602\n",
      "Epoch 20:  Train Loss: 0.6247  Eval Loss: 0.6081   Accuracy: 0.6605\n",
      "Epoch 21:  Train Loss: 0.6237  Eval Loss: 0.6087   Accuracy: 0.6602\n",
      "Epoch 22:  Train Loss: 0.6242  Eval Loss: 0.6075   Accuracy: 0.6644\n",
      "Epoch 23:  Train Loss: 0.6234  Eval Loss: 0.6036   Accuracy: 0.6642\n",
      "Epoch 24:  Train Loss: 0.6233  Eval Loss: 0.6050   Accuracy: 0.6648\n",
      "Epoch 25:  Train Loss: 0.6230  Eval Loss: 0.6047   Accuracy: 0.6627\n",
      "Epoch 26:  Train Loss: 0.6237  Eval Loss: 0.6076   Accuracy: 0.6637\n",
      "Epoch 27:  Train Loss: 0.6237  Eval Loss: 0.6058   Accuracy: 0.6674\n",
      "Epoch 28:  Train Loss: 0.6233  Eval Loss: 0.6081   Accuracy: 0.6678\n",
      "Epoch 29:  Train Loss: 0.6241  Eval Loss: 0.6064   Accuracy: 0.6664\n",
      "Epoch 30:  Train Loss: 0.6245  Eval Loss: 0.6070   Accuracy: 0.6646\n",
      "Epoch 31:  Train Loss: 0.6240  Eval Loss: 0.6030   Accuracy: 0.6656\n",
      "Epoch 32:  Train Loss: 0.6248  Eval Loss: 0.6052   Accuracy: 0.6664\n",
      "Epoch 33:  Train Loss: 0.6237  Eval Loss: 0.6029   Accuracy: 0.6656\n",
      "Epoch 34:  Train Loss: 0.6230  Eval Loss: 0.6043   Accuracy: 0.6665\n",
      "Epoch 35:  Train Loss: 0.6239  Eval Loss: 0.6083   Accuracy: 0.6667\n",
      "Epoch 36:  Train Loss: 0.6236  Eval Loss: 0.6034   Accuracy: 0.6665\n",
      "Epoch 37:  Train Loss: 0.6229  Eval Loss: 0.6028   Accuracy: 0.6687\n",
      "Epoch 38:  Train Loss: 0.6232  Eval Loss: 0.6022   Accuracy: 0.6699\n",
      "Epoch 39:  Train Loss: 0.6229  Eval Loss: 0.6031   Accuracy: 0.6704\n",
      "Epoch 40:  Train Loss: 0.6229  Eval Loss: 0.6013   Accuracy: 0.6695\n",
      "Epoch 41:  Train Loss: 0.6230  Eval Loss: 0.6028   Accuracy: 0.6693\n",
      "Epoch 42:  Train Loss: 0.6229  Eval Loss: 0.6018   Accuracy: 0.6660\n",
      "Epoch 43:  Train Loss: 0.6227  Eval Loss: 0.6021   Accuracy: 0.6683\n",
      "Epoch 44:  Train Loss: 0.6229  Eval Loss: 0.5994   Accuracy: 0.6686\n",
      "Epoch 45:  Train Loss: 0.6226  Eval Loss: 0.6004   Accuracy: 0.6696\n",
      "Epoch 46:  Train Loss: 0.6240  Eval Loss: 0.6035   Accuracy: 0.6683\n",
      "Epoch 47:  Train Loss: 0.6227  Eval Loss: 0.5980   Accuracy: 0.6701\n",
      "Epoch 48:  Train Loss: 0.6224  Eval Loss: 0.5993   Accuracy: 0.6711\n",
      "Epoch 49:  Train Loss: 0.6224  Eval Loss: 0.5978   Accuracy: 0.6701\n",
      "Epoch 50:  Train Loss: 0.6222  Eval Loss: 0.5973   Accuracy: 0.6717\n",
      "    Final Results: {'eval_loss': 0.5972602620720864, 'accuracy': 0.6716547118476379, 'best_accuracy': 0.6716547118476379}\n",
      "  Method: full_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.6503  Eval Loss: 0.6182   Accuracy: 0.6372\n",
      "Epoch 2:  Train Loss: 0.6142  Eval Loss: 0.5985   Accuracy: 0.6672\n",
      "Epoch 3:  Train Loss: 0.5948  Eval Loss: 0.5813   Accuracy: 0.6739\n",
      "Epoch 4:  Train Loss: 0.5838  Eval Loss: 0.5716   Accuracy: 0.6755\n",
      "Epoch 5:  Train Loss: 0.5821  Eval Loss: 0.5671   Accuracy: 0.6839\n",
      "Epoch 6:  Train Loss: 0.5817  Eval Loss: 0.5713   Accuracy: 0.6789\n",
      "Epoch 7:  Train Loss: 0.5805  Eval Loss: 0.5707   Accuracy: 0.6760\n",
      "Epoch 8:  Train Loss: 0.5815  Eval Loss: 0.5740   Accuracy: 0.6748\n",
      "Epoch 9:  Train Loss: 0.5816  Eval Loss: 0.5735   Accuracy: 0.6755\n",
      "Epoch 10:  Train Loss: 0.5826  Eval Loss: 0.5675   Accuracy: 0.6800\n",
      "Epoch 11:  Train Loss: 0.5830  Eval Loss: 0.5736   Accuracy: 0.6779\n",
      "Epoch 12:  Train Loss: 0.5835  Eval Loss: 0.5702   Accuracy: 0.6866\n",
      "Epoch 13:  Train Loss: 0.5837  Eval Loss: 0.5696   Accuracy: 0.6831\n",
      "Epoch 14:  Train Loss: 0.5856  Eval Loss: 0.5652   Accuracy: 0.6895\n",
      "Epoch 15:  Train Loss: 0.5855  Eval Loss: 0.5637   Accuracy: 0.6908\n",
      "Epoch 16:  Train Loss: 0.5853  Eval Loss: 0.5629   Accuracy: 0.6954\n",
      "Epoch 17:  Train Loss: 0.5880  Eval Loss: 0.5669   Accuracy: 0.6891\n",
      "Epoch 18:  Train Loss: 0.5916  Eval Loss: 0.5773   Accuracy: 0.6827\n",
      "Epoch 19:  Train Loss: 0.5940  Eval Loss: 0.5799   Accuracy: 0.6760\n",
      "Epoch 20:  Train Loss: 0.5963  Eval Loss: 0.5748   Accuracy: 0.6864\n",
      "Epoch 21:  Train Loss: 0.5965  Eval Loss: 0.5758   Accuracy: 0.6856\n",
      "Epoch 22:  Train Loss: 0.5973  Eval Loss: 0.5779   Accuracy: 0.6838\n",
      "Epoch 23:  Train Loss: 0.5973  Eval Loss: 0.5768   Accuracy: 0.6828\n",
      "Epoch 24:  Train Loss: 0.5980  Eval Loss: 0.5739   Accuracy: 0.6863\n",
      "Epoch 25:  Train Loss: 0.5994  Eval Loss: 0.5766   Accuracy: 0.6845\n",
      "Epoch 26:  Train Loss: 0.6001  Eval Loss: 0.5807   Accuracy: 0.6798\n",
      "Epoch 27:  Train Loss: 0.6024  Eval Loss: 0.5853   Accuracy: 0.6745\n",
      "Epoch 28:  Train Loss: 0.6036  Eval Loss: 0.5836   Accuracy: 0.6781\n",
      "Epoch 29:  Train Loss: 0.6063  Eval Loss: 0.5880   Accuracy: 0.6744\n",
      "Epoch 30:  Train Loss: 0.6087  Eval Loss: 0.5867   Accuracy: 0.6754\n",
      "Epoch 31:  Train Loss: 0.6089  Eval Loss: 0.5893   Accuracy: 0.6758\n",
      "Epoch 32:  Train Loss: 0.6097  Eval Loss: 0.5910   Accuracy: 0.6759\n",
      "Epoch 33:  Train Loss: 0.6106  Eval Loss: 0.5914   Accuracy: 0.6755\n",
      "Epoch 34:  Train Loss: 0.6127  Eval Loss: 0.5912   Accuracy: 0.6739\n",
      "Epoch 35:  Train Loss: 0.6134  Eval Loss: 0.5917   Accuracy: 0.6752\n",
      "Epoch 36:  Train Loss: 0.6139  Eval Loss: 0.5945   Accuracy: 0.6706\n",
      "Epoch 37:  Train Loss: 0.6153  Eval Loss: 0.5943   Accuracy: 0.6742\n",
      "Epoch 38:  Train Loss: 0.6162  Eval Loss: 0.5982   Accuracy: 0.6698\n",
      "Epoch 39:  Train Loss: 0.6195  Eval Loss: 0.5961   Accuracy: 0.6729\n",
      "Epoch 40:  Train Loss: 0.6186  Eval Loss: 0.5985   Accuracy: 0.6691\n",
      "Epoch 41:  Train Loss: 0.6200  Eval Loss: 0.5980   Accuracy: 0.6702\n",
      "Epoch 42:  Train Loss: 0.6210  Eval Loss: 0.5986   Accuracy: 0.6711\n",
      "Epoch 43:  Train Loss: 0.6205  Eval Loss: 0.5990   Accuracy: 0.6726\n",
      "Epoch 44:  Train Loss: 0.6208  Eval Loss: 0.5994   Accuracy: 0.6712\n",
      "Epoch 45:  Train Loss: 0.6227  Eval Loss: 0.5993   Accuracy: 0.6705\n",
      "Epoch 46:  Train Loss: 0.6230  Eval Loss: 0.6001   Accuracy: 0.6708\n",
      "Epoch 47:  Train Loss: 0.6239  Eval Loss: 0.6009   Accuracy: 0.6691\n",
      "Epoch 48:  Train Loss: 0.6233  Eval Loss: 0.6023   Accuracy: 0.6676\n",
      "Epoch 49:  Train Loss: 0.6235  Eval Loss: 0.6017   Accuracy: 0.6690\n",
      "Epoch 50:  Train Loss: 0.6237  Eval Loss: 0.6022   Accuracy: 0.6682\n",
      "    Final Results: {'eval_loss': 0.6021672993898392, 'accuracy': 0.668216670789018, 'best_accuracy': 0.6953747217412812}\n",
      "  Method: lora\n",
      "Epoch 1:  Train Loss: 0.6538  Eval Loss: 0.6311   Accuracy: 0.6319\n",
      "Epoch 2:  Train Loss: 0.6283  Eval Loss: 0.6144   Accuracy: 0.6498\n",
      "Epoch 3:  Train Loss: 0.6180  Eval Loss: 0.6087   Accuracy: 0.6562\n",
      "Epoch 4:  Train Loss: 0.6139  Eval Loss: 0.6060   Accuracy: 0.6606\n",
      "Epoch 5:  Train Loss: 0.6116  Eval Loss: 0.6034   Accuracy: 0.6594\n",
      "Epoch 6:  Train Loss: 0.6068  Eval Loss: 0.5947   Accuracy: 0.6671\n",
      "Epoch 7:  Train Loss: 0.6027  Eval Loss: 0.5903   Accuracy: 0.6689\n",
      "Epoch 8:  Train Loss: 0.6015  Eval Loss: 0.5924   Accuracy: 0.6693\n",
      "Epoch 9:  Train Loss: 0.5997  Eval Loss: 0.5885   Accuracy: 0.6743\n",
      "Epoch 10:  Train Loss: 0.5990  Eval Loss: 0.5879   Accuracy: 0.6736\n",
      "Epoch 11:  Train Loss: 0.5969  Eval Loss: 0.5858   Accuracy: 0.6738\n",
      "Epoch 12:  Train Loss: 0.5966  Eval Loss: 0.5857   Accuracy: 0.6732\n",
      "Epoch 13:  Train Loss: 0.5947  Eval Loss: 0.5847   Accuracy: 0.6754\n",
      "Epoch 14:  Train Loss: 0.5926  Eval Loss: 0.5796   Accuracy: 0.6808\n",
      "Epoch 15:  Train Loss: 0.5908  Eval Loss: 0.5792   Accuracy: 0.6766\n",
      "Epoch 16:  Train Loss: 0.5894  Eval Loss: 0.5770   Accuracy: 0.6811\n",
      "Epoch 17:  Train Loss: 0.5880  Eval Loss: 0.5752   Accuracy: 0.6875\n",
      "Epoch 18:  Train Loss: 0.5865  Eval Loss: 0.5727   Accuracy: 0.6839\n",
      "Epoch 19:  Train Loss: 0.5859  Eval Loss: 0.5734   Accuracy: 0.6829\n",
      "Epoch 20:  Train Loss: 0.5851  Eval Loss: 0.5768   Accuracy: 0.6772\n",
      "Epoch 21:  Train Loss: 0.5831  Eval Loss: 0.5707   Accuracy: 0.6856\n",
      "Epoch 22:  Train Loss: 0.5817  Eval Loss: 0.5709   Accuracy: 0.6838\n",
      "Epoch 23:  Train Loss: 0.5813  Eval Loss: 0.5745   Accuracy: 0.6815\n",
      "Epoch 24:  Train Loss: 0.5817  Eval Loss: 0.5679   Accuracy: 0.6886\n",
      "Epoch 25:  Train Loss: 0.5805  Eval Loss: 0.5710   Accuracy: 0.6853\n",
      "Epoch 26:  Train Loss: 0.5795  Eval Loss: 0.5640   Accuracy: 0.6898\n",
      "Epoch 27:  Train Loss: 0.5783  Eval Loss: 0.5662   Accuracy: 0.6899\n",
      "Epoch 28:  Train Loss: 0.5768  Eval Loss: 0.5660   Accuracy: 0.6876\n",
      "Epoch 29:  Train Loss: 0.5746  Eval Loss: 0.5668   Accuracy: 0.6861\n",
      "Epoch 30:  Train Loss: 0.5730  Eval Loss: 0.5591   Accuracy: 0.6915\n",
      "Epoch 31:  Train Loss: 0.5724  Eval Loss: 0.5591   Accuracy: 0.6929\n",
      "Epoch 32:  Train Loss: 0.5707  Eval Loss: 0.5560   Accuracy: 0.6968\n",
      "Epoch 33:  Train Loss: 0.5693  Eval Loss: 0.5550   Accuracy: 0.6989\n",
      "Epoch 34:  Train Loss: 0.5676  Eval Loss: 0.5590   Accuracy: 0.6913\n",
      "Epoch 35:  Train Loss: 0.5659  Eval Loss: 0.5578   Accuracy: 0.6903\n",
      "Epoch 36:  Train Loss: 0.5665  Eval Loss: 0.5502   Accuracy: 0.6988\n",
      "Epoch 37:  Train Loss: 0.5655  Eval Loss: 0.5616   Accuracy: 0.6867\n",
      "Epoch 38:  Train Loss: 0.5647  Eval Loss: 0.5499   Accuracy: 0.6957\n",
      "Epoch 39:  Train Loss: 0.5645  Eval Loss: 0.5542   Accuracy: 0.6898\n",
      "Epoch 40:  Train Loss: 0.5632  Eval Loss: 0.5536   Accuracy: 0.6915\n",
      "Epoch 41:  Train Loss: 0.5631  Eval Loss: 0.5516   Accuracy: 0.6925\n",
      "Epoch 42:  Train Loss: 0.5630  Eval Loss: 0.5487   Accuracy: 0.6967\n",
      "Epoch 43:  Train Loss: 0.5617  Eval Loss: 0.5470   Accuracy: 0.6982\n",
      "Epoch 44:  Train Loss: 0.5620  Eval Loss: 0.5483   Accuracy: 0.6974\n",
      "Epoch 45:  Train Loss: 0.5619  Eval Loss: 0.5546   Accuracy: 0.6925\n",
      "Epoch 46:  Train Loss: 0.5617  Eval Loss: 0.5495   Accuracy: 0.6953\n",
      "Epoch 47:  Train Loss: 0.5614  Eval Loss: 0.5496   Accuracy: 0.6969\n",
      "Epoch 48:  Train Loss: 0.5599  Eval Loss: 0.5494   Accuracy: 0.6942\n",
      "Epoch 49:  Train Loss: 0.5601  Eval Loss: 0.5464   Accuracy: 0.6954\n",
      "Epoch 50:  Train Loss: 0.5588  Eval Loss: 0.5450   Accuracy: 0.6989\n",
      "    Final Results: {'eval_loss': 0.5449863955378532, 'accuracy': 0.6989116992332426, 'best_accuracy': 0.6989116992332426}\n",
      "  Method: ia3\n",
      "Epoch 1:  Train Loss: 0.6502  Eval Loss: 0.6346   Accuracy: 0.6319\n",
      "Epoch 2:  Train Loss: 0.6303  Eval Loss: 0.6193   Accuracy: 0.6399\n",
      "Epoch 3:  Train Loss: 0.6200  Eval Loss: 0.6087   Accuracy: 0.6510\n",
      "Epoch 4:  Train Loss: 0.6142  Eval Loss: 0.6055   Accuracy: 0.6554\n",
      "Epoch 5:  Train Loss: 0.6112  Eval Loss: 0.5981   Accuracy: 0.6585\n",
      "Epoch 6:  Train Loss: 0.6075  Eval Loss: 0.5968   Accuracy: 0.6635\n",
      "Epoch 7:  Train Loss: 0.6060  Eval Loss: 0.5958   Accuracy: 0.6687\n",
      "Epoch 8:  Train Loss: 0.6040  Eval Loss: 0.5932   Accuracy: 0.6678\n",
      "Epoch 9:  Train Loss: 0.6031  Eval Loss: 0.5908   Accuracy: 0.6694\n",
      "Epoch 10:  Train Loss: 0.6025  Eval Loss: 0.5907   Accuracy: 0.6718\n",
      "Epoch 11:  Train Loss: 0.6017  Eval Loss: 0.5907   Accuracy: 0.6720\n",
      "Epoch 12:  Train Loss: 0.6000  Eval Loss: 0.5871   Accuracy: 0.6745\n",
      "Epoch 13:  Train Loss: 0.5997  Eval Loss: 0.5883   Accuracy: 0.6789\n",
      "Epoch 14:  Train Loss: 0.5981  Eval Loss: 0.5861   Accuracy: 0.6795\n",
      "Epoch 15:  Train Loss: 0.5962  Eval Loss: 0.5864   Accuracy: 0.6817\n",
      "Epoch 16:  Train Loss: 0.5953  Eval Loss: 0.5848   Accuracy: 0.6840\n",
      "Epoch 17:  Train Loss: 0.5957  Eval Loss: 0.5796   Accuracy: 0.6814\n",
      "Epoch 18:  Train Loss: 0.5949  Eval Loss: 0.5805   Accuracy: 0.6847\n",
      "Epoch 19:  Train Loss: 0.5941  Eval Loss: 0.5810   Accuracy: 0.6807\n",
      "Epoch 20:  Train Loss: 0.5932  Eval Loss: 0.5807   Accuracy: 0.6812\n",
      "Epoch 21:  Train Loss: 0.5940  Eval Loss: 0.5778   Accuracy: 0.6858\n",
      "Epoch 22:  Train Loss: 0.5930  Eval Loss: 0.5747   Accuracy: 0.6847\n",
      "Epoch 23:  Train Loss: 0.5928  Eval Loss: 0.5804   Accuracy: 0.6828\n",
      "Epoch 24:  Train Loss: 0.5924  Eval Loss: 0.5748   Accuracy: 0.6864\n",
      "Epoch 25:  Train Loss: 0.5917  Eval Loss: 0.5748   Accuracy: 0.6876\n",
      "Epoch 26:  Train Loss: 0.5908  Eval Loss: 0.5751   Accuracy: 0.6899\n",
      "Epoch 27:  Train Loss: 0.5899  Eval Loss: 0.5726   Accuracy: 0.6905\n",
      "Epoch 28:  Train Loss: 0.5899  Eval Loss: 0.5756   Accuracy: 0.6897\n",
      "Epoch 29:  Train Loss: 0.5901  Eval Loss: 0.5760   Accuracy: 0.6897\n",
      "Epoch 30:  Train Loss: 0.5891  Eval Loss: 0.5717   Accuracy: 0.6946\n",
      "Epoch 31:  Train Loss: 0.5886  Eval Loss: 0.5759   Accuracy: 0.6932\n",
      "Epoch 32:  Train Loss: 0.5888  Eval Loss: 0.5736   Accuracy: 0.6935\n",
      "Epoch 33:  Train Loss: 0.5877  Eval Loss: 0.5732   Accuracy: 0.6943\n",
      "Epoch 34:  Train Loss: 0.5875  Eval Loss: 0.5718   Accuracy: 0.6950\n",
      "Epoch 35:  Train Loss: 0.5868  Eval Loss: 0.5717   Accuracy: 0.6943\n",
      "Epoch 36:  Train Loss: 0.5878  Eval Loss: 0.5724   Accuracy: 0.6924\n",
      "Epoch 37:  Train Loss: 0.5879  Eval Loss: 0.5715   Accuracy: 0.6939\n",
      "Epoch 38:  Train Loss: 0.5883  Eval Loss: 0.5765   Accuracy: 0.6927\n",
      "Epoch 39:  Train Loss: 0.5879  Eval Loss: 0.5693   Accuracy: 0.6969\n",
      "Epoch 40:  Train Loss: 0.5870  Eval Loss: 0.5705   Accuracy: 0.6961\n",
      "Epoch 41:  Train Loss: 0.5876  Eval Loss: 0.5721   Accuracy: 0.6939\n",
      "Epoch 42:  Train Loss: 0.5872  Eval Loss: 0.5706   Accuracy: 0.6972\n",
      "Epoch 43:  Train Loss: 0.5872  Eval Loss: 0.5712   Accuracy: 0.6963\n",
      "Epoch 44:  Train Loss: 0.5878  Eval Loss: 0.5721   Accuracy: 0.6969\n",
      "Epoch 45:  Train Loss: 0.5870  Eval Loss: 0.5726   Accuracy: 0.6950\n",
      "Epoch 46:  Train Loss: 0.5864  Eval Loss: 0.5713   Accuracy: 0.6948\n",
      "Epoch 47:  Train Loss: 0.5865  Eval Loss: 0.5721   Accuracy: 0.6922\n",
      "Epoch 48:  Train Loss: 0.5867  Eval Loss: 0.5712   Accuracy: 0.6955\n",
      "Epoch 49:  Train Loss: 0.5864  Eval Loss: 0.5674   Accuracy: 0.6981\n",
      "Epoch 50:  Train Loss: 0.5848  Eval Loss: 0.5670   Accuracy: 0.6977\n",
      "    Final Results: {'eval_loss': 0.5670197382569313, 'accuracy': 0.6977244620331438, 'best_accuracy': 0.6980707395498392}\n",
      "  Method: single_layer_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.6564  Eval Loss: 0.6275   Accuracy: 0.6353\n",
      "Epoch 2:  Train Loss: 0.6337  Eval Loss: 0.6153   Accuracy: 0.6399\n",
      "Epoch 3:  Train Loss: 0.6277  Eval Loss: 0.6137   Accuracy: 0.6356\n",
      "Epoch 4:  Train Loss: 0.6241  Eval Loss: 0.6096   Accuracy: 0.6419\n",
      "Epoch 5:  Train Loss: 0.6187  Eval Loss: 0.6013   Accuracy: 0.6542\n",
      "Epoch 6:  Train Loss: 0.6156  Eval Loss: 0.5994   Accuracy: 0.6570\n",
      "Epoch 7:  Train Loss: 0.6152  Eval Loss: 0.5986   Accuracy: 0.6565\n",
      "Epoch 8:  Train Loss: 0.6118  Eval Loss: 0.5987   Accuracy: 0.6571\n",
      "Epoch 9:  Train Loss: 0.6112  Eval Loss: 0.5966   Accuracy: 0.6594\n",
      "Epoch 10:  Train Loss: 0.6098  Eval Loss: 0.5999   Accuracy: 0.6551\n",
      "Epoch 11:  Train Loss: 0.6093  Eval Loss: 0.5936   Accuracy: 0.6634\n",
      "Epoch 12:  Train Loss: 0.6071  Eval Loss: 0.5898   Accuracy: 0.6691\n",
      "Epoch 13:  Train Loss: 0.6063  Eval Loss: 0.5889   Accuracy: 0.6705\n",
      "Epoch 14:  Train Loss: 0.6050  Eval Loss: 0.5869   Accuracy: 0.6727\n",
      "Epoch 15:  Train Loss: 0.6034  Eval Loss: 0.5858   Accuracy: 0.6757\n",
      "Epoch 16:  Train Loss: 0.6031  Eval Loss: 0.5861   Accuracy: 0.6768\n",
      "Epoch 17:  Train Loss: 0.6018  Eval Loss: 0.5830   Accuracy: 0.6764\n",
      "Epoch 18:  Train Loss: 0.6018  Eval Loss: 0.5845   Accuracy: 0.6771\n",
      "Epoch 19:  Train Loss: 0.6008  Eval Loss: 0.5842   Accuracy: 0.6750\n",
      "Epoch 20:  Train Loss: 0.6006  Eval Loss: 0.5852   Accuracy: 0.6752\n",
      "Epoch 21:  Train Loss: 0.6002  Eval Loss: 0.5850   Accuracy: 0.6759\n",
      "Epoch 22:  Train Loss: 0.6000  Eval Loss: 0.5834   Accuracy: 0.6752\n",
      "Epoch 23:  Train Loss: 0.6007  Eval Loss: 0.5804   Accuracy: 0.6770\n",
      "Epoch 24:  Train Loss: 0.5997  Eval Loss: 0.5826   Accuracy: 0.6762\n",
      "Epoch 25:  Train Loss: 0.5997  Eval Loss: 0.5828   Accuracy: 0.6791\n",
      "Epoch 26:  Train Loss: 0.5988  Eval Loss: 0.5800   Accuracy: 0.6788\n",
      "Epoch 27:  Train Loss: 0.5991  Eval Loss: 0.5797   Accuracy: 0.6786\n",
      "Epoch 28:  Train Loss: 0.5993  Eval Loss: 0.5798   Accuracy: 0.6796\n",
      "Epoch 29:  Train Loss: 0.5987  Eval Loss: 0.5809   Accuracy: 0.6797\n",
      "Epoch 30:  Train Loss: 0.5986  Eval Loss: 0.5818   Accuracy: 0.6764\n",
      "Epoch 31:  Train Loss: 0.5992  Eval Loss: 0.5799   Accuracy: 0.6777\n",
      "Epoch 32:  Train Loss: 0.5993  Eval Loss: 0.5788   Accuracy: 0.6791\n",
      "Epoch 33:  Train Loss: 0.5978  Eval Loss: 0.5813   Accuracy: 0.6779\n",
      "Epoch 34:  Train Loss: 0.5974  Eval Loss: 0.5782   Accuracy: 0.6805\n",
      "Epoch 35:  Train Loss: 0.5969  Eval Loss: 0.5768   Accuracy: 0.6826\n",
      "Epoch 36:  Train Loss: 0.5974  Eval Loss: 0.5769   Accuracy: 0.6811\n",
      "Epoch 37:  Train Loss: 0.5973  Eval Loss: 0.5767   Accuracy: 0.6805\n",
      "Epoch 38:  Train Loss: 0.5983  Eval Loss: 0.5773   Accuracy: 0.6802\n",
      "Epoch 39:  Train Loss: 0.5980  Eval Loss: 0.5761   Accuracy: 0.6820\n",
      "Epoch 40:  Train Loss: 0.5966  Eval Loss: 0.5789   Accuracy: 0.6815\n",
      "Epoch 41:  Train Loss: 0.5973  Eval Loss: 0.5766   Accuracy: 0.6812\n",
      "Epoch 42:  Train Loss: 0.5980  Eval Loss: 0.5791   Accuracy: 0.6805\n",
      "Epoch 43:  Train Loss: 0.5972  Eval Loss: 0.5777   Accuracy: 0.6831\n",
      "Epoch 44:  Train Loss: 0.5967  Eval Loss: 0.5776   Accuracy: 0.6800\n",
      "Epoch 45:  Train Loss: 0.5959  Eval Loss: 0.5770   Accuracy: 0.6815\n",
      "Epoch 46:  Train Loss: 0.5950  Eval Loss: 0.5776   Accuracy: 0.6837\n",
      "Epoch 47:  Train Loss: 0.5953  Eval Loss: 0.5763   Accuracy: 0.6845\n",
      "Epoch 48:  Train Loss: 0.5948  Eval Loss: 0.5744   Accuracy: 0.6862\n",
      "Epoch 49:  Train Loss: 0.5946  Eval Loss: 0.5750   Accuracy: 0.6875\n",
      "Epoch 50:  Train Loss: 0.5939  Eval Loss: 0.5778   Accuracy: 0.6850\n",
      "    Final Results: {'eval_loss': 0.5778334259986877, 'accuracy': 0.6849863962404156, 'best_accuracy': 0.6875092752906258}\n",
      "  Method: soft_prompt_lora\n",
      "Epoch 1:  Train Loss: 0.6901  Eval Loss: 0.6858   Accuracy: 0.6025\n",
      "Epoch 2:  Train Loss: 0.6901  Eval Loss: 0.6860   Accuracy: 0.6016\n",
      "Epoch 3:  Train Loss: 0.6898  Eval Loss: 0.6854   Accuracy: 0.6065\n",
      "Epoch 4:  Train Loss: 0.6890  Eval Loss: 0.6847   Accuracy: 0.6129\n",
      "Epoch 5:  Train Loss: 0.6889  Eval Loss: 0.6849   Accuracy: 0.6117\n",
      "Epoch 6:  Train Loss: 0.6888  Eval Loss: 0.6841   Accuracy: 0.6163\n",
      "Epoch 7:  Train Loss: 0.6883  Eval Loss: 0.6838   Accuracy: 0.6168\n",
      "Epoch 8:  Train Loss: 0.6877  Eval Loss: 0.6833   Accuracy: 0.6184\n",
      "Epoch 9:  Train Loss: 0.6873  Eval Loss: 0.6825   Accuracy: 0.6228\n",
      "Epoch 10:  Train Loss: 0.6868  Eval Loss: 0.6822   Accuracy: 0.6245\n",
      "Epoch 11:  Train Loss: 0.6863  Eval Loss: 0.6818   Accuracy: 0.6271\n",
      "Epoch 12:  Train Loss: 0.6856  Eval Loss: 0.6812   Accuracy: 0.6295\n",
      "Epoch 13:  Train Loss: 0.6845  Eval Loss: 0.6789   Accuracy: 0.6324\n",
      "Epoch 14:  Train Loss: 0.6834  Eval Loss: 0.6778   Accuracy: 0.6318\n",
      "Epoch 15:  Train Loss: 0.6827  Eval Loss: 0.6779   Accuracy: 0.6318\n",
      "Epoch 16:  Train Loss: 0.6821  Eval Loss: 0.6766   Accuracy: 0.6318\n",
      "Epoch 17:  Train Loss: 0.6809  Eval Loss: 0.6754   Accuracy: 0.6317\n",
      "Epoch 18:  Train Loss: 0.6796  Eval Loss: 0.6736   Accuracy: 0.6318\n",
      "Epoch 19:  Train Loss: 0.6783  Eval Loss: 0.6728   Accuracy: 0.6318\n",
      "Epoch 20:  Train Loss: 0.6779  Eval Loss: 0.6725   Accuracy: 0.6318\n",
      "Epoch 21:  Train Loss: 0.6769  Eval Loss: 0.6708   Accuracy: 0.6318\n",
      "Epoch 22:  Train Loss: 0.6758  Eval Loss: 0.6702   Accuracy: 0.6318\n",
      "Epoch 23:  Train Loss: 0.6747  Eval Loss: 0.6689   Accuracy: 0.6318\n",
      "Epoch 24:  Train Loss: 0.6734  Eval Loss: 0.6679   Accuracy: 0.6318\n",
      "Epoch 25:  Train Loss: 0.6726  Eval Loss: 0.6676   Accuracy: 0.6318\n",
      "Epoch 26:  Train Loss: 0.6722  Eval Loss: 0.6669   Accuracy: 0.6318\n",
      "Epoch 27:  Train Loss: 0.6715  Eval Loss: 0.6659   Accuracy: 0.6318\n",
      "Epoch 28:  Train Loss: 0.6705  Eval Loss: 0.6654   Accuracy: 0.6318\n",
      "Epoch 29:  Train Loss: 0.6699  Eval Loss: 0.6644   Accuracy: 0.6318\n",
      "Epoch 30:  Train Loss: 0.6692  Eval Loss: 0.6638   Accuracy: 0.6318\n",
      "Epoch 31:  Train Loss: 0.6684  Eval Loss: 0.6635   Accuracy: 0.6318\n",
      "Epoch 32:  Train Loss: 0.6684  Eval Loss: 0.6636   Accuracy: 0.6318\n",
      "Epoch 33:  Train Loss: 0.6683  Eval Loss: 0.6636   Accuracy: 0.6318\n",
      "Epoch 34:  Train Loss: 0.6679  Eval Loss: 0.6633   Accuracy: 0.6318\n",
      "Epoch 35:  Train Loss: 0.6678  Eval Loss: 0.6633   Accuracy: 0.6318\n",
      "Epoch 36:  Train Loss: 0.6672  Eval Loss: 0.6624   Accuracy: 0.6318\n",
      "Epoch 37:  Train Loss: 0.6670  Eval Loss: 0.6620   Accuracy: 0.6318\n",
      "Epoch 38:  Train Loss: 0.6663  Eval Loss: 0.6608   Accuracy: 0.6318\n",
      "Epoch 39:  Train Loss: 0.6654  Eval Loss: 0.6604   Accuracy: 0.6318\n",
      "Epoch 40:  Train Loss: 0.6650  Eval Loss: 0.6605   Accuracy: 0.6318\n",
      "Epoch 41:  Train Loss: 0.6650  Eval Loss: 0.6601   Accuracy: 0.6318\n",
      "Epoch 42:  Train Loss: 0.6647  Eval Loss: 0.6596   Accuracy: 0.6318\n",
      "Epoch 43:  Train Loss: 0.6642  Eval Loss: 0.6593   Accuracy: 0.6318\n",
      "Epoch 44:  Train Loss: 0.6635  Eval Loss: 0.6587   Accuracy: 0.6318\n",
      "Epoch 45:  Train Loss: 0.6632  Eval Loss: 0.6589   Accuracy: 0.6318\n",
      "Epoch 46:  Train Loss: 0.6631  Eval Loss: 0.6588   Accuracy: 0.6318\n",
      "Epoch 47:  Train Loss: 0.6631  Eval Loss: 0.6588   Accuracy: 0.6318\n",
      "Epoch 48:  Train Loss: 0.6630  Eval Loss: 0.6589   Accuracy: 0.6318\n",
      "Epoch 49:  Train Loss: 0.6632  Eval Loss: 0.6588   Accuracy: 0.6318\n",
      "Epoch 50:  Train Loss: 0.6627  Eval Loss: 0.6587   Accuracy: 0.6318\n",
      "    Final Results: {'eval_loss': 0.6586717039346695, 'accuracy': 0.6318327974276527, 'best_accuracy': 0.6323769478110314}\n",
      "  Method: prefix_lora\n",
      "Epoch 1:  Train Loss: 0.7126  Eval Loss: 0.7178   Accuracy: 0.3996\n",
      "Epoch 2:  Train Loss: 0.7123  Eval Loss: 0.7182   Accuracy: 0.3986\n",
      "Epoch 3:  Train Loss: 0.7121  Eval Loss: 0.7169   Accuracy: 0.4028\n",
      "Epoch 4:  Train Loss: 0.7113  Eval Loss: 0.7161   Accuracy: 0.4050\n",
      "Epoch 5:  Train Loss: 0.7103  Eval Loss: 0.7155   Accuracy: 0.4066\n",
      "Epoch 6:  Train Loss: 0.7101  Eval Loss: 0.7148   Accuracy: 0.4088\n",
      "Epoch 7:  Train Loss: 0.7089  Eval Loss: 0.7133   Accuracy: 0.4132\n",
      "Epoch 8:  Train Loss: 0.7073  Eval Loss: 0.7114   Accuracy: 0.4205\n",
      "Epoch 9:  Train Loss: 0.7062  Eval Loss: 0.7099   Accuracy: 0.4270\n",
      "Epoch 10:  Train Loss: 0.7045  Eval Loss: 0.7080   Accuracy: 0.4360\n",
      "Epoch 11:  Train Loss: 0.7034  Eval Loss: 0.7074   Accuracy: 0.4385\n",
      "Epoch 12:  Train Loss: 0.7024  Eval Loss: 0.7052   Accuracy: 0.4495\n",
      "Epoch 13:  Train Loss: 0.7012  Eval Loss: 0.7050   Accuracy: 0.4512\n",
      "Epoch 14:  Train Loss: 0.7003  Eval Loss: 0.7028   Accuracy: 0.4629\n",
      "Epoch 15:  Train Loss: 0.6976  Eval Loss: 0.6991   Accuracy: 0.4845\n",
      "Epoch 16:  Train Loss: 0.6946  Eval Loss: 0.6971   Accuracy: 0.4949\n",
      "Epoch 17:  Train Loss: 0.6920  Eval Loss: 0.6927   Accuracy: 0.5221\n",
      "Epoch 18:  Train Loss: 0.6894  Eval Loss: 0.6909   Accuracy: 0.5340\n",
      "Epoch 19:  Train Loss: 0.6877  Eval Loss: 0.6891   Accuracy: 0.5457\n",
      "Epoch 20:  Train Loss: 0.6856  Eval Loss: 0.6857   Accuracy: 0.5669\n",
      "Epoch 21:  Train Loss: 0.6828  Eval Loss: 0.6828   Accuracy: 0.5805\n",
      "Epoch 22:  Train Loss: 0.6815  Eval Loss: 0.6820   Accuracy: 0.5838\n",
      "Epoch 23:  Train Loss: 0.6801  Eval Loss: 0.6786   Accuracy: 0.5991\n",
      "Epoch 24:  Train Loss: 0.6758  Eval Loss: 0.6740   Accuracy: 0.6137\n",
      "Epoch 25:  Train Loss: 0.6735  Eval Loss: 0.6725   Accuracy: 0.6186\n",
      "Epoch 26:  Train Loss: 0.6722  Eval Loss: 0.6701   Accuracy: 0.6238\n",
      "Epoch 27:  Train Loss: 0.6690  Eval Loss: 0.6668   Accuracy: 0.6322\n",
      "Epoch 28:  Train Loss: 0.6678  Eval Loss: 0.6664   Accuracy: 0.6312\n",
      "Epoch 29:  Train Loss: 0.6662  Eval Loss: 0.6633   Accuracy: 0.6355\n",
      "Epoch 30:  Train Loss: 0.6646  Eval Loss: 0.6621   Accuracy: 0.6361\n",
      "Epoch 31:  Train Loss: 0.6628  Eval Loss: 0.6596   Accuracy: 0.6357\n",
      "Epoch 32:  Train Loss: 0.6616  Eval Loss: 0.6578   Accuracy: 0.6339\n",
      "Epoch 33:  Train Loss: 0.6598  Eval Loss: 0.6560   Accuracy: 0.6331\n",
      "Epoch 34:  Train Loss: 0.6584  Eval Loss: 0.6550   Accuracy: 0.6326\n",
      "Epoch 35:  Train Loss: 0.6578  Eval Loss: 0.6543   Accuracy: 0.6324\n",
      "Epoch 36:  Train Loss: 0.6572  Eval Loss: 0.6535   Accuracy: 0.6318\n",
      "Epoch 37:  Train Loss: 0.6565  Eval Loss: 0.6523   Accuracy: 0.6319\n",
      "Epoch 38:  Train Loss: 0.6557  Eval Loss: 0.6515   Accuracy: 0.6325\n",
      "Epoch 39:  Train Loss: 0.6546  Eval Loss: 0.6501   Accuracy: 0.6319\n",
      "Epoch 40:  Train Loss: 0.6543  Eval Loss: 0.6499   Accuracy: 0.6319\n",
      "Epoch 41:  Train Loss: 0.6540  Eval Loss: 0.6495   Accuracy: 0.6320\n",
      "Epoch 42:  Train Loss: 0.6535  Eval Loss: 0.6492   Accuracy: 0.6320\n",
      "Epoch 43:  Train Loss: 0.6535  Eval Loss: 0.6497   Accuracy: 0.6319\n",
      "Epoch 44:  Train Loss: 0.6538  Eval Loss: 0.6493   Accuracy: 0.6318\n",
      "Epoch 45:  Train Loss: 0.6537  Eval Loss: 0.6492   Accuracy: 0.6319\n",
      "Epoch 46:  Train Loss: 0.6537  Eval Loss: 0.6487   Accuracy: 0.6321\n",
      "Epoch 47:  Train Loss: 0.6533  Eval Loss: 0.6488   Accuracy: 0.6319\n",
      "Epoch 48:  Train Loss: 0.6537  Eval Loss: 0.6489   Accuracy: 0.6320\n",
      "Epoch 49:  Train Loss: 0.6536  Eval Loss: 0.6491   Accuracy: 0.6321\n",
      "Epoch 50:  Train Loss: 0.6535  Eval Loss: 0.6486   Accuracy: 0.6321\n",
      "    Final Results: {'eval_loss': 0.6485646530985832, 'accuracy': 0.6321048726193421, 'best_accuracy': 0.6360623299530052}\n",
      "==================================================\n",
      "\n",
      "Results for qqp:\n",
      "  Method: soft_prompt, Accuracy: 0.6314, Loss: 0.6345\n",
      "  Method: prefix, Accuracy: 0.6717, Loss: 0.5973\n",
      "  Method: full_fine_tuning, Accuracy: 0.6682, Loss: 0.6022\n",
      "  Method: lora, Accuracy: 0.6989, Loss: 0.5450\n",
      "  Method: ia3, Accuracy: 0.6977, Loss: 0.5670\n",
      "  Method: single_layer_fine_tuning, Accuracy: 0.6850, Loss: 0.5778\n",
      "  Method: soft_prompt_lora, Accuracy: 0.6318, Loss: 0.6587\n",
      "  Method: prefix_lora, Accuracy: 0.6321, Loss: 0.6486\n",
      "\n",
      "Results have been appended to peft_experiment_results.txt\n"
     ]
    }
   ],
   "source": [
    "results = run_peft_experiments(epsilon=8,dataset=['qqp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc8af28-f1ab-4c55-912f-4f8775c3b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing dataset: qqp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40430/40430 [00:03<00:00, 13435.11 examples/s]\n",
      "Map: 100%|██████████| 40430/40430 [00:01<00:00, 23519.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Method: soft_prompt\n",
      "Epoch 1:  Train Loss: 0.6662  Eval Loss: 0.6577   Accuracy: 0.6318\n",
      "Epoch 2:  Train Loss: 0.6596  Eval Loss: 0.6567   Accuracy: 0.6318\n",
      "Epoch 3:  Train Loss: 0.6592  Eval Loss: 0.6568   Accuracy: 0.6318\n",
      "Epoch 4:  Train Loss: 0.6594  Eval Loss: 0.6560   Accuracy: 0.6318\n",
      "Epoch 5:  Train Loss: 0.6596  Eval Loss: 0.6581   Accuracy: 0.6318\n",
      "Epoch 6:  Train Loss: 0.6598  Eval Loss: 0.6565   Accuracy: 0.6318\n",
      "Epoch 7:  Train Loss: 0.6593  Eval Loss: 0.6560   Accuracy: 0.6318\n",
      "Epoch 8:  Train Loss: 0.6595  Eval Loss: 0.6559   Accuracy: 0.6318\n",
      "Epoch 9:  Train Loss: 0.6586  Eval Loss: 0.6550   Accuracy: 0.6318\n",
      "Epoch 10:  Train Loss: 0.6593  Eval Loss: 0.6556   Accuracy: 0.6318\n",
      "Epoch 11:  Train Loss: 0.6597  Eval Loss: 0.6556   Accuracy: 0.6318\n",
      "Epoch 12:  Train Loss: 0.6593  Eval Loss: 0.6553   Accuracy: 0.6318\n",
      "Epoch 13:  Train Loss: 0.6594  Eval Loss: 0.6551   Accuracy: 0.6318\n",
      "Epoch 14:  Train Loss: 0.6593  Eval Loss: 0.6553   Accuracy: 0.6318\n",
      "Epoch 15:  Train Loss: 0.6592  Eval Loss: 0.6554   Accuracy: 0.6318\n",
      "Epoch 16:  Train Loss: 0.6600  Eval Loss: 0.6554   Accuracy: 0.6318\n",
      "Epoch 17:  Train Loss: 0.6602  Eval Loss: 0.6552   Accuracy: 0.6318\n",
      "Epoch 18:  Train Loss: 0.6599  Eval Loss: 0.6550   Accuracy: 0.6318\n",
      "Epoch 19:  Train Loss: 0.6600  Eval Loss: 0.6551   Accuracy: 0.6318\n",
      "Epoch 20:  Train Loss: 0.6597  Eval Loss: 0.6540   Accuracy: 0.6319\n",
      "Epoch 21:  Train Loss: 0.6594  Eval Loss: 0.6540   Accuracy: 0.6318\n",
      "Epoch 22:  Train Loss: 0.6590  Eval Loss: 0.6538   Accuracy: 0.6319\n",
      "Epoch 23:  Train Loss: 0.6590  Eval Loss: 0.6537   Accuracy: 0.6318\n",
      "Epoch 24:  Train Loss: 0.6585  Eval Loss: 0.6534   Accuracy: 0.6318\n",
      "Epoch 25:  Train Loss: 0.6586  Eval Loss: 0.6536   Accuracy: 0.6318\n",
      "Epoch 26:  Train Loss: 0.6591  Eval Loss: 0.6539   Accuracy: 0.6318\n",
      "Epoch 27:  Train Loss: 0.6594  Eval Loss: 0.6542   Accuracy: 0.6318\n",
      "Epoch 28:  Train Loss: 0.6597  Eval Loss: 0.6542   Accuracy: 0.6318\n",
      "Epoch 29:  Train Loss: 0.6599  Eval Loss: 0.6546   Accuracy: 0.6318\n",
      "Epoch 30:  Train Loss: 0.6599  Eval Loss: 0.6549   Accuracy: 0.6318\n",
      "Epoch 31:  Train Loss: 0.6602  Eval Loss: 0.6552   Accuracy: 0.6318\n",
      "Epoch 32:  Train Loss: 0.6603  Eval Loss: 0.6551   Accuracy: 0.6318\n",
      "Epoch 33:  Train Loss: 0.6604  Eval Loss: 0.6550   Accuracy: 0.6318\n",
      "Epoch 34:  Train Loss: 0.6603  Eval Loss: 0.6547   Accuracy: 0.6318\n",
      "Epoch 35:  Train Loss: 0.6600  Eval Loss: 0.6542   Accuracy: 0.6318\n",
      "Epoch 36:  Train Loss: 0.6599  Eval Loss: 0.6536   Accuracy: 0.6318\n",
      "Epoch 37:  Train Loss: 0.6594  Eval Loss: 0.6531   Accuracy: 0.6318\n",
      "Epoch 38:  Train Loss: 0.6598  Eval Loss: 0.6526   Accuracy: 0.6318\n",
      "Epoch 39:  Train Loss: 0.6595  Eval Loss: 0.6525   Accuracy: 0.6318\n",
      "Epoch 40:  Train Loss: 0.6592  Eval Loss: 0.6528   Accuracy: 0.6317\n",
      "Epoch 41:  Train Loss: 0.6598  Eval Loss: 0.6528   Accuracy: 0.6318\n",
      "Epoch 42:  Train Loss: 0.6595  Eval Loss: 0.6528   Accuracy: 0.6318\n",
      "Epoch 43:  Train Loss: 0.6594  Eval Loss: 0.6532   Accuracy: 0.6318\n",
      "Epoch 44:  Train Loss: 0.6594  Eval Loss: 0.6532   Accuracy: 0.6318\n",
      "Epoch 45:  Train Loss: 0.6591  Eval Loss: 0.6527   Accuracy: 0.6318\n",
      "Epoch 46:  Train Loss: 0.6589  Eval Loss: 0.6526   Accuracy: 0.6318\n",
      "Epoch 47:  Train Loss: 0.6596  Eval Loss: 0.6530   Accuracy: 0.6318\n",
      "Epoch 48:  Train Loss: 0.6595  Eval Loss: 0.6524   Accuracy: 0.6318\n",
      "Epoch 49:  Train Loss: 0.6596  Eval Loss: 0.6523   Accuracy: 0.6318\n",
      "Epoch 50:  Train Loss: 0.6591  Eval Loss: 0.6526   Accuracy: 0.6318\n",
      "    Final Results: {'eval_loss': 0.6525887861847878, 'accuracy': 0.6318327974276527, 'best_accuracy': 0.6318575315359881}\n",
      "  Method: prefix\n",
      "Epoch 1:  Train Loss: 0.6617  Eval Loss: 0.6376   Accuracy: 0.6250\n",
      "Epoch 2:  Train Loss: 0.6410  Eval Loss: 0.6246   Accuracy: 0.6351\n",
      "Epoch 3:  Train Loss: 0.6359  Eval Loss: 0.6228   Accuracy: 0.6381\n",
      "Epoch 4:  Train Loss: 0.6349  Eval Loss: 0.6216   Accuracy: 0.6408\n",
      "Epoch 5:  Train Loss: 0.6324  Eval Loss: 0.6216   Accuracy: 0.6416\n",
      "Epoch 6:  Train Loss: 0.6322  Eval Loss: 0.6188   Accuracy: 0.6452\n",
      "Epoch 7:  Train Loss: 0.6312  Eval Loss: 0.6140   Accuracy: 0.6473\n",
      "Epoch 8:  Train Loss: 0.6296  Eval Loss: 0.6194   Accuracy: 0.6496\n",
      "Epoch 9:  Train Loss: 0.6287  Eval Loss: 0.6151   Accuracy: 0.6521\n",
      "Epoch 10:  Train Loss: 0.6280  Eval Loss: 0.6139   Accuracy: 0.6535\n",
      "Epoch 11:  Train Loss: 0.6272  Eval Loss: 0.6134   Accuracy: 0.6565\n",
      "Epoch 12:  Train Loss: 0.6261  Eval Loss: 0.6148   Accuracy: 0.6553\n",
      "Epoch 13:  Train Loss: 0.6261  Eval Loss: 0.6123   Accuracy: 0.6548\n",
      "Epoch 14:  Train Loss: 0.6250  Eval Loss: 0.6104   Accuracy: 0.6553\n",
      "Epoch 15:  Train Loss: 0.6246  Eval Loss: 0.6091   Accuracy: 0.6555\n",
      "Epoch 16:  Train Loss: 0.6249  Eval Loss: 0.6077   Accuracy: 0.6557\n",
      "Epoch 17:  Train Loss: 0.6241  Eval Loss: 0.6102   Accuracy: 0.6584\n",
      "Epoch 18:  Train Loss: 0.6251  Eval Loss: 0.6087   Accuracy: 0.6573\n",
      "Epoch 19:  Train Loss: 0.6240  Eval Loss: 0.6031   Accuracy: 0.6528\n",
      "Epoch 20:  Train Loss: 0.6245  Eval Loss: 0.6064   Accuracy: 0.6577\n",
      "Epoch 21:  Train Loss: 0.6243  Eval Loss: 0.6066   Accuracy: 0.6585\n",
      "Epoch 22:  Train Loss: 0.6234  Eval Loss: 0.6050   Accuracy: 0.6583\n",
      "Epoch 23:  Train Loss: 0.6230  Eval Loss: 0.6077   Accuracy: 0.6633\n",
      "Epoch 24:  Train Loss: 0.6233  Eval Loss: 0.6051   Accuracy: 0.6625\n",
      "Epoch 25:  Train Loss: 0.6228  Eval Loss: 0.6046   Accuracy: 0.6612\n",
      "Epoch 26:  Train Loss: 0.6223  Eval Loss: 0.6049   Accuracy: 0.6640\n",
      "Epoch 27:  Train Loss: 0.6228  Eval Loss: 0.6044   Accuracy: 0.6621\n",
      "Epoch 28:  Train Loss: 0.6230  Eval Loss: 0.6017   Accuracy: 0.6617\n",
      "Epoch 29:  Train Loss: 0.6225  Eval Loss: 0.6052   Accuracy: 0.6616\n",
      "Epoch 30:  Train Loss: 0.6234  Eval Loss: 0.6030   Accuracy: 0.6605\n",
      "Epoch 31:  Train Loss: 0.6229  Eval Loss: 0.6015   Accuracy: 0.6618\n",
      "Epoch 32:  Train Loss: 0.6232  Eval Loss: 0.6013   Accuracy: 0.6598\n",
      "Epoch 33:  Train Loss: 0.6243  Eval Loss: 0.6032   Accuracy: 0.6590\n",
      "Epoch 34:  Train Loss: 0.6240  Eval Loss: 0.6033   Accuracy: 0.6580\n",
      "Epoch 35:  Train Loss: 0.6235  Eval Loss: 0.6068   Accuracy: 0.6571\n",
      "Epoch 36:  Train Loss: 0.6232  Eval Loss: 0.6035   Accuracy: 0.6590\n",
      "Epoch 37:  Train Loss: 0.6234  Eval Loss: 0.6052   Accuracy: 0.6586\n",
      "Epoch 38:  Train Loss: 0.6234  Eval Loss: 0.6026   Accuracy: 0.6579\n",
      "Epoch 39:  Train Loss: 0.6228  Eval Loss: 0.6049   Accuracy: 0.6568\n",
      "Epoch 40:  Train Loss: 0.6231  Eval Loss: 0.6010   Accuracy: 0.6612\n",
      "Epoch 41:  Train Loss: 0.6227  Eval Loss: 0.6057   Accuracy: 0.6580\n",
      "Epoch 42:  Train Loss: 0.6235  Eval Loss: 0.6021   Accuracy: 0.6616\n",
      "Epoch 43:  Train Loss: 0.6225  Eval Loss: 0.6037   Accuracy: 0.6611\n",
      "Epoch 44:  Train Loss: 0.6235  Eval Loss: 0.6035   Accuracy: 0.6609\n",
      "Epoch 45:  Train Loss: 0.6237  Eval Loss: 0.6064   Accuracy: 0.6571\n",
      "Epoch 46:  Train Loss: 0.6238  Eval Loss: 0.6048   Accuracy: 0.6583\n",
      "Epoch 47:  Train Loss: 0.6241  Eval Loss: 0.6071   Accuracy: 0.6580\n",
      "Epoch 48:  Train Loss: 0.6239  Eval Loss: 0.6054   Accuracy: 0.6609\n",
      "Epoch 49:  Train Loss: 0.6235  Eval Loss: 0.6025   Accuracy: 0.6618\n",
      "Epoch 50:  Train Loss: 0.6233  Eval Loss: 0.6038   Accuracy: 0.6630\n",
      "    Final Results: {'eval_loss': 0.6037967443466187, 'accuracy': 0.6629977739302498, 'best_accuracy': 0.6639871382636656}\n",
      "  Method: full_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.6499  Eval Loss: 0.6217   Accuracy: 0.6326\n",
      "Epoch 2:  Train Loss: 0.6090  Eval Loss: 0.5860   Accuracy: 0.6827\n",
      "Epoch 3:  Train Loss: 0.5870  Eval Loss: 0.5754   Accuracy: 0.6754\n",
      "Epoch 4:  Train Loss: 0.5783  Eval Loss: 0.5655   Accuracy: 0.6889\n",
      "Epoch 5:  Train Loss: 0.5713  Eval Loss: 0.5601   Accuracy: 0.6847\n",
      "Epoch 6:  Train Loss: 0.5707  Eval Loss: 0.5568   Accuracy: 0.6919\n",
      "Epoch 7:  Train Loss: 0.5704  Eval Loss: 0.5626   Accuracy: 0.6894\n",
      "Epoch 8:  Train Loss: 0.5733  Eval Loss: 0.5589   Accuracy: 0.6968\n",
      "Epoch 9:  Train Loss: 0.5754  Eval Loss: 0.5641   Accuracy: 0.6899\n",
      "Epoch 10:  Train Loss: 0.5768  Eval Loss: 0.5679   Accuracy: 0.6841\n",
      "Epoch 11:  Train Loss: 0.5771  Eval Loss: 0.5572   Accuracy: 0.6962\n",
      "Epoch 12:  Train Loss: 0.5799  Eval Loss: 0.5622   Accuracy: 0.6904\n",
      "Epoch 13:  Train Loss: 0.5801  Eval Loss: 0.5608   Accuracy: 0.6922\n",
      "Epoch 14:  Train Loss: 0.5832  Eval Loss: 0.5613   Accuracy: 0.6955\n",
      "Epoch 15:  Train Loss: 0.5857  Eval Loss: 0.5628   Accuracy: 0.6945\n",
      "Epoch 16:  Train Loss: 0.5870  Eval Loss: 0.5663   Accuracy: 0.6922\n",
      "Epoch 17:  Train Loss: 0.5874  Eval Loss: 0.5666   Accuracy: 0.6934\n",
      "Epoch 18:  Train Loss: 0.5905  Eval Loss: 0.5706   Accuracy: 0.6895\n",
      "Epoch 19:  Train Loss: 0.5912  Eval Loss: 0.5708   Accuracy: 0.6914\n",
      "Epoch 20:  Train Loss: 0.5930  Eval Loss: 0.5715   Accuracy: 0.6922\n",
      "Epoch 21:  Train Loss: 0.5943  Eval Loss: 0.5745   Accuracy: 0.6893\n",
      "Epoch 22:  Train Loss: 0.5948  Eval Loss: 0.5747   Accuracy: 0.6915\n",
      "Epoch 23:  Train Loss: 0.5961  Eval Loss: 0.5751   Accuracy: 0.6879\n",
      "Epoch 24:  Train Loss: 0.5973  Eval Loss: 0.5811   Accuracy: 0.6813\n",
      "Epoch 25:  Train Loss: 0.5981  Eval Loss: 0.5770   Accuracy: 0.6886\n",
      "Epoch 26:  Train Loss: 0.5996  Eval Loss: 0.5767   Accuracy: 0.6902\n",
      "Epoch 27:  Train Loss: 0.6007  Eval Loss: 0.5806   Accuracy: 0.6842\n",
      "Epoch 28:  Train Loss: 0.6025  Eval Loss: 0.5810   Accuracy: 0.6860\n",
      "Epoch 29:  Train Loss: 0.6013  Eval Loss: 0.5801   Accuracy: 0.6854\n",
      "Epoch 30:  Train Loss: 0.6022  Eval Loss: 0.5800   Accuracy: 0.6854\n",
      "Epoch 31:  Train Loss: 0.6027  Eval Loss: 0.5830   Accuracy: 0.6834\n",
      "Epoch 32:  Train Loss: 0.6040  Eval Loss: 0.5850   Accuracy: 0.6828\n",
      "Epoch 33:  Train Loss: 0.6061  Eval Loss: 0.5877   Accuracy: 0.6772\n",
      "Epoch 34:  Train Loss: 0.6070  Eval Loss: 0.5868   Accuracy: 0.6779\n",
      "Epoch 35:  Train Loss: 0.6099  Eval Loss: 0.5874   Accuracy: 0.6770\n",
      "Epoch 36:  Train Loss: 0.6111  Eval Loss: 0.5902   Accuracy: 0.6744\n",
      "Epoch 37:  Train Loss: 0.6128  Eval Loss: 0.5903   Accuracy: 0.6765\n",
      "Epoch 38:  Train Loss: 0.6124  Eval Loss: 0.5927   Accuracy: 0.6726\n",
      "Epoch 39:  Train Loss: 0.6123  Eval Loss: 0.5938   Accuracy: 0.6727\n",
      "Epoch 40:  Train Loss: 0.6135  Eval Loss: 0.5956   Accuracy: 0.6720\n",
      "Epoch 41:  Train Loss: 0.6137  Eval Loss: 0.5974   Accuracy: 0.6674\n",
      "Epoch 42:  Train Loss: 0.6143  Eval Loss: 0.5956   Accuracy: 0.6721\n",
      "Epoch 43:  Train Loss: 0.6156  Eval Loss: 0.5968   Accuracy: 0.6719\n",
      "Epoch 44:  Train Loss: 0.6166  Eval Loss: 0.5966   Accuracy: 0.6689\n",
      "Epoch 45:  Train Loss: 0.6171  Eval Loss: 0.5981   Accuracy: 0.6673\n",
      "Epoch 46:  Train Loss: 0.6184  Eval Loss: 0.5988   Accuracy: 0.6683\n",
      "Epoch 47:  Train Loss: 0.6189  Eval Loss: 0.5984   Accuracy: 0.6683\n",
      "Epoch 48:  Train Loss: 0.6186  Eval Loss: 0.5991   Accuracy: 0.6690\n",
      "Epoch 49:  Train Loss: 0.6188  Eval Loss: 0.6003   Accuracy: 0.6694\n",
      "Epoch 50:  Train Loss: 0.6197  Eval Loss: 0.6018   Accuracy: 0.6679\n",
      "    Final Results: {'eval_loss': 0.6017644166946411, 'accuracy': 0.6678703932723226, 'best_accuracy': 0.6967598318080633}\n",
      "  Method: lora\n",
      "Epoch 1:  Train Loss: 0.6644  Eval Loss: 0.6334   Accuracy: 0.6333\n",
      "Epoch 2:  Train Loss: 0.6258  Eval Loss: 0.6137   Accuracy: 0.6432\n",
      "Epoch 3:  Train Loss: 0.6163  Eval Loss: 0.6075   Accuracy: 0.6494\n",
      "Epoch 4:  Train Loss: 0.6128  Eval Loss: 0.6040   Accuracy: 0.6547\n",
      "Epoch 5:  Train Loss: 0.6100  Eval Loss: 0.5985   Accuracy: 0.6627\n",
      "Epoch 6:  Train Loss: 0.6060  Eval Loss: 0.5962   Accuracy: 0.6718\n",
      "Epoch 7:  Train Loss: 0.6042  Eval Loss: 0.5934   Accuracy: 0.6701\n",
      "Epoch 8:  Train Loss: 0.6026  Eval Loss: 0.5943   Accuracy: 0.6689\n",
      "Epoch 9:  Train Loss: 0.6003  Eval Loss: 0.5891   Accuracy: 0.6771\n",
      "Epoch 10:  Train Loss: 0.5993  Eval Loss: 0.5912   Accuracy: 0.6722\n",
      "Epoch 11:  Train Loss: 0.5990  Eval Loss: 0.5898   Accuracy: 0.6779\n",
      "Epoch 12:  Train Loss: 0.5972  Eval Loss: 0.5902   Accuracy: 0.6801\n",
      "Epoch 13:  Train Loss: 0.5951  Eval Loss: 0.5862   Accuracy: 0.6832\n",
      "Epoch 14:  Train Loss: 0.5942  Eval Loss: 0.5845   Accuracy: 0.6852\n",
      "Epoch 15:  Train Loss: 0.5923  Eval Loss: 0.5834   Accuracy: 0.6859\n",
      "Epoch 16:  Train Loss: 0.5898  Eval Loss: 0.5779   Accuracy: 0.6879\n",
      "Epoch 17:  Train Loss: 0.5880  Eval Loss: 0.5780   Accuracy: 0.6863\n",
      "Epoch 18:  Train Loss: 0.5864  Eval Loss: 0.5742   Accuracy: 0.6900\n",
      "Epoch 19:  Train Loss: 0.5846  Eval Loss: 0.5725   Accuracy: 0.6911\n",
      "Epoch 20:  Train Loss: 0.5823  Eval Loss: 0.5704   Accuracy: 0.6917\n",
      "Epoch 21:  Train Loss: 0.5796  Eval Loss: 0.5707   Accuracy: 0.6912\n",
      "Epoch 22:  Train Loss: 0.5779  Eval Loss: 0.5671   Accuracy: 0.6922\n",
      "Epoch 23:  Train Loss: 0.5762  Eval Loss: 0.5650   Accuracy: 0.6967\n",
      "Epoch 24:  Train Loss: 0.5755  Eval Loss: 0.5633   Accuracy: 0.6959\n",
      "Epoch 25:  Train Loss: 0.5748  Eval Loss: 0.5649   Accuracy: 0.6919\n",
      "Epoch 26:  Train Loss: 0.5730  Eval Loss: 0.5602   Accuracy: 0.6951\n",
      "Epoch 27:  Train Loss: 0.5728  Eval Loss: 0.5628   Accuracy: 0.6902\n",
      "Epoch 28:  Train Loss: 0.5710  Eval Loss: 0.5602   Accuracy: 0.6934\n",
      "Epoch 29:  Train Loss: 0.5706  Eval Loss: 0.5592   Accuracy: 0.6953\n",
      "Epoch 30:  Train Loss: 0.5701  Eval Loss: 0.5589   Accuracy: 0.6928\n",
      "Epoch 31:  Train Loss: 0.5685  Eval Loss: 0.5596   Accuracy: 0.6913\n",
      "Epoch 32:  Train Loss: 0.5678  Eval Loss: 0.5588   Accuracy: 0.6915\n",
      "Epoch 33:  Train Loss: 0.5662  Eval Loss: 0.5533   Accuracy: 0.6953\n",
      "Epoch 34:  Train Loss: 0.5652  Eval Loss: 0.5538   Accuracy: 0.6973\n",
      "Epoch 35:  Train Loss: 0.5653  Eval Loss: 0.5538   Accuracy: 0.6961\n",
      "Epoch 36:  Train Loss: 0.5645  Eval Loss: 0.5559   Accuracy: 0.6941\n",
      "Epoch 37:  Train Loss: 0.5638  Eval Loss: 0.5520   Accuracy: 0.6977\n",
      "Epoch 38:  Train Loss: 0.5627  Eval Loss: 0.5511   Accuracy: 0.6973\n",
      "Epoch 39:  Train Loss: 0.5629  Eval Loss: 0.5543   Accuracy: 0.6943\n",
      "Epoch 40:  Train Loss: 0.5631  Eval Loss: 0.5502   Accuracy: 0.6971\n",
      "Epoch 41:  Train Loss: 0.5626  Eval Loss: 0.5522   Accuracy: 0.6952\n",
      "Epoch 42:  Train Loss: 0.5617  Eval Loss: 0.5490   Accuracy: 0.6981\n",
      "Epoch 43:  Train Loss: 0.5601  Eval Loss: 0.5479   Accuracy: 0.6984\n",
      "Epoch 44:  Train Loss: 0.5597  Eval Loss: 0.5441   Accuracy: 0.7013\n",
      "Epoch 45:  Train Loss: 0.5588  Eval Loss: 0.5481   Accuracy: 0.6977\n",
      "Epoch 46:  Train Loss: 0.5583  Eval Loss: 0.5465   Accuracy: 0.6999\n",
      "Epoch 47:  Train Loss: 0.5576  Eval Loss: 0.5459   Accuracy: 0.7008\n",
      "Epoch 48:  Train Loss: 0.5577  Eval Loss: 0.5477   Accuracy: 0.6990\n",
      "Epoch 49:  Train Loss: 0.5568  Eval Loss: 0.5439   Accuracy: 0.7008\n",
      "Epoch 50:  Train Loss: 0.5567  Eval Loss: 0.5500   Accuracy: 0.6932\n",
      "    Final Results: {'eval_loss': 0.549985146522522, 'accuracy': 0.6932475884244373, 'best_accuracy': 0.7012614395251051}\n",
      "  Method: ia3\n",
      "Epoch 1:  Train Loss: 0.6448  Eval Loss: 0.6229   Accuracy: 0.6374\n",
      "Epoch 2:  Train Loss: 0.6223  Eval Loss: 0.6094   Accuracy: 0.6508\n",
      "Epoch 3:  Train Loss: 0.6167  Eval Loss: 0.6106   Accuracy: 0.6609\n",
      "Epoch 4:  Train Loss: 0.6130  Eval Loss: 0.6039   Accuracy: 0.6595\n",
      "Epoch 5:  Train Loss: 0.6101  Eval Loss: 0.6017   Accuracy: 0.6644\n",
      "Epoch 6:  Train Loss: 0.6072  Eval Loss: 0.5977   Accuracy: 0.6678\n",
      "Epoch 7:  Train Loss: 0.6047  Eval Loss: 0.5946   Accuracy: 0.6681\n",
      "Epoch 8:  Train Loss: 0.6044  Eval Loss: 0.5932   Accuracy: 0.6672\n",
      "Epoch 9:  Train Loss: 0.6031  Eval Loss: 0.5935   Accuracy: 0.6703\n",
      "Epoch 10:  Train Loss: 0.6010  Eval Loss: 0.5900   Accuracy: 0.6733\n",
      "Epoch 11:  Train Loss: 0.6003  Eval Loss: 0.5902   Accuracy: 0.6763\n",
      "Epoch 12:  Train Loss: 0.5989  Eval Loss: 0.5864   Accuracy: 0.6749\n",
      "Epoch 13:  Train Loss: 0.5987  Eval Loss: 0.5891   Accuracy: 0.6709\n",
      "Epoch 14:  Train Loss: 0.5977  Eval Loss: 0.5864   Accuracy: 0.6741\n",
      "Epoch 15:  Train Loss: 0.5967  Eval Loss: 0.5892   Accuracy: 0.6758\n",
      "Epoch 16:  Train Loss: 0.5958  Eval Loss: 0.5884   Accuracy: 0.6712\n",
      "Epoch 17:  Train Loss: 0.5964  Eval Loss: 0.5872   Accuracy: 0.6744\n",
      "Epoch 18:  Train Loss: 0.5968  Eval Loss: 0.5843   Accuracy: 0.6759\n",
      "Epoch 19:  Train Loss: 0.5964  Eval Loss: 0.5825   Accuracy: 0.6772\n",
      "Epoch 20:  Train Loss: 0.5960  Eval Loss: 0.5864   Accuracy: 0.6732\n",
      "Epoch 21:  Train Loss: 0.5959  Eval Loss: 0.5840   Accuracy: 0.6761\n",
      "Epoch 22:  Train Loss: 0.5955  Eval Loss: 0.5822   Accuracy: 0.6774\n",
      "Epoch 23:  Train Loss: 0.5949  Eval Loss: 0.5827   Accuracy: 0.6758\n",
      "Epoch 24:  Train Loss: 0.5942  Eval Loss: 0.5792   Accuracy: 0.6798\n",
      "Epoch 25:  Train Loss: 0.5940  Eval Loss: 0.5808   Accuracy: 0.6791\n",
      "Epoch 26:  Train Loss: 0.5932  Eval Loss: 0.5787   Accuracy: 0.6783\n",
      "Epoch 27:  Train Loss: 0.5921  Eval Loss: 0.5810   Accuracy: 0.6753\n",
      "Epoch 28:  Train Loss: 0.5933  Eval Loss: 0.5798   Accuracy: 0.6763\n",
      "Epoch 29:  Train Loss: 0.5925  Eval Loss: 0.5790   Accuracy: 0.6798\n",
      "Epoch 30:  Train Loss: 0.5928  Eval Loss: 0.5769   Accuracy: 0.6821\n",
      "Epoch 31:  Train Loss: 0.5927  Eval Loss: 0.5788   Accuracy: 0.6807\n",
      "Epoch 32:  Train Loss: 0.5912  Eval Loss: 0.5768   Accuracy: 0.6835\n",
      "Epoch 33:  Train Loss: 0.5918  Eval Loss: 0.5758   Accuracy: 0.6823\n",
      "Epoch 34:  Train Loss: 0.5909  Eval Loss: 0.5745   Accuracy: 0.6858\n",
      "Epoch 35:  Train Loss: 0.5906  Eval Loss: 0.5760   Accuracy: 0.6883\n",
      "Epoch 36:  Train Loss: 0.5902  Eval Loss: 0.5767   Accuracy: 0.6846\n",
      "Epoch 37:  Train Loss: 0.5906  Eval Loss: 0.5734   Accuracy: 0.6884\n",
      "Epoch 38:  Train Loss: 0.5902  Eval Loss: 0.5753   Accuracy: 0.6879\n",
      "Epoch 39:  Train Loss: 0.5900  Eval Loss: 0.5762   Accuracy: 0.6876\n",
      "Epoch 40:  Train Loss: 0.5906  Eval Loss: 0.5726   Accuracy: 0.6895\n",
      "Epoch 41:  Train Loss: 0.5901  Eval Loss: 0.5741   Accuracy: 0.6886\n",
      "Epoch 42:  Train Loss: 0.5893  Eval Loss: 0.5758   Accuracy: 0.6861\n",
      "Epoch 43:  Train Loss: 0.5886  Eval Loss: 0.5729   Accuracy: 0.6877\n",
      "Epoch 44:  Train Loss: 0.5882  Eval Loss: 0.5748   Accuracy: 0.6834\n",
      "Epoch 45:  Train Loss: 0.5893  Eval Loss: 0.5715   Accuracy: 0.6884\n",
      "Epoch 46:  Train Loss: 0.5899  Eval Loss: 0.5717   Accuracy: 0.6882\n",
      "Epoch 47:  Train Loss: 0.5884  Eval Loss: 0.5710   Accuracy: 0.6893\n",
      "Epoch 48:  Train Loss: 0.5879  Eval Loss: 0.5714   Accuracy: 0.6885\n",
      "Epoch 49:  Train Loss: 0.5873  Eval Loss: 0.5687   Accuracy: 0.6908\n",
      "Epoch 50:  Train Loss: 0.5865  Eval Loss: 0.5709   Accuracy: 0.6870\n",
      "    Final Results: {'eval_loss': 0.5708799615502358, 'accuracy': 0.6870145931239179, 'best_accuracy': 0.6907989116992332}\n",
      "  Method: single_layer_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.6610  Eval Loss: 0.6375   Accuracy: 0.6154\n",
      "Epoch 2:  Train Loss: 0.6426  Eval Loss: 0.6248   Accuracy: 0.6220\n",
      "Epoch 3:  Train Loss: 0.6337  Eval Loss: 0.6174   Accuracy: 0.6293\n",
      "Epoch 4:  Train Loss: 0.6272  Eval Loss: 0.6108   Accuracy: 0.6388\n",
      "Epoch 5:  Train Loss: 0.6212  Eval Loss: 0.6053   Accuracy: 0.6489\n",
      "Epoch 6:  Train Loss: 0.6171  Eval Loss: 0.6018   Accuracy: 0.6537\n",
      "Epoch 7:  Train Loss: 0.6148  Eval Loss: 0.6019   Accuracy: 0.6536\n",
      "Epoch 8:  Train Loss: 0.6123  Eval Loss: 0.6007   Accuracy: 0.6531\n",
      "Epoch 9:  Train Loss: 0.6111  Eval Loss: 0.5971   Accuracy: 0.6568\n",
      "Epoch 10:  Train Loss: 0.6100  Eval Loss: 0.5937   Accuracy: 0.6595\n",
      "Epoch 11:  Train Loss: 0.6087  Eval Loss: 0.5945   Accuracy: 0.6614\n",
      "Epoch 12:  Train Loss: 0.6088  Eval Loss: 0.5951   Accuracy: 0.6623\n",
      "Epoch 13:  Train Loss: 0.6074  Eval Loss: 0.5879   Accuracy: 0.6671\n",
      "Epoch 14:  Train Loss: 0.6052  Eval Loss: 0.5893   Accuracy: 0.6670\n",
      "Epoch 15:  Train Loss: 0.6046  Eval Loss: 0.5888   Accuracy: 0.6696\n",
      "Epoch 16:  Train Loss: 0.6037  Eval Loss: 0.5894   Accuracy: 0.6679\n",
      "Epoch 17:  Train Loss: 0.6029  Eval Loss: 0.5865   Accuracy: 0.6677\n",
      "Epoch 18:  Train Loss: 0.6032  Eval Loss: 0.5886   Accuracy: 0.6666\n",
      "Epoch 19:  Train Loss: 0.6028  Eval Loss: 0.5898   Accuracy: 0.6671\n",
      "Epoch 20:  Train Loss: 0.6026  Eval Loss: 0.5837   Accuracy: 0.6740\n",
      "Epoch 21:  Train Loss: 0.6015  Eval Loss: 0.5849   Accuracy: 0.6748\n",
      "Epoch 22:  Train Loss: 0.6007  Eval Loss: 0.5867   Accuracy: 0.6776\n",
      "Epoch 23:  Train Loss: 0.6000  Eval Loss: 0.5857   Accuracy: 0.6757\n",
      "Epoch 24:  Train Loss: 0.6004  Eval Loss: 0.5869   Accuracy: 0.6736\n",
      "Epoch 25:  Train Loss: 0.5994  Eval Loss: 0.5838   Accuracy: 0.6781\n",
      "Epoch 26:  Train Loss: 0.5993  Eval Loss: 0.5819   Accuracy: 0.6745\n",
      "Epoch 27:  Train Loss: 0.5988  Eval Loss: 0.5846   Accuracy: 0.6752\n",
      "Epoch 28:  Train Loss: 0.5981  Eval Loss: 0.5848   Accuracy: 0.6784\n",
      "Epoch 29:  Train Loss: 0.5972  Eval Loss: 0.5844   Accuracy: 0.6800\n",
      "Epoch 30:  Train Loss: 0.5965  Eval Loss: 0.5791   Accuracy: 0.6812\n",
      "Epoch 31:  Train Loss: 0.5966  Eval Loss: 0.5791   Accuracy: 0.6819\n",
      "Epoch 32:  Train Loss: 0.5969  Eval Loss: 0.5812   Accuracy: 0.6822\n",
      "Epoch 33:  Train Loss: 0.5956  Eval Loss: 0.5832   Accuracy: 0.6823\n",
      "Epoch 34:  Train Loss: 0.5960  Eval Loss: 0.5798   Accuracy: 0.6829\n",
      "Epoch 35:  Train Loss: 0.5959  Eval Loss: 0.5787   Accuracy: 0.6828\n",
      "Epoch 36:  Train Loss: 0.5952  Eval Loss: 0.5795   Accuracy: 0.6831\n",
      "Epoch 37:  Train Loss: 0.5958  Eval Loss: 0.5773   Accuracy: 0.6833\n",
      "Epoch 40:  Train Loss: 0.5958  Eval Loss: 0.5780   Accuracy: 0.6826\n",
      "Epoch 41:  Train Loss: 0.5961  Eval Loss: 0.5805   Accuracy: 0.6829\n",
      "Epoch 42:  Train Loss: 0.5960  Eval Loss: 0.5808   Accuracy: 0.6824\n",
      "Epoch 43:  Train Loss: 0.5958  Eval Loss: 0.5812   Accuracy: 0.6833\n",
      "Epoch 44:  Train Loss: 0.5952  Eval Loss: 0.5794   Accuracy: 0.6836\n",
      "Epoch 45:  Train Loss: 0.5953  Eval Loss: 0.5813   Accuracy: 0.6839\n",
      "Epoch 46:  Train Loss: 0.5947  Eval Loss: 0.5804   Accuracy: 0.6846\n",
      "Epoch 47:  Train Loss: 0.5947  Eval Loss: 0.5817   Accuracy: 0.6821\n",
      "Epoch 48:  Train Loss: 0.5938  Eval Loss: 0.5765   Accuracy: 0.6840\n",
      "Epoch 49:  Train Loss: 0.5939  Eval Loss: 0.5740   Accuracy: 0.6855\n",
      "Epoch 50:  Train Loss: 0.5946  Eval Loss: 0.5739   Accuracy: 0.6862\n",
      "    Final Results: {'eval_loss': 0.573861987888813, 'accuracy': 0.6862231016571853, 'best_accuracy': 0.6862231016571853}\n",
      "  Method: soft_prompt_lora\n",
      "Epoch 1:  Train Loss: 0.6678  Eval Loss: 0.6621   Accuracy: 0.6318\n",
      "Epoch 2:  Train Loss: 0.6678  Eval Loss: 0.6623   Accuracy: 0.6318\n",
      "Epoch 3:  Train Loss: 0.6680  Eval Loss: 0.6621   Accuracy: 0.6318\n",
      "Epoch 4:  Train Loss: 0.6679  Eval Loss: 0.6621   Accuracy: 0.6318\n",
      "Epoch 5:  Train Loss: 0.6677  Eval Loss: 0.6621   Accuracy: 0.6318\n",
      "Epoch 6:  Train Loss: 0.6679  Eval Loss: 0.6619   Accuracy: 0.6318\n",
      "Epoch 7:  Train Loss: 0.6676  Eval Loss: 0.6620   Accuracy: 0.6318\n",
      "Epoch 8:  Train Loss: 0.6677  Eval Loss: 0.6615   Accuracy: 0.6318\n",
      "Epoch 9:  Train Loss: 0.6669  Eval Loss: 0.6611   Accuracy: 0.6318\n",
      "Epoch 10:  Train Loss: 0.6664  Eval Loss: 0.6609   Accuracy: 0.6318\n",
      "Epoch 11:  Train Loss: 0.6663  Eval Loss: 0.6608   Accuracy: 0.6318\n",
      "Epoch 12:  Train Loss: 0.6661  Eval Loss: 0.6608   Accuracy: 0.6318\n",
      "Epoch 13:  Train Loss: 0.6663  Eval Loss: 0.6609   Accuracy: 0.6318\n",
      "Epoch 14:  Train Loss: 0.6664  Eval Loss: 0.6607   Accuracy: 0.6318\n",
      "Epoch 15:  Train Loss: 0.6665  Eval Loss: 0.6609   Accuracy: 0.6318\n",
      "Epoch 16:  Train Loss: 0.6665  Eval Loss: 0.6607   Accuracy: 0.6318\n",
      "Epoch 17:  Train Loss: 0.6659  Eval Loss: 0.6607   Accuracy: 0.6318\n",
      "Epoch 18:  Train Loss: 0.6659  Eval Loss: 0.6607   Accuracy: 0.6318\n",
      "Epoch 19:  Train Loss: 0.6662  Eval Loss: 0.6610   Accuracy: 0.6318\n",
      "Epoch 20:  Train Loss: 0.6663  Eval Loss: 0.6610   Accuracy: 0.6318\n",
      "Epoch 21:  Train Loss: 0.6659  Eval Loss: 0.6608   Accuracy: 0.6318\n",
      "Epoch 22:  Train Loss: 0.6659  Eval Loss: 0.6605   Accuracy: 0.6318\n",
      "Epoch 23:  Train Loss: 0.6652  Eval Loss: 0.6601   Accuracy: 0.6318\n",
      "Epoch 24:  Train Loss: 0.6650  Eval Loss: 0.6600   Accuracy: 0.6318\n",
      "Epoch 25:  Train Loss: 0.6646  Eval Loss: 0.6597   Accuracy: 0.6318\n",
      "Epoch 26:  Train Loss: 0.6647  Eval Loss: 0.6599   Accuracy: 0.6318\n",
      "Epoch 27:  Train Loss: 0.6646  Eval Loss: 0.6596   Accuracy: 0.6318\n",
      "Epoch 28:  Train Loss: 0.6644  Eval Loss: 0.6597   Accuracy: 0.6318\n",
      "Epoch 29:  Train Loss: 0.6644  Eval Loss: 0.6596   Accuracy: 0.6318\n",
      "Epoch 30:  Train Loss: 0.6640  Eval Loss: 0.6596   Accuracy: 0.6318\n",
      "Epoch 31:  Train Loss: 0.6638  Eval Loss: 0.6592   Accuracy: 0.6318\n",
      "Epoch 32:  Train Loss: 0.6634  Eval Loss: 0.6591   Accuracy: 0.6318\n",
      "Epoch 33:  Train Loss: 0.6632  Eval Loss: 0.6590   Accuracy: 0.6318\n",
      "Epoch 34:  Train Loss: 0.6631  Eval Loss: 0.6592   Accuracy: 0.6318\n",
      "Epoch 35:  Train Loss: 0.6637  Eval Loss: 0.6594   Accuracy: 0.6318\n",
      "Epoch 36:  Train Loss: 0.6636  Eval Loss: 0.6592   Accuracy: 0.6318\n",
      "Epoch 37:  Train Loss: 0.6633  Eval Loss: 0.6591   Accuracy: 0.6318\n",
      "Epoch 38:  Train Loss: 0.6634  Eval Loss: 0.6592   Accuracy: 0.6318\n",
      "Epoch 39:  Train Loss: 0.6635  Eval Loss: 0.6591   Accuracy: 0.6318\n",
      "Epoch 40:  Train Loss: 0.6630  Eval Loss: 0.6591   Accuracy: 0.6318\n",
      "Epoch 41:  Train Loss: 0.6632  Eval Loss: 0.6590   Accuracy: 0.6318\n",
      "Epoch 42:  Train Loss: 0.6629  Eval Loss: 0.6590   Accuracy: 0.6318\n",
      "Epoch 43:  Train Loss: 0.6628  Eval Loss: 0.6590   Accuracy: 0.6318\n",
      "Epoch 44:  Train Loss: 0.6630  Eval Loss: 0.6591   Accuracy: 0.6318\n",
      "Epoch 45:  Train Loss: 0.6630  Eval Loss: 0.6590   Accuracy: 0.6318\n",
      "Epoch 46:  Train Loss: 0.6629  Eval Loss: 0.6589   Accuracy: 0.6318\n",
      "Epoch 47:  Train Loss: 0.6631  Eval Loss: 0.6589   Accuracy: 0.6318\n",
      "Epoch 48:  Train Loss: 0.6627  Eval Loss: 0.6587   Accuracy: 0.6318\n",
      "Epoch 49:  Train Loss: 0.6623  Eval Loss: 0.6587   Accuracy: 0.6318\n",
      "Epoch 50:  Train Loss: 0.6624  Eval Loss: 0.6588   Accuracy: 0.6318\n",
      "    Final Results: {'eval_loss': 0.6587887331843376, 'accuracy': 0.6318327974276527, 'best_accuracy': 0.6318327974276527}\n",
      "  Method: prefix_lora\n",
      "Epoch 1:  Train Loss: 0.6769  Eval Loss: 0.6825   Accuracy: 0.5539\n",
      "Epoch 2:  Train Loss: 0.6766  Eval Loss: 0.6810   Accuracy: 0.5599\n",
      "Epoch 3:  Train Loss: 0.6758  Eval Loss: 0.6812   Accuracy: 0.5588\n",
      "Epoch 4:  Train Loss: 0.6754  Eval Loss: 0.6804   Accuracy: 0.5619\n",
      "Epoch 5:  Train Loss: 0.6753  Eval Loss: 0.6800   Accuracy: 0.5610\n",
      "Epoch 6:  Train Loss: 0.6748  Eval Loss: 0.6789   Accuracy: 0.5660\n",
      "Epoch 7:  Train Loss: 0.6745  Eval Loss: 0.6783   Accuracy: 0.5683\n",
      "Epoch 8:  Train Loss: 0.6734  Eval Loss: 0.6768   Accuracy: 0.5732\n",
      "Epoch 9:  Train Loss: 0.6716  Eval Loss: 0.6747   Accuracy: 0.5790\n",
      "Epoch 10:  Train Loss: 0.6709  Eval Loss: 0.6741   Accuracy: 0.5802\n",
      "Epoch 11:  Train Loss: 0.6698  Eval Loss: 0.6732   Accuracy: 0.5846\n",
      "Epoch 12:  Train Loss: 0.6697  Eval Loss: 0.6719   Accuracy: 0.5900\n",
      "Epoch 13:  Train Loss: 0.6683  Eval Loss: 0.6706   Accuracy: 0.5945\n",
      "Epoch 14:  Train Loss: 0.6664  Eval Loss: 0.6667   Accuracy: 0.6047\n",
      "Epoch 15:  Train Loss: 0.6649  Eval Loss: 0.6654   Accuracy: 0.6067\n",
      "Epoch 16:  Train Loss: 0.6631  Eval Loss: 0.6627   Accuracy: 0.6116\n",
      "Epoch 17:  Train Loss: 0.6616  Eval Loss: 0.6610   Accuracy: 0.6143\n",
      "Epoch 18:  Train Loss: 0.6605  Eval Loss: 0.6597   Accuracy: 0.6168\n",
      "Epoch 19:  Train Loss: 0.6594  Eval Loss: 0.6584   Accuracy: 0.6184\n",
      "Epoch 20:  Train Loss: 0.6580  Eval Loss: 0.6562   Accuracy: 0.6222\n",
      "Epoch 21:  Train Loss: 0.6569  Eval Loss: 0.6543   Accuracy: 0.6239\n",
      "Epoch 22:  Train Loss: 0.6556  Eval Loss: 0.6529   Accuracy: 0.6264\n",
      "Epoch 23:  Train Loss: 0.6547  Eval Loss: 0.6517   Accuracy: 0.6290\n",
      "Epoch 24:  Train Loss: 0.6533  Eval Loss: 0.6489   Accuracy: 0.6319\n",
      "Epoch 25:  Train Loss: 0.6521  Eval Loss: 0.6475   Accuracy: 0.6320\n",
      "Epoch 26:  Train Loss: 0.6510  Eval Loss: 0.6465   Accuracy: 0.6329\n",
      "Epoch 27:  Train Loss: 0.6505  Eval Loss: 0.6464   Accuracy: 0.6342\n",
      "Epoch 28:  Train Loss: 0.6504  Eval Loss: 0.6457   Accuracy: 0.6340\n",
      "Epoch 29:  Train Loss: 0.6491  Eval Loss: 0.6439   Accuracy: 0.6339\n",
      "Epoch 30:  Train Loss: 0.6483  Eval Loss: 0.6423   Accuracy: 0.6342\n",
      "Epoch 31:  Train Loss: 0.6478  Eval Loss: 0.6411   Accuracy: 0.6332\n",
      "Epoch 32:  Train Loss: 0.6477  Eval Loss: 0.6403   Accuracy: 0.6324\n",
      "Epoch 33:  Train Loss: 0.6474  Eval Loss: 0.6396   Accuracy: 0.6323\n",
      "Epoch 34:  Train Loss: 0.6469  Eval Loss: 0.6405   Accuracy: 0.6320\n",
      "Epoch 35:  Train Loss: 0.6468  Eval Loss: 0.6405   Accuracy: 0.6318\n",
      "Epoch 36:  Train Loss: 0.6469  Eval Loss: 0.6403   Accuracy: 0.6315\n",
      "Epoch 37:  Train Loss: 0.6472  Eval Loss: 0.6405   Accuracy: 0.6318\n",
      "Epoch 38:  Train Loss: 0.6469  Eval Loss: 0.6397   Accuracy: 0.6322\n",
      "Epoch 39:  Train Loss: 0.6462  Eval Loss: 0.6385   Accuracy: 0.6318\n",
      "Epoch 40:  Train Loss: 0.6457  Eval Loss: 0.6376   Accuracy: 0.6326\n",
      "Epoch 41:  Train Loss: 0.6454  Eval Loss: 0.6387   Accuracy: 0.6321\n",
      "Epoch 42:  Train Loss: 0.6458  Eval Loss: 0.6397   Accuracy: 0.6319\n",
      "Epoch 43:  Train Loss: 0.6461  Eval Loss: 0.6402   Accuracy: 0.6324\n",
      "Epoch 44:  Train Loss: 0.6463  Eval Loss: 0.6388   Accuracy: 0.6327\n",
      "Epoch 45:  Train Loss: 0.6451  Eval Loss: 0.6392   Accuracy: 0.6335\n",
      "Epoch 46:  Train Loss: 0.6449  Eval Loss: 0.6374   Accuracy: 0.6330\n",
      "Epoch 47:  Train Loss: 0.6444  Eval Loss: 0.6377   Accuracy: 0.6339\n",
      "Epoch 48:  Train Loss: 0.6437  Eval Loss: 0.6353   Accuracy: 0.6330\n",
      "Epoch 49:  Train Loss: 0.6428  Eval Loss: 0.6345   Accuracy: 0.6339\n",
      "Epoch 50:  Train Loss: 0.6426  Eval Loss: 0.6343   Accuracy: 0.6334\n",
      "    Final Results: {'eval_loss': 0.6342826247215271, 'accuracy': 0.6334405144694534, 'best_accuracy': 0.6342072718278506}\n",
      "==================================================\n",
      "\n",
      "Results for qqp:\n",
      "  Method: soft_prompt, Accuracy: 0.6318, Loss: 0.6526\n",
      "  Method: prefix, Accuracy: 0.6630, Loss: 0.6038\n",
      "  Method: full_fine_tuning, Accuracy: 0.6679, Loss: 0.6018\n",
      "  Method: lora, Accuracy: 0.6932, Loss: 0.5500\n",
      "  Method: ia3, Accuracy: 0.6870, Loss: 0.5709\n",
      "  Method: single_layer_fine_tuning, Accuracy: 0.6862, Loss: 0.5739\n",
      "  Method: soft_prompt_lora, Accuracy: 0.6318, Loss: 0.6588\n",
      "  Method: prefix_lora, Accuracy: 0.6334, Loss: 0.6343\n",
      "\n",
      "Results have been appended to peft_experiment_results.txt\n"
     ]
    }
   ],
   "source": [
    "results = run_peft_experiments(epsilon=0,dataset=['qqp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf886c6f-34c2-404f-b4fa-4167a844b848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
