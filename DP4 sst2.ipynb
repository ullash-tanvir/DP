{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be948b88-1b5e-460d-83be-b204abf2912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tislam/.conda/envs/tfgpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tislam/.conda/envs/tfgpu/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer, Trainer, \n",
    "                        TrainingArguments, DataCollatorWithPadding, default_data_collator)\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    PromptTuningConfig,\n",
    "    PrefixTuningConfig,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    TaskType,\n",
    ")\n",
    "from opacus.privacy_engine import GradSampleModule\n",
    "from opacus.optimizers import DPOptimizer\n",
    "from opacus import PrivacyEngine\n",
    "from transformers import DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c3d767-904e-4c99-9087-8c03512ea5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44f61fd-2f3e-401b-aa36-0a00eecdb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "logging.getLogger(\"torch\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86705d8e-5f20-424a-b097-4b4d81416cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the model and tokenizer\n",
    "def setup_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "        print(f\"Using {n_gpu} GPU(s)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        n_gpu = 0\n",
    "        print(\"Using CPU\")\n",
    "    return device, n_gpu\n",
    "\n",
    "def load_model_and_tokenizer(model_name, num_labels):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=num_labels,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to prepare the dataset\n",
    "def prepare_dataset(dataset_name, tokenizer):\n",
    "    # Load the dataset from Hugging Face Datasets\n",
    "    dataset = load_dataset('glue', dataset_name)\n",
    "\n",
    "    # Tokenization function depending on the dataset\n",
    "    def tokenize_function(examples):\n",
    "        if dataset_name.lower() == \"sst2\":\n",
    "            return tokenizer(\n",
    "                examples[\"sentence\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"qqp\":\n",
    "            return tokenizer(\n",
    "                examples[\"question1\"],\n",
    "                examples[\"question2\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"qnli\":\n",
    "            return tokenizer(\n",
    "                examples[\"question\"],\n",
    "                examples[\"sentence\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"mnli\":\n",
    "            return tokenizer(\n",
    "                examples[\"premise\"],\n",
    "                examples[\"hypothesis\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Dataset {dataset_name} is not supported.\")\n",
    "\n",
    "    # Determine which columns to remove\n",
    "    columns_to_remove = set(dataset[\"train\"].column_names) - {\"label\"}\n",
    "\n",
    "    # Apply the tokenization to the dataset\n",
    "    tokenized_datasets = dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=list(columns_to_remove)  # Remove all columns except 'label'\n",
    "    )\n",
    "\n",
    "    # Rename 'label' to 'labels'\n",
    "    tokenized_datasets = tokenized_datasets.map(\n",
    "        lambda examples: {\"labels\": examples[\"label\"]},\n",
    "        remove_columns=[\"label\"]\n",
    "    )\n",
    "\n",
    "    # Convert the datasets to PyTorch tensors\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "    return tokenized_datasets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to compute metrics during evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Get the predictions by taking the argmax over logits\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Compute accuracy by comparing predictions and labels\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    # Return the accuracy inside a dictionary\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Function to get the PEFT configuration based on the method\n",
    "def get_peft_config(method):\n",
    "    if method == \"soft_prompt\":\n",
    "        peft_config = PromptTuningConfig(\n",
    "            task_type=TaskType.SEQ_CLS, num_virtual_tokens=20\n",
    "        )\n",
    "    elif method == \"prefix\":\n",
    "        peft_config = PrefixTuningConfig(\n",
    "            task_type=TaskType.SEQ_CLS, num_virtual_tokens=20\n",
    "        )\n",
    "    elif method == \"lora\":\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "        )\n",
    "    elif method == \"ia3\":\n",
    "        peft_config = IA3Config(task_type=TaskType.SEQ_CLS)\n",
    "    elif method == \"soft_prompt_lora\":\n",
    "        # Combine Prompt Tuning and LoRA\n",
    "        peft_config = [\n",
    "            PromptTuningConfig(task_type=TaskType.SEQ_CLS, num_virtual_tokens=20),\n",
    "            LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "            ),\n",
    "        ]\n",
    "    elif method == \"prefix_lora\":\n",
    "        # Combine Prefix Tuning and LoRA\n",
    "        peft_config = [\n",
    "            PrefixTuningConfig(task_type=TaskType.SEQ_CLS, num_virtual_tokens=20),\n",
    "            LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "            ),\n",
    "        ]\n",
    "    else:\n",
    "        peft_config = None\n",
    "    return peft_config\n",
    "\n",
    "def get_validation_dataset(tokenized_datasets):\n",
    "    # Check for common validation set names and return the first that exists\n",
    "    for val_name in [\"validation\", \"validation_matched\", \"validation_mismatched\"]:\n",
    "        if val_name in tokenized_datasets:\n",
    "            return tokenized_datasets[val_name]\n",
    "    raise ValueError(\"No valid validation set found.\")\n",
    "\n",
    "\n",
    "def create_dp_optimizer(model, learning_rate, epsilon, delta, expected_batch_size):\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    \n",
    "    # Wrap the model with GradSampleModule\n",
    "    model = GradSampleModule(model)\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Make optimizer differentially private\n",
    "    dp_optimizer = DPOptimizer(\n",
    "        optimizer=optimizer,\n",
    "        noise_multiplier=1.3,\n",
    "        max_grad_norm=1.0,\n",
    "        expected_batch_size=expected_batch_size\n",
    "    )\n",
    "\n",
    "    return model, dp_optimizer\n",
    "\n",
    "def compute_dp_noise_scale(epsilon, delta, sample_rate, steps):\n",
    "    \"\"\"Compute noise scale for DP-SGD.\"\"\"\n",
    "    return np.sqrt(2 * np.log(1.25 / delta)) / (epsilon * np.sqrt(steps * sample_rate))\n",
    "\n",
    "def add_noise_to_grads(model, noise_scale, max_grad_norm):\n",
    "    \"\"\"Add noise to gradients for Differential Privacy.\"\"\"\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** 0.5\n",
    "\n",
    "    clip_coef = max_grad_norm / (total_norm + 1e-6)\n",
    "    clip_coef = min(clip_coef, 1.0)  # Clamp without using torch.clamp\n",
    "\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            p.grad.data.mul_(clip_coef)\n",
    "            noise = torch.randn_like(p.grad) * noise_scale * max_grad_norm\n",
    "            p.grad.data.add_(noise)\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_results_to_file(results, epsilon):\n",
    "    filename = \"peft_experiment_results.txt\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Read existing content\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            existing_content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        existing_content = \"\"\n",
    "    \n",
    "    # Prepare new content\n",
    "    new_content = f\"\\n\\n--- Experiment Results ({timestamp}) ---\\n\"\n",
    "    new_content += f\"Epsilon: {epsilon}\\n\" if epsilon is not None else \"No Differential Privacy\\n\"\n",
    "    new_content += json.dumps(results, indent=2)\n",
    "    \n",
    "    # Combine existing and new content\n",
    "    updated_content = existing_content + new_content\n",
    "    \n",
    "    # Write updated content back to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(updated_content)\n",
    "    \n",
    "    print(f\"\\nResults have been appended to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe3d190-183c-49b9-8923-6d18d7cb158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_peft_experiments(dataset, epsilon=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model_name = \"prajjwal1/bert-tiny\"\n",
    "    # datasets = [\"sst2\", \"qnli\", \"qqp\", \"mnli\"]\n",
    "    methods = [\n",
    "        \"soft_prompt\",\n",
    "        \"prefix\",\n",
    "        \"full_fine_tuning\",\n",
    "        \"lora\",\n",
    "        \"ia3\",\n",
    "        \"single_layer_fine_tuning\",\n",
    "        \"soft_prompt_lora\",\n",
    "        \"prefix_lora\",\n",
    "    ]\n",
    "    \n",
    "    # Dataset-specific parameters\n",
    "    dataset_params = {\n",
    "        \"sst2\": {\"lambda\": 1e-5, \"noise_multiplier\": 0.92, \"num_labels\": 2},\n",
    "        \"qnli\": {\"lambda\": 1e-5, \"noise_multiplier\": 0.83, \"num_labels\": 2},\n",
    "        \"qqp\": {\"lambda\": 1e-6, \"noise_multiplier\": 0.66, \"num_labels\": 2},\n",
    "        \"mnli\": {\"lambda\": 1e-6, \"noise_multiplier\": 0.65, \"num_labels\": 3},\n",
    "    }\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    for dataset_name in dataset:\n",
    "        print(f\"Processing dataset: {dataset_name}\")\n",
    "        \n",
    "        params = dataset_params[dataset_name]\n",
    "        num_labels = params[\"num_labels\"]\n",
    "        \n",
    "        model, tokenizer = load_model_and_tokenizer(model_name, num_labels)\n",
    "        tokenized_dataset = prepare_dataset(dataset_name, tokenizer)\n",
    "        \n",
    "        results_dict[dataset_name] = {}\n",
    "        \n",
    "        for method in methods:\n",
    "            print(f\"  Method: {method}\")\n",
    "            model, tokenizer = load_model_and_tokenizer(model_name, num_labels)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            if method == \"full_fine_tuning\":\n",
    "                peft_model = model\n",
    "            elif method == \"single_layer_fine_tuning\":\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "                model.classifier = torch.nn.Linear(model.config.hidden_size, num_labels).to(device)\n",
    "                peft_model = model\n",
    "            else:\n",
    "                peft_config = get_peft_config(method)\n",
    "                if isinstance(peft_config, list):\n",
    "                    peft_model = model\n",
    "                    for config in peft_config:\n",
    "                        peft_model = get_peft_model(peft_model, config)\n",
    "                else:\n",
    "                    peft_model = get_peft_model(model, peft_config)\n",
    "            peft_model = peft_model.to(device)\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=f\"./results/{dataset_name}_{method}\",\n",
    "                num_train_epochs=50,\n",
    "                per_device_train_batch_size=1024,\n",
    "                per_device_eval_batch_size=1024,\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                save_strategy=\"epoch\",\n",
    "                logging_dir=f\"./logs/{dataset_name}_{method}\",\n",
    "                logging_steps=100,\n",
    "                learning_rate=5e-4,\n",
    "                load_best_model_at_end=False,\n",
    "                save_total_limit=1,\n",
    "            )\n",
    "            \n",
    "            train_dataloader = torch.utils.data.DataLoader(\n",
    "                tokenized_dataset[\"train\"],\n",
    "                batch_size=training_args.per_device_train_batch_size,\n",
    "                shuffle=True,\n",
    "                collate_fn=default_data_collator,\n",
    "            )\n",
    "            \n",
    "            eval_dataloader = torch.utils.data.DataLoader(\n",
    "                get_validation_dataset(tokenized_dataset),\n",
    "                batch_size=training_args.per_device_eval_batch_size,\n",
    "                collate_fn=default_data_collator,\n",
    "            )\n",
    "            \n",
    "            if epsilon is not None:\n",
    "                results = train_with_dp(\n",
    "                    peft_model=peft_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    eval_dataloader=eval_dataloader,\n",
    "                    device=device,\n",
    "                    epsilon=epsilon,\n",
    "                    delta=params[\"lambda\"],\n",
    "                    noise_multiplier=params[\"noise_multiplier\"],\n",
    "                    epochs=int(training_args.num_train_epochs),\n",
    "                    batch_size=training_args.per_device_train_batch_size,\n",
    "                    max_grad_norm=1.0,\n",
    "                    learning_rate=training_args.learning_rate,\n",
    "                    weight_decay=1e-2\n",
    "                )\n",
    "            else:\n",
    "                # Train without differential privacy\n",
    "                results = train_without_dp(\n",
    "                    peft_model=peft_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    eval_dataloader=eval_dataloader,\n",
    "                    device=device,\n",
    "                    epochs=int(training_args.num_train_epochs),\n",
    "                    learning_rate=training_args.learning_rate,\n",
    "                    weight_decay=1e-2\n",
    "                )\n",
    "            \n",
    "            results_dict[dataset_name][method] = results\n",
    "            print(f\"    Final Results: {results}\")\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"=\"*50)\n",
    "    for dataset_name in dataset:\n",
    "        print(f\"\\nResults for {dataset_name}:\")\n",
    "        for method, result in results_dict[dataset_name].items():\n",
    "            accuracy = result.get(\"accuracy\", \"N/A\")\n",
    "            loss = result.get(\"eval_loss\", \"N/A\")\n",
    "            print(f\"  Method: {method}, Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    # Save results to file\n",
    "    save_results_to_file(results_dict, epsilon)\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "def train_with_dp(peft_model, train_dataloader, eval_dataloader, device, epsilon, delta, noise_multiplier, epochs, batch_size, max_grad_norm, learning_rate, weight_decay):\n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        peft_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = peft_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(peft_model.parameters(), max_grad_norm)\n",
    "            \n",
    "            # Add noise to gradients\n",
    "            for param in peft_model.parameters():\n",
    "                if param.requires_grad and param.grad is not None:\n",
    "                    noise = torch.randn_like(param.grad) * noise_multiplier * max_grad_norm\n",
    "                    param.grad.add_(noise)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_results = evaluate(peft_model, eval_dataloader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:  Train Loss: {avg_train_loss:.4f}  Eval Loss: {eval_results['eval_loss']:.4f}   Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "\n",
    "        \n",
    "        if eval_results['accuracy'] > best_accuracy:\n",
    "            best_accuracy = eval_results['accuracy']\n",
    "            # print(f\"  New best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    return {\"eval_loss\": eval_results['eval_loss'], \"accuracy\": eval_results['accuracy'], \"best_accuracy\": best_accuracy}\n",
    "\n",
    "def train_without_dp(peft_model, train_dataloader, eval_dataloader, device, epochs, learning_rate, weight_decay):\n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        peft_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = peft_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_results = evaluate(peft_model, eval_dataloader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:   Train Loss: {avg_train_loss:.4f}   Eval Loss: {eval_results['eval_loss']:.4f}   Accuracy: {eval_results['accuracy']:.4f} \")\n",
    "\n",
    "        \n",
    "        if eval_results['accuracy'] > best_accuracy:\n",
    "            best_accuracy = eval_results['accuracy']\n",
    "            # print(f\"  New best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    return {\"eval_loss\": eval_results['eval_loss'], \"accuracy\": eval_results['accuracy'], \"best_accuracy\": best_accuracy}\n",
    "\n",
    "def evaluate(model, eval_dataloader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_steps = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            eval_loss += outputs.loss.item()\n",
    "            eval_steps += 1\n",
    "            all_preds.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "    \n",
    "    eval_loss = eval_loss / eval_steps\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    return {\"eval_loss\": eval_loss, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd36835-b0a4-47ee-ac08-150a0b0b62d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing dataset: sst2\n",
      "  Method: soft_prompt\n",
      "Epoch 1:  Train Loss: 0.6957  Eval Loss: 0.6963   Accuracy: 0.5080\n",
      "Epoch 2:  Train Loss: 0.6891  Eval Loss: 0.6972   Accuracy: 0.5092\n",
      "Epoch 3:  Train Loss: 0.6882  Eval Loss: 0.6964   Accuracy: 0.5092\n",
      "Epoch 4:  Train Loss: 0.6874  Eval Loss: 0.6984   Accuracy: 0.5092\n",
      "Epoch 5:  Train Loss: 0.6866  Eval Loss: 0.6996   Accuracy: 0.5092\n",
      "Epoch 6:  Train Loss: 0.6868  Eval Loss: 0.6964   Accuracy: 0.5092\n",
      "Epoch 7:  Train Loss: 0.6867  Eval Loss: 0.6992   Accuracy: 0.5092\n",
      "Epoch 8:  Train Loss: 0.6863  Eval Loss: 0.6996   Accuracy: 0.5092\n",
      "Epoch 9:  Train Loss: 0.6860  Eval Loss: 0.6967   Accuracy: 0.5092\n",
      "Epoch 10:  Train Loss: 0.6856  Eval Loss: 0.6956   Accuracy: 0.5092\n",
      "Epoch 11:  Train Loss: 0.6861  Eval Loss: 0.6959   Accuracy: 0.5092\n",
      "Epoch 12:  Train Loss: 0.6861  Eval Loss: 0.6960   Accuracy: 0.5092\n",
      "Epoch 13:  Train Loss: 0.6857  Eval Loss: 0.6959   Accuracy: 0.5092\n",
      "Epoch 14:  Train Loss: 0.6852  Eval Loss: 0.6986   Accuracy: 0.5092\n",
      "Epoch 15:  Train Loss: 0.6860  Eval Loss: 0.6961   Accuracy: 0.5092\n",
      "Epoch 16:  Train Loss: 0.6858  Eval Loss: 0.6962   Accuracy: 0.5092\n",
      "Epoch 17:  Train Loss: 0.6855  Eval Loss: 0.6994   Accuracy: 0.5092\n",
      "Epoch 18:  Train Loss: 0.6854  Eval Loss: 0.6973   Accuracy: 0.5092\n",
      "Epoch 19:  Train Loss: 0.6854  Eval Loss: 0.6973   Accuracy: 0.5092\n",
      "Epoch 20:  Train Loss: 0.6848  Eval Loss: 0.6967   Accuracy: 0.5092\n",
      "Epoch 21:  Train Loss: 0.6849  Eval Loss: 0.6955   Accuracy: 0.5092\n",
      "Epoch 22:  Train Loss: 0.6851  Eval Loss: 0.6960   Accuracy: 0.5080\n",
      "Epoch 23:  Train Loss: 0.6843  Eval Loss: 0.6998   Accuracy: 0.5092\n",
      "Epoch 24:  Train Loss: 0.6845  Eval Loss: 0.6977   Accuracy: 0.5092\n",
      "Epoch 25:  Train Loss: 0.6833  Eval Loss: 0.6978   Accuracy: 0.5092\n",
      "Epoch 26:  Train Loss: 0.6840  Eval Loss: 0.6960   Accuracy: 0.5080\n",
      "Epoch 27:  Train Loss: 0.6832  Eval Loss: 0.6955   Accuracy: 0.5080\n",
      "Epoch 28:  Train Loss: 0.6827  Eval Loss: 0.6974   Accuracy: 0.5092\n",
      "Epoch 29:  Train Loss: 0.6821  Eval Loss: 0.6954   Accuracy: 0.5092\n",
      "Epoch 30:  Train Loss: 0.6832  Eval Loss: 0.6970   Accuracy: 0.5092\n",
      "Epoch 31:  Train Loss: 0.6820  Eval Loss: 0.6948   Accuracy: 0.5092\n",
      "Epoch 32:  Train Loss: 0.6829  Eval Loss: 0.6920   Accuracy: 0.5103\n",
      "Epoch 33:  Train Loss: 0.6830  Eval Loss: 0.6926   Accuracy: 0.5092\n",
      "Epoch 34:  Train Loss: 0.6826  Eval Loss: 0.6925   Accuracy: 0.5126\n",
      "Epoch 35:  Train Loss: 0.6820  Eval Loss: 0.6939   Accuracy: 0.5103\n",
      "Epoch 36:  Train Loss: 0.6818  Eval Loss: 0.6953   Accuracy: 0.5103\n",
      "Epoch 37:  Train Loss: 0.6812  Eval Loss: 0.6929   Accuracy: 0.5115\n",
      "Epoch 38:  Train Loss: 0.6805  Eval Loss: 0.6930   Accuracy: 0.5103\n",
      "Epoch 39:  Train Loss: 0.6808  Eval Loss: 0.6924   Accuracy: 0.5126\n",
      "Epoch 40:  Train Loss: 0.6801  Eval Loss: 0.6946   Accuracy: 0.5092\n",
      "Epoch 41:  Train Loss: 0.6797  Eval Loss: 0.6908   Accuracy: 0.5138\n",
      "Epoch 42:  Train Loss: 0.6795  Eval Loss: 0.6956   Accuracy: 0.5103\n",
      "Epoch 43:  Train Loss: 0.6802  Eval Loss: 0.6923   Accuracy: 0.5103\n",
      "Epoch 44:  Train Loss: 0.6802  Eval Loss: 0.6913   Accuracy: 0.5115\n",
      "Epoch 45:  Train Loss: 0.6788  Eval Loss: 0.6901   Accuracy: 0.5126\n",
      "Epoch 46:  Train Loss: 0.6795  Eval Loss: 0.6917   Accuracy: 0.5103\n",
      "Epoch 47:  Train Loss: 0.6788  Eval Loss: 0.6920   Accuracy: 0.5103\n",
      "Epoch 48:  Train Loss: 0.6792  Eval Loss: 0.6901   Accuracy: 0.5126\n",
      "Epoch 49:  Train Loss: 0.6787  Eval Loss: 0.6923   Accuracy: 0.5126\n",
      "Epoch 50:  Train Loss: 0.6789  Eval Loss: 0.6915   Accuracy: 0.5126\n",
      "    Final Results: {'eval_loss': 0.6914567351341248, 'accuracy': 0.5126146788990825, 'best_accuracy': 0.5137614678899083}\n",
      "  Method: prefix\n",
      "Epoch 1:  Train Loss: 0.6921  Eval Loss: 0.6911   Accuracy: 0.5241\n",
      "Epoch 2:  Train Loss: 0.6865  Eval Loss: 0.6924   Accuracy: 0.5138\n",
      "Epoch 3:  Train Loss: 0.6859  Eval Loss: 0.6945   Accuracy: 0.5138\n",
      "Epoch 4:  Train Loss: 0.6849  Eval Loss: 0.6902   Accuracy: 0.5241\n",
      "Epoch 5:  Train Loss: 0.6841  Eval Loss: 0.6891   Accuracy: 0.5298\n",
      "Epoch 6:  Train Loss: 0.6840  Eval Loss: 0.6911   Accuracy: 0.5206\n",
      "Epoch 7:  Train Loss: 0.6838  Eval Loss: 0.6897   Accuracy: 0.5252\n",
      "Epoch 8:  Train Loss: 0.6838  Eval Loss: 0.6878   Accuracy: 0.5378\n",
      "Epoch 9:  Train Loss: 0.6833  Eval Loss: 0.6864   Accuracy: 0.5528\n",
      "Epoch 10:  Train Loss: 0.6829  Eval Loss: 0.6863   Accuracy: 0.5596\n",
      "Epoch 11:  Train Loss: 0.6833  Eval Loss: 0.6876   Accuracy: 0.5401\n",
      "Epoch 12:  Train Loss: 0.6823  Eval Loss: 0.6865   Accuracy: 0.5436\n",
      "Epoch 13:  Train Loss: 0.6817  Eval Loss: 0.6868   Accuracy: 0.5424\n",
      "Epoch 14:  Train Loss: 0.6812  Eval Loss: 0.6858   Accuracy: 0.5413\n",
      "Epoch 15:  Train Loss: 0.6801  Eval Loss: 0.6820   Accuracy: 0.5631\n",
      "Epoch 16:  Train Loss: 0.6794  Eval Loss: 0.6811   Accuracy: 0.5631\n",
      "Epoch 17:  Train Loss: 0.6792  Eval Loss: 0.6816   Accuracy: 0.5631\n",
      "Epoch 18:  Train Loss: 0.6787  Eval Loss: 0.6805   Accuracy: 0.5631\n",
      "Epoch 19:  Train Loss: 0.6785  Eval Loss: 0.6803   Accuracy: 0.5665\n",
      "Epoch 20:  Train Loss: 0.6789  Eval Loss: 0.6813   Accuracy: 0.5665\n",
      "Epoch 21:  Train Loss: 0.6776  Eval Loss: 0.6806   Accuracy: 0.5700\n",
      "Epoch 22:  Train Loss: 0.6772  Eval Loss: 0.6795   Accuracy: 0.5688\n",
      "Epoch 23:  Train Loss: 0.6769  Eval Loss: 0.6780   Accuracy: 0.5642\n",
      "Epoch 24:  Train Loss: 0.6767  Eval Loss: 0.6775   Accuracy: 0.5642\n",
      "Epoch 25:  Train Loss: 0.6765  Eval Loss: 0.6785   Accuracy: 0.5654\n",
      "Epoch 26:  Train Loss: 0.6767  Eval Loss: 0.6791   Accuracy: 0.5642\n",
      "Epoch 27:  Train Loss: 0.6768  Eval Loss: 0.6768   Accuracy: 0.5711\n",
      "Epoch 28:  Train Loss: 0.6746  Eval Loss: 0.6766   Accuracy: 0.5734\n",
      "Epoch 29:  Train Loss: 0.6747  Eval Loss: 0.6756   Accuracy: 0.5722\n",
      "Epoch 30:  Train Loss: 0.6738  Eval Loss: 0.6762   Accuracy: 0.5654\n",
      "Epoch 31:  Train Loss: 0.6742  Eval Loss: 0.6778   Accuracy: 0.5642\n",
      "Epoch 32:  Train Loss: 0.6742  Eval Loss: 0.6748   Accuracy: 0.5734\n",
      "Epoch 33:  Train Loss: 0.6739  Eval Loss: 0.6734   Accuracy: 0.5722\n",
      "Epoch 34:  Train Loss: 0.6736  Eval Loss: 0.6746   Accuracy: 0.5700\n",
      "Epoch 35:  Train Loss: 0.6733  Eval Loss: 0.6730   Accuracy: 0.5768\n",
      "Epoch 36:  Train Loss: 0.6733  Eval Loss: 0.6738   Accuracy: 0.5780\n",
      "Epoch 37:  Train Loss: 0.6728  Eval Loss: 0.6721   Accuracy: 0.5814\n",
      "Epoch 38:  Train Loss: 0.6731  Eval Loss: 0.6718   Accuracy: 0.5803\n",
      "Epoch 39:  Train Loss: 0.6721  Eval Loss: 0.6717   Accuracy: 0.5860\n",
      "Epoch 40:  Train Loss: 0.6723  Eval Loss: 0.6715   Accuracy: 0.5906\n",
      "Epoch 41:  Train Loss: 0.6724  Eval Loss: 0.6718   Accuracy: 0.5872\n",
      "Epoch 42:  Train Loss: 0.6716  Eval Loss: 0.6710   Accuracy: 0.5883\n",
      "Epoch 43:  Train Loss: 0.6714  Eval Loss: 0.6714   Accuracy: 0.5768\n",
      "Epoch 44:  Train Loss: 0.6723  Eval Loss: 0.6716   Accuracy: 0.5826\n",
      "Epoch 45:  Train Loss: 0.6720  Eval Loss: 0.6721   Accuracy: 0.5803\n",
      "Epoch 46:  Train Loss: 0.6724  Eval Loss: 0.6710   Accuracy: 0.5872\n",
      "Epoch 47:  Train Loss: 0.6733  Eval Loss: 0.6720   Accuracy: 0.5860\n",
      "Epoch 48:  Train Loss: 0.6724  Eval Loss: 0.6718   Accuracy: 0.5837\n",
      "Epoch 49:  Train Loss: 0.6713  Eval Loss: 0.6713   Accuracy: 0.5872\n",
      "Epoch 50:  Train Loss: 0.6713  Eval Loss: 0.6682   Accuracy: 0.5894\n",
      "    Final Results: {'eval_loss': 0.6681929230690002, 'accuracy': 0.5894495412844036, 'best_accuracy': 0.5905963302752294}\n",
      "  Method: full_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.6971  Eval Loss: 0.6929   Accuracy: 0.5115\n",
      "Epoch 2:  Train Loss: 0.6884  Eval Loss: 0.6932   Accuracy: 0.5138\n",
      "Epoch 3:  Train Loss: 0.6854  Eval Loss: 0.6920   Accuracy: 0.5115\n",
      "Epoch 4:  Train Loss: 0.6833  Eval Loss: 0.6893   Accuracy: 0.5172\n",
      "Epoch 5:  Train Loss: 0.6823  Eval Loss: 0.6881   Accuracy: 0.5138\n",
      "Epoch 6:  Train Loss: 0.6805  Eval Loss: 0.6889   Accuracy: 0.5115\n",
      "Epoch 7:  Train Loss: 0.6792  Eval Loss: 0.6870   Accuracy: 0.5138\n",
      "Epoch 8:  Train Loss: 0.6779  Eval Loss: 0.6827   Accuracy: 0.5378\n",
      "Epoch 9:  Train Loss: 0.6770  Eval Loss: 0.6845   Accuracy: 0.5161\n",
      "Epoch 10:  Train Loss: 0.6757  Eval Loss: 0.6796   Accuracy: 0.5447\n",
      "Epoch 11:  Train Loss: 0.6738  Eval Loss: 0.6792   Accuracy: 0.5356\n",
      "Epoch 12:  Train Loss: 0.6725  Eval Loss: 0.6758   Accuracy: 0.5745\n",
      "Epoch 13:  Train Loss: 0.6714  Eval Loss: 0.6752   Accuracy: 0.5826\n",
      "Epoch 14:  Train Loss: 0.6724  Eval Loss: 0.6740   Accuracy: 0.6181\n",
      "Epoch 15:  Train Loss: 0.6710  Eval Loss: 0.6776   Accuracy: 0.5528\n",
      "Epoch 16:  Train Loss: 0.6709  Eval Loss: 0.6768   Accuracy: 0.5401\n",
      "Epoch 17:  Train Loss: 0.6699  Eval Loss: 0.6749   Accuracy: 0.5608\n",
      "Epoch 18:  Train Loss: 0.6684  Eval Loss: 0.6750   Accuracy: 0.5528\n",
      "Epoch 19:  Train Loss: 0.6692  Eval Loss: 0.6742   Accuracy: 0.5528\n",
      "Epoch 20:  Train Loss: 0.6681  Eval Loss: 0.6751   Accuracy: 0.5459\n",
      "Epoch 21:  Train Loss: 0.6673  Eval Loss: 0.6733   Accuracy: 0.5757\n",
      "Epoch 22:  Train Loss: 0.6663  Eval Loss: 0.6713   Accuracy: 0.5745\n",
      "Epoch 23:  Train Loss: 0.6643  Eval Loss: 0.6704   Accuracy: 0.5791\n",
      "Epoch 24:  Train Loss: 0.6638  Eval Loss: 0.6692   Accuracy: 0.5860\n",
      "Epoch 25:  Train Loss: 0.6625  Eval Loss: 0.6663   Accuracy: 0.6067\n",
      "Epoch 26:  Train Loss: 0.6604  Eval Loss: 0.6663   Accuracy: 0.6021\n",
      "Epoch 27:  Train Loss: 0.6595  Eval Loss: 0.6661   Accuracy: 0.5860\n",
      "Epoch 28:  Train Loss: 0.6586  Eval Loss: 0.6661   Accuracy: 0.5837\n",
      "Epoch 29:  Train Loss: 0.6584  Eval Loss: 0.6614   Accuracy: 0.6261\n",
      "Epoch 30:  Train Loss: 0.6570  Eval Loss: 0.6617   Accuracy: 0.6181\n",
      "Epoch 31:  Train Loss: 0.6555  Eval Loss: 0.6606   Accuracy: 0.6089\n",
      "Epoch 32:  Train Loss: 0.6554  Eval Loss: 0.6608   Accuracy: 0.6273\n",
      "Epoch 33:  Train Loss: 0.6553  Eval Loss: 0.6610   Accuracy: 0.6239\n",
      "Epoch 34:  Train Loss: 0.6553  Eval Loss: 0.6601   Accuracy: 0.6193\n",
      "Epoch 35:  Train Loss: 0.6532  Eval Loss: 0.6599   Accuracy: 0.6227\n",
      "Epoch 36:  Train Loss: 0.6551  Eval Loss: 0.6573   Accuracy: 0.6307\n",
      "Epoch 37:  Train Loss: 0.6540  Eval Loss: 0.6571   Accuracy: 0.6445\n",
      "Epoch 38:  Train Loss: 0.6516  Eval Loss: 0.6569   Accuracy: 0.6388\n",
      "Epoch 39:  Train Loss: 0.6498  Eval Loss: 0.6553   Accuracy: 0.6284\n",
      "Epoch 40:  Train Loss: 0.6485  Eval Loss: 0.6555   Accuracy: 0.6250\n",
      "Epoch 41:  Train Loss: 0.6477  Eval Loss: 0.6533   Accuracy: 0.6319\n",
      "Epoch 42:  Train Loss: 0.6455  Eval Loss: 0.6552   Accuracy: 0.6284\n",
      "Epoch 43:  Train Loss: 0.6454  Eval Loss: 0.6541   Accuracy: 0.6319\n",
      "Epoch 44:  Train Loss: 0.6433  Eval Loss: 0.6534   Accuracy: 0.6296\n",
      "Epoch 45:  Train Loss: 0.6432  Eval Loss: 0.6510   Accuracy: 0.6411\n",
      "Epoch 46:  Train Loss: 0.6406  Eval Loss: 0.6471   Accuracy: 0.6399\n",
      "Epoch 47:  Train Loss: 0.6390  Eval Loss: 0.6441   Accuracy: 0.6399\n",
      "Epoch 48:  Train Loss: 0.6368  Eval Loss: 0.6414   Accuracy: 0.6365\n",
      "Epoch 49:  Train Loss: 0.6379  Eval Loss: 0.6416   Accuracy: 0.6388\n",
      "Epoch 50:  Train Loss: 0.6379  Eval Loss: 0.6411   Accuracy: 0.6468\n",
      "    Final Results: {'eval_loss': 0.6411211490631104, 'accuracy': 0.6467889908256881, 'best_accuracy': 0.6467889908256881}\n",
      "  Method: lora\n",
      "Epoch 1:  Train Loss: 0.6865  Eval Loss: 0.6956   Accuracy: 0.5092\n",
      "Epoch 2:  Train Loss: 0.6865  Eval Loss: 0.6932   Accuracy: 0.5092\n",
      "Epoch 3:  Train Loss: 0.6860  Eval Loss: 0.6930   Accuracy: 0.5092\n",
      "Epoch 4:  Train Loss: 0.6852  Eval Loss: 0.6918   Accuracy: 0.5092\n",
      "Epoch 5:  Train Loss: 0.6855  Eval Loss: 0.6902   Accuracy: 0.5092\n",
      "Epoch 6:  Train Loss: 0.6841  Eval Loss: 0.6898   Accuracy: 0.5092\n",
      "Epoch 7:  Train Loss: 0.6831  Eval Loss: 0.6889   Accuracy: 0.5092\n",
      "Epoch 8:  Train Loss: 0.6828  Eval Loss: 0.6851   Accuracy: 0.5275\n",
      "Epoch 9:  Train Loss: 0.6823  Eval Loss: 0.6852   Accuracy: 0.5310\n",
      "Epoch 10:  Train Loss: 0.6814  Eval Loss: 0.6849   Accuracy: 0.5275\n",
      "Epoch 11:  Train Loss: 0.6808  Eval Loss: 0.6860   Accuracy: 0.5172\n",
      "Epoch 12:  Train Loss: 0.6804  Eval Loss: 0.6888   Accuracy: 0.5126\n",
      "Epoch 13:  Train Loss: 0.6799  Eval Loss: 0.6861   Accuracy: 0.5218\n",
      "Epoch 14:  Train Loss: 0.6787  Eval Loss: 0.6829   Accuracy: 0.5550\n",
      "Epoch 15:  Train Loss: 0.6791  Eval Loss: 0.6827   Accuracy: 0.5539\n",
      "Epoch 16:  Train Loss: 0.6787  Eval Loss: 0.6819   Accuracy: 0.5573\n",
      "Epoch 17:  Train Loss: 0.6783  Eval Loss: 0.6783   Accuracy: 0.5757\n",
      "Epoch 18:  Train Loss: 0.6776  Eval Loss: 0.6780   Accuracy: 0.5780\n",
      "Epoch 19:  Train Loss: 0.6761  Eval Loss: 0.6778   Accuracy: 0.5803\n",
      "Epoch 20:  Train Loss: 0.6761  Eval Loss: 0.6802   Accuracy: 0.5573\n",
      "Epoch 21:  Train Loss: 0.6759  Eval Loss: 0.6804   Accuracy: 0.5539\n",
      "Epoch 22:  Train Loss: 0.6764  Eval Loss: 0.6800   Accuracy: 0.5528\n",
      "Epoch 23:  Train Loss: 0.6755  Eval Loss: 0.6785   Accuracy: 0.5642\n",
      "Epoch 24:  Train Loss: 0.6754  Eval Loss: 0.6771   Accuracy: 0.5722\n",
      "Epoch 25:  Train Loss: 0.6769  Eval Loss: 0.6780   Accuracy: 0.5688\n",
      "Epoch 26:  Train Loss: 0.6753  Eval Loss: 0.6770   Accuracy: 0.5688\n",
      "Epoch 27:  Train Loss: 0.6739  Eval Loss: 0.6777   Accuracy: 0.5654\n",
      "Epoch 28:  Train Loss: 0.6745  Eval Loss: 0.6772   Accuracy: 0.5734\n",
      "Epoch 29:  Train Loss: 0.6741  Eval Loss: 0.6797   Accuracy: 0.5562\n",
      "Epoch 30:  Train Loss: 0.6738  Eval Loss: 0.6757   Accuracy: 0.5722\n",
      "Epoch 31:  Train Loss: 0.6727  Eval Loss: 0.6752   Accuracy: 0.5722\n",
      "Epoch 32:  Train Loss: 0.6723  Eval Loss: 0.6739   Accuracy: 0.5745\n",
      "Epoch 33:  Train Loss: 0.6714  Eval Loss: 0.6741   Accuracy: 0.5711\n",
      "Epoch 34:  Train Loss: 0.6710  Eval Loss: 0.6731   Accuracy: 0.5711\n",
      "Epoch 35:  Train Loss: 0.6707  Eval Loss: 0.6732   Accuracy: 0.5757\n",
      "Epoch 36:  Train Loss: 0.6703  Eval Loss: 0.6731   Accuracy: 0.5768\n",
      "Epoch 37:  Train Loss: 0.6713  Eval Loss: 0.6735   Accuracy: 0.5780\n",
      "Epoch 38:  Train Loss: 0.6709  Eval Loss: 0.6731   Accuracy: 0.5745\n",
      "Epoch 39:  Train Loss: 0.6704  Eval Loss: 0.6708   Accuracy: 0.5826\n",
      "Epoch 40:  Train Loss: 0.6690  Eval Loss: 0.6721   Accuracy: 0.5745\n",
      "Epoch 41:  Train Loss: 0.6696  Eval Loss: 0.6695   Accuracy: 0.5883\n",
      "Epoch 42:  Train Loss: 0.6682  Eval Loss: 0.6688   Accuracy: 0.5872\n",
      "Epoch 43:  Train Loss: 0.6690  Eval Loss: 0.6697   Accuracy: 0.5837\n",
      "Epoch 44:  Train Loss: 0.6677  Eval Loss: 0.6688   Accuracy: 0.5872\n",
      "Epoch 45:  Train Loss: 0.6680  Eval Loss: 0.6687   Accuracy: 0.5963\n",
      "Epoch 46:  Train Loss: 0.6667  Eval Loss: 0.6710   Accuracy: 0.5780\n",
      "Epoch 47:  Train Loss: 0.6677  Eval Loss: 0.6727   Accuracy: 0.5677\n",
      "Epoch 48:  Train Loss: 0.6678  Eval Loss: 0.6699   Accuracy: 0.5803\n",
      "Epoch 49:  Train Loss: 0.6662  Eval Loss: 0.6677   Accuracy: 0.5940\n",
      "Epoch 50:  Train Loss: 0.6662  Eval Loss: 0.6666   Accuracy: 0.5998\n",
      "    Final Results: {'eval_loss': 0.6665770411491394, 'accuracy': 0.5997706422018348, 'best_accuracy': 0.5997706422018348}\n",
      "  Method: ia3\n",
      "Epoch 1:  Train Loss: 0.6856  Eval Loss: 0.6912   Accuracy: 0.5390\n",
      "Epoch 2:  Train Loss: 0.6853  Eval Loss: 0.6914   Accuracy: 0.5275\n",
      "Epoch 3:  Train Loss: 0.6855  Eval Loss: 0.6943   Accuracy: 0.5138\n",
      "Epoch 4:  Train Loss: 0.6838  Eval Loss: 0.6925   Accuracy: 0.5103\n",
      "Epoch 5:  Train Loss: 0.6823  Eval Loss: 0.6887   Accuracy: 0.5206\n",
      "Epoch 6:  Train Loss: 0.6815  Eval Loss: 0.6884   Accuracy: 0.5115\n",
      "Epoch 7:  Train Loss: 0.6800  Eval Loss: 0.6855   Accuracy: 0.5195\n",
      "Epoch 8:  Train Loss: 0.6793  Eval Loss: 0.6857   Accuracy: 0.5172\n",
      "Epoch 9:  Train Loss: 0.6783  Eval Loss: 0.6825   Accuracy: 0.5401\n",
      "Epoch 10:  Train Loss: 0.6774  Eval Loss: 0.6819   Accuracy: 0.5275\n",
      "Epoch 11:  Train Loss: 0.6766  Eval Loss: 0.6809   Accuracy: 0.5333\n",
      "Epoch 12:  Train Loss: 0.6758  Eval Loss: 0.6792   Accuracy: 0.5573\n",
      "Epoch 13:  Train Loss: 0.6752  Eval Loss: 0.6785   Accuracy: 0.5688\n",
      "Epoch 14:  Train Loss: 0.6750  Eval Loss: 0.6785   Accuracy: 0.5550\n",
      "Epoch 15:  Train Loss: 0.6751  Eval Loss: 0.6789   Accuracy: 0.5562\n",
      "Epoch 16:  Train Loss: 0.6750  Eval Loss: 0.6775   Accuracy: 0.5711\n",
      "Epoch 17:  Train Loss: 0.6740  Eval Loss: 0.6776   Accuracy: 0.5700\n",
      "Epoch 18:  Train Loss: 0.6748  Eval Loss: 0.6772   Accuracy: 0.5768\n",
      "Epoch 19:  Train Loss: 0.6737  Eval Loss: 0.6752   Accuracy: 0.5883\n",
      "Epoch 20:  Train Loss: 0.6749  Eval Loss: 0.6761   Accuracy: 0.5929\n",
      "Epoch 21:  Train Loss: 0.6744  Eval Loss: 0.6743   Accuracy: 0.5917\n",
      "Epoch 22:  Train Loss: 0.6729  Eval Loss: 0.6731   Accuracy: 0.5963\n",
      "Epoch 23:  Train Loss: 0.6716  Eval Loss: 0.6714   Accuracy: 0.5952\n",
      "Epoch 24:  Train Loss: 0.6721  Eval Loss: 0.6711   Accuracy: 0.5952\n",
      "Epoch 25:  Train Loss: 0.6713  Eval Loss: 0.6698   Accuracy: 0.5940\n",
      "Epoch 26:  Train Loss: 0.6708  Eval Loss: 0.6684   Accuracy: 0.6089\n",
      "Epoch 27:  Train Loss: 0.6713  Eval Loss: 0.6690   Accuracy: 0.6009\n",
      "Epoch 28:  Train Loss: 0.6696  Eval Loss: 0.6680   Accuracy: 0.6009\n",
      "Epoch 29:  Train Loss: 0.6696  Eval Loss: 0.6673   Accuracy: 0.6078\n",
      "Epoch 30:  Train Loss: 0.6693  Eval Loss: 0.6676   Accuracy: 0.6158\n",
      "Epoch 31:  Train Loss: 0.6680  Eval Loss: 0.6694   Accuracy: 0.5998\n",
      "Epoch 32:  Train Loss: 0.6673  Eval Loss: 0.6684   Accuracy: 0.6124\n",
      "Epoch 33:  Train Loss: 0.6674  Eval Loss: 0.6684   Accuracy: 0.6067\n",
      "Epoch 34:  Train Loss: 0.6675  Eval Loss: 0.6684   Accuracy: 0.5963\n",
      "Epoch 35:  Train Loss: 0.6676  Eval Loss: 0.6682   Accuracy: 0.6044\n",
      "Epoch 36:  Train Loss: 0.6668  Eval Loss: 0.6680   Accuracy: 0.6021\n",
      "Epoch 37:  Train Loss: 0.6672  Eval Loss: 0.6695   Accuracy: 0.5929\n",
      "Epoch 38:  Train Loss: 0.6661  Eval Loss: 0.6710   Accuracy: 0.5849\n",
      "Epoch 39:  Train Loss: 0.6662  Eval Loss: 0.6673   Accuracy: 0.5963\n",
      "Epoch 40:  Train Loss: 0.6660  Eval Loss: 0.6682   Accuracy: 0.5894\n",
      "Epoch 41:  Train Loss: 0.6665  Eval Loss: 0.6681   Accuracy: 0.5940\n",
      "Epoch 42:  Train Loss: 0.6655  Eval Loss: 0.6670   Accuracy: 0.5975\n",
      "Epoch 43:  Train Loss: 0.6656  Eval Loss: 0.6680   Accuracy: 0.5929\n",
      "Epoch 44:  Train Loss: 0.6647  Eval Loss: 0.6698   Accuracy: 0.5780\n",
      "Epoch 45:  Train Loss: 0.6657  Eval Loss: 0.6667   Accuracy: 0.5940\n",
      "Epoch 46:  Train Loss: 0.6640  Eval Loss: 0.6648   Accuracy: 0.6089\n",
      "Epoch 47:  Train Loss: 0.6632  Eval Loss: 0.6674   Accuracy: 0.5860\n",
      "Epoch 48:  Train Loss: 0.6638  Eval Loss: 0.6655   Accuracy: 0.6204\n",
      "Epoch 49:  Train Loss: 0.6648  Eval Loss: 0.6659   Accuracy: 0.6170\n",
      "Epoch 50:  Train Loss: 0.6636  Eval Loss: 0.6656   Accuracy: 0.6216\n",
      "    Final Results: {'eval_loss': 0.6656416654586792, 'accuracy': 0.6215596330275229, 'best_accuracy': 0.6215596330275229}\n",
      "  Method: single_layer_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.7016  Eval Loss: 0.7147   Accuracy: 0.4656\n",
      "Epoch 2:  Train Loss: 0.7008  Eval Loss: 0.7122   Accuracy: 0.4725\n",
      "Epoch 3:  Train Loss: 0.6988  Eval Loss: 0.7106   Accuracy: 0.4759\n",
      "Epoch 4:  Train Loss: 0.6999  Eval Loss: 0.7103   Accuracy: 0.4851\n",
      "Epoch 5:  Train Loss: 0.6962  Eval Loss: 0.7085   Accuracy: 0.4897\n",
      "Epoch 6:  Train Loss: 0.6968  Eval Loss: 0.7066   Accuracy: 0.4885\n",
      "Epoch 7:  Train Loss: 0.6960  Eval Loss: 0.7048   Accuracy: 0.4931\n",
      "Epoch 8:  Train Loss: 0.6940  Eval Loss: 0.7012   Accuracy: 0.5023\n",
      "Epoch 9:  Train Loss: 0.6936  Eval Loss: 0.7017   Accuracy: 0.5057\n",
      "Epoch 10:  Train Loss: 0.6922  Eval Loss: 0.6995   Accuracy: 0.5023\n",
      "Epoch 11:  Train Loss: 0.6920  Eval Loss: 0.7007   Accuracy: 0.5034\n",
      "Epoch 12:  Train Loss: 0.6900  Eval Loss: 0.6980   Accuracy: 0.5069\n",
      "Epoch 13:  Train Loss: 0.6907  Eval Loss: 0.6963   Accuracy: 0.5103\n",
      "Epoch 14:  Train Loss: 0.6881  Eval Loss: 0.6942   Accuracy: 0.5195\n",
      "Epoch 15:  Train Loss: 0.6875  Eval Loss: 0.6929   Accuracy: 0.5287\n",
      "Epoch 16:  Train Loss: 0.6863  Eval Loss: 0.6929   Accuracy: 0.5172\n",
      "Epoch 17:  Train Loss: 0.6849  Eval Loss: 0.6923   Accuracy: 0.5206\n",
      "Epoch 18:  Train Loss: 0.6851  Eval Loss: 0.6909   Accuracy: 0.5264\n",
      "Epoch 19:  Train Loss: 0.6835  Eval Loss: 0.6910   Accuracy: 0.5161\n",
      "Epoch 20:  Train Loss: 0.6824  Eval Loss: 0.6881   Accuracy: 0.5401\n",
      "Epoch 21:  Train Loss: 0.6809  Eval Loss: 0.6865   Accuracy: 0.5436\n",
      "Epoch 22:  Train Loss: 0.6809  Eval Loss: 0.6861   Accuracy: 0.5424\n",
      "Epoch 23:  Train Loss: 0.6792  Eval Loss: 0.6851   Accuracy: 0.5344\n",
      "Epoch 24:  Train Loss: 0.6791  Eval Loss: 0.6858   Accuracy: 0.5378\n",
      "Epoch 25:  Train Loss: 0.6785  Eval Loss: 0.6848   Accuracy: 0.5413\n",
      "Epoch 26:  Train Loss: 0.6777  Eval Loss: 0.6841   Accuracy: 0.5447\n",
      "Epoch 27:  Train Loss: 0.6770  Eval Loss: 0.6876   Accuracy: 0.5241\n",
      "Epoch 28:  Train Loss: 0.6782  Eval Loss: 0.6875   Accuracy: 0.5310\n",
      "Epoch 29:  Train Loss: 0.6778  Eval Loss: 0.6868   Accuracy: 0.5229\n",
      "Epoch 30:  Train Loss: 0.6777  Eval Loss: 0.6844   Accuracy: 0.5390\n",
      "Epoch 31:  Train Loss: 0.6755  Eval Loss: 0.6843   Accuracy: 0.5287\n",
      "Epoch 32:  Train Loss: 0.6749  Eval Loss: 0.6831   Accuracy: 0.5321\n",
      "Epoch 33:  Train Loss: 0.6733  Eval Loss: 0.6820   Accuracy: 0.5367\n",
      "Epoch 34:  Train Loss: 0.6735  Eval Loss: 0.6820   Accuracy: 0.5333\n",
      "Epoch 35:  Train Loss: 0.6731  Eval Loss: 0.6795   Accuracy: 0.5470\n",
      "Epoch 36:  Train Loss: 0.6729  Eval Loss: 0.6777   Accuracy: 0.5631\n",
      "Epoch 37:  Train Loss: 0.6721  Eval Loss: 0.6785   Accuracy: 0.5550\n",
      "Epoch 38:  Train Loss: 0.6735  Eval Loss: 0.6813   Accuracy: 0.5528\n",
      "Epoch 39:  Train Loss: 0.6730  Eval Loss: 0.6816   Accuracy: 0.5528\n",
      "Epoch 40:  Train Loss: 0.6737  Eval Loss: 0.6810   Accuracy: 0.5528\n",
      "Epoch 41:  Train Loss: 0.6721  Eval Loss: 0.6796   Accuracy: 0.5631\n",
      "Epoch 42:  Train Loss: 0.6716  Eval Loss: 0.6776   Accuracy: 0.5493\n",
      "Epoch 43:  Train Loss: 0.6721  Eval Loss: 0.6800   Accuracy: 0.5573\n",
      "Epoch 44:  Train Loss: 0.6717  Eval Loss: 0.6774   Accuracy: 0.5596\n",
      "Epoch 45:  Train Loss: 0.6706  Eval Loss: 0.6784   Accuracy: 0.5562\n",
      "Epoch 46:  Train Loss: 0.6704  Eval Loss: 0.6774   Accuracy: 0.5562\n",
      "Epoch 47:  Train Loss: 0.6689  Eval Loss: 0.6770   Accuracy: 0.5550\n",
      "Epoch 48:  Train Loss: 0.6699  Eval Loss: 0.6762   Accuracy: 0.5631\n",
      "Epoch 49:  Train Loss: 0.6704  Eval Loss: 0.6751   Accuracy: 0.5642\n",
      "Epoch 50:  Train Loss: 0.6687  Eval Loss: 0.6781   Accuracy: 0.5585\n",
      "    Final Results: {'eval_loss': 0.6781367659568787, 'accuracy': 0.5584862385321101, 'best_accuracy': 0.5642201834862385}\n",
      "  Method: soft_prompt_lora\n",
      "Epoch 1:  Train Loss: 0.6866  Eval Loss: 0.6990   Accuracy: 0.5092\n",
      "Epoch 2:  Train Loss: 0.6862  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 3:  Train Loss: 0.6860  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 4:  Train Loss: 0.6864  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 5:  Train Loss: 0.6863  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 6:  Train Loss: 0.6863  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 7:  Train Loss: 0.6866  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 8:  Train Loss: 0.6862  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 9:  Train Loss: 0.6864  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 10:  Train Loss: 0.6866  Eval Loss: 0.6991   Accuracy: 0.5092\n",
      "Epoch 11:  Train Loss: 0.6861  Eval Loss: 0.6991   Accuracy: 0.5092\n",
      "Epoch 12:  Train Loss: 0.6865  Eval Loss: 0.6991   Accuracy: 0.5092\n",
      "Epoch 13:  Train Loss: 0.6864  Eval Loss: 0.6993   Accuracy: 0.5092\n",
      "Epoch 14:  Train Loss: 0.6864  Eval Loss: 0.6991   Accuracy: 0.5092\n",
      "Epoch 15:  Train Loss: 0.6862  Eval Loss: 0.6990   Accuracy: 0.5092\n",
      "Epoch 16:  Train Loss: 0.6859  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 17:  Train Loss: 0.6863  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 18:  Train Loss: 0.6862  Eval Loss: 0.6990   Accuracy: 0.5092\n",
      "Epoch 19:  Train Loss: 0.6863  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 20:  Train Loss: 0.6862  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 21:  Train Loss: 0.6861  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 22:  Train Loss: 0.6865  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 23:  Train Loss: 0.6863  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 24:  Train Loss: 0.6863  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 25:  Train Loss: 0.6863  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 26:  Train Loss: 0.6862  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 27:  Train Loss: 0.6860  Eval Loss: 0.6990   Accuracy: 0.5092\n",
      "Epoch 28:  Train Loss: 0.6865  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 29:  Train Loss: 0.6860  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 30:  Train Loss: 0.6862  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 31:  Train Loss: 0.6862  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 32:  Train Loss: 0.6861  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 33:  Train Loss: 0.6861  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 34:  Train Loss: 0.6860  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 35:  Train Loss: 0.6859  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 36:  Train Loss: 0.6862  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 37:  Train Loss: 0.6862  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 38:  Train Loss: 0.6858  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 39:  Train Loss: 0.6863  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 40:  Train Loss: 0.6864  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 41:  Train Loss: 0.6864  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 42:  Train Loss: 0.6865  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 43:  Train Loss: 0.6858  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 44:  Train Loss: 0.6859  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 45:  Train Loss: 0.6858  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 46:  Train Loss: 0.6861  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 47:  Train Loss: 0.6858  Eval Loss: 0.6987   Accuracy: 0.5092\n",
      "Epoch 48:  Train Loss: 0.6860  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 49:  Train Loss: 0.6861  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "Epoch 50:  Train Loss: 0.6860  Eval Loss: 0.6989   Accuracy: 0.5092\n",
      "    Final Results: {'eval_loss': 0.6989241242408752, 'accuracy': 0.5091743119266054, 'best_accuracy': 0.5091743119266054}\n",
      "  Method: prefix_lora\n",
      "Epoch 1:  Train Loss: 0.6990  Eval Loss: 0.7018   Accuracy: 0.4507\n",
      "Epoch 2:  Train Loss: 0.6988  Eval Loss: 0.7017   Accuracy: 0.4530\n",
      "Epoch 3:  Train Loss: 0.6989  Eval Loss: 0.7017   Accuracy: 0.4507\n",
      "Epoch 4:  Train Loss: 0.6986  Eval Loss: 0.7017   Accuracy: 0.4553\n",
      "Epoch 5:  Train Loss: 0.6988  Eval Loss: 0.7017   Accuracy: 0.4599\n",
      "Epoch 6:  Train Loss: 0.6987  Eval Loss: 0.7018   Accuracy: 0.4564\n",
      "Epoch 7:  Train Loss: 0.6987  Eval Loss: 0.7017   Accuracy: 0.4541\n",
      "Epoch 8:  Train Loss: 0.6990  Eval Loss: 0.7017   Accuracy: 0.4564\n",
      "Epoch 9:  Train Loss: 0.6982  Eval Loss: 0.7017   Accuracy: 0.4530\n",
      "Epoch 10:  Train Loss: 0.6988  Eval Loss: 0.7017   Accuracy: 0.4541\n",
      "Epoch 11:  Train Loss: 0.6986  Eval Loss: 0.7017   Accuracy: 0.4541\n",
      "Epoch 12:  Train Loss: 0.6982  Eval Loss: 0.7016   Accuracy: 0.4553\n",
      "Epoch 13:  Train Loss: 0.6983  Eval Loss: 0.7015   Accuracy: 0.4564\n",
      "Epoch 14:  Train Loss: 0.6980  Eval Loss: 0.7013   Accuracy: 0.4587\n",
      "Epoch 15:  Train Loss: 0.6982  Eval Loss: 0.7013   Accuracy: 0.4587\n",
      "Epoch 16:  Train Loss: 0.6983  Eval Loss: 0.7014   Accuracy: 0.4564\n",
      "Epoch 17:  Train Loss: 0.6979  Eval Loss: 0.7014   Accuracy: 0.4599\n",
      "Epoch 18:  Train Loss: 0.6981  Eval Loss: 0.7015   Accuracy: 0.4495\n",
      "Epoch 19:  Train Loss: 0.6980  Eval Loss: 0.7015   Accuracy: 0.4518\n",
      "Epoch 20:  Train Loss: 0.6983  Eval Loss: 0.7017   Accuracy: 0.4553\n",
      "Epoch 21:  Train Loss: 0.6981  Eval Loss: 0.7018   Accuracy: 0.4507\n",
      "Epoch 22:  Train Loss: 0.6980  Eval Loss: 0.7018   Accuracy: 0.4530\n",
      "Epoch 23:  Train Loss: 0.6980  Eval Loss: 0.7018   Accuracy: 0.4518\n",
      "Epoch 24:  Train Loss: 0.6983  Eval Loss: 0.7019   Accuracy: 0.4495\n",
      "Epoch 25:  Train Loss: 0.6981  Eval Loss: 0.7020   Accuracy: 0.4438\n",
      "Epoch 26:  Train Loss: 0.6979  Eval Loss: 0.7019   Accuracy: 0.4495\n",
      "Epoch 27:  Train Loss: 0.6977  Eval Loss: 0.7019   Accuracy: 0.4518\n",
      "Epoch 28:  Train Loss: 0.6978  Eval Loss: 0.7018   Accuracy: 0.4507\n",
      "Epoch 29:  Train Loss: 0.6976  Eval Loss: 0.7017   Accuracy: 0.4518\n",
      "Epoch 30:  Train Loss: 0.6974  Eval Loss: 0.7016   Accuracy: 0.4530\n",
      "Epoch 31:  Train Loss: 0.6976  Eval Loss: 0.7017   Accuracy: 0.4507\n",
      "Epoch 32:  Train Loss: 0.6979  Eval Loss: 0.7017   Accuracy: 0.4518\n",
      "Epoch 33:  Train Loss: 0.6976  Eval Loss: 0.7016   Accuracy: 0.4507\n",
      "Epoch 34:  Train Loss: 0.6970  Eval Loss: 0.7015   Accuracy: 0.4518\n",
      "Epoch 35:  Train Loss: 0.6974  Eval Loss: 0.7012   Accuracy: 0.4518\n",
      "Epoch 36:  Train Loss: 0.6969  Eval Loss: 0.7011   Accuracy: 0.4507\n",
      "Epoch 37:  Train Loss: 0.6963  Eval Loss: 0.7009   Accuracy: 0.4541\n",
      "Epoch 38:  Train Loss: 0.6962  Eval Loss: 0.7010   Accuracy: 0.4541\n",
      "Epoch 39:  Train Loss: 0.6968  Eval Loss: 0.7009   Accuracy: 0.4518\n",
      "Epoch 40:  Train Loss: 0.6967  Eval Loss: 0.7009   Accuracy: 0.4507\n",
      "Epoch 41:  Train Loss: 0.6965  Eval Loss: 0.7006   Accuracy: 0.4472\n",
      "Epoch 42:  Train Loss: 0.6965  Eval Loss: 0.7006   Accuracy: 0.4530\n",
      "Epoch 43:  Train Loss: 0.6963  Eval Loss: 0.7004   Accuracy: 0.4518\n",
      "Epoch 44:  Train Loss: 0.6964  Eval Loss: 0.7004   Accuracy: 0.4530\n",
      "Epoch 45:  Train Loss: 0.6962  Eval Loss: 0.7003   Accuracy: 0.4507\n",
      "Epoch 46:  Train Loss: 0.6963  Eval Loss: 0.7003   Accuracy: 0.4541\n",
      "Epoch 47:  Train Loss: 0.6967  Eval Loss: 0.7004   Accuracy: 0.4507\n",
      "Epoch 48:  Train Loss: 0.6962  Eval Loss: 0.7003   Accuracy: 0.4576\n",
      "Epoch 49:  Train Loss: 0.6962  Eval Loss: 0.7003   Accuracy: 0.4622\n",
      "Epoch 50:  Train Loss: 0.6958  Eval Loss: 0.7004   Accuracy: 0.4610\n",
      "    Final Results: {'eval_loss': 0.7004327774047852, 'accuracy': 0.4610091743119266, 'best_accuracy': 0.46215596330275227}\n",
      "==================================================\n",
      "\n",
      "Results for sst2:\n",
      "  Method: soft_prompt, Accuracy: 0.5126, Loss: 0.6915\n",
      "  Method: prefix, Accuracy: 0.5894, Loss: 0.6682\n",
      "  Method: full_fine_tuning, Accuracy: 0.6468, Loss: 0.6411\n",
      "  Method: lora, Accuracy: 0.5998, Loss: 0.6666\n",
      "  Method: ia3, Accuracy: 0.6216, Loss: 0.6656\n",
      "  Method: single_layer_fine_tuning, Accuracy: 0.5585, Loss: 0.6781\n",
      "  Method: soft_prompt_lora, Accuracy: 0.5092, Loss: 0.6989\n",
      "  Method: prefix_lora, Accuracy: 0.4610, Loss: 0.7004\n",
      "\n",
      "Results have been appended to peft_experiment_results.txt\n"
     ]
    }
   ],
   "source": [
    "results = run_peft_experiments(epsilon=8,dataset=['sst2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc8af28-f1ab-4c55-912f-4f8775c3b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing dataset: sst2\n",
      "  Method: soft_prompt\n",
      "Epoch 1:  Train Loss: 0.6885  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 2:  Train Loss: 0.6880  Eval Loss: 0.6973   Accuracy: 0.5092\n",
      "Epoch 3:  Train Loss: 0.6883  Eval Loss: 0.6993   Accuracy: 0.5092\n",
      "Epoch 4:  Train Loss: 0.6887  Eval Loss: 0.6999   Accuracy: 0.5092\n",
      "Epoch 5:  Train Loss: 0.6887  Eval Loss: 0.6994   Accuracy: 0.5092\n",
      "Epoch 6:  Train Loss: 0.6889  Eval Loss: 0.6978   Accuracy: 0.5092\n",
      "Epoch 7:  Train Loss: 0.6882  Eval Loss: 0.6969   Accuracy: 0.5092\n",
      "Epoch 8:  Train Loss: 0.6883  Eval Loss: 0.6965   Accuracy: 0.5092\n",
      "Epoch 9:  Train Loss: 0.6888  Eval Loss: 0.6988   Accuracy: 0.5092\n",
      "Epoch 10:  Train Loss: 0.6890  Eval Loss: 0.6942   Accuracy: 0.5092\n",
      "Epoch 11:  Train Loss: 0.6883  Eval Loss: 0.6946   Accuracy: 0.5092\n",
      "Epoch 12:  Train Loss: 0.6883  Eval Loss: 0.6960   Accuracy: 0.5092\n",
      "Epoch 13:  Train Loss: 0.6887  Eval Loss: 0.6969   Accuracy: 0.5092\n",
      "Epoch 14:  Train Loss: 0.6894  Eval Loss: 0.6979   Accuracy: 0.5092\n",
      "Epoch 15:  Train Loss: 0.6892  Eval Loss: 0.6992   Accuracy: 0.5092\n",
      "Epoch 16:  Train Loss: 0.6892  Eval Loss: 0.6976   Accuracy: 0.5092\n",
      "Epoch 17:  Train Loss: 0.6893  Eval Loss: 0.6957   Accuracy: 0.5092\n",
      "Epoch 18:  Train Loss: 0.6887  Eval Loss: 0.6953   Accuracy: 0.5092\n",
      "Epoch 19:  Train Loss: 0.6883  Eval Loss: 0.6964   Accuracy: 0.5092\n",
      "Epoch 20:  Train Loss: 0.6885  Eval Loss: 0.6970   Accuracy: 0.5092\n",
      "Epoch 21:  Train Loss: 0.6886  Eval Loss: 0.6970   Accuracy: 0.5092\n",
      "Epoch 22:  Train Loss: 0.6880  Eval Loss: 0.6938   Accuracy: 0.5092\n",
      "Epoch 23:  Train Loss: 0.6889  Eval Loss: 0.6940   Accuracy: 0.5092\n",
      "Epoch 24:  Train Loss: 0.6889  Eval Loss: 0.6953   Accuracy: 0.5092\n",
      "Epoch 25:  Train Loss: 0.6881  Eval Loss: 0.6959   Accuracy: 0.5092\n",
      "Epoch 26:  Train Loss: 0.6876  Eval Loss: 0.6965   Accuracy: 0.5092\n",
      "Epoch 27:  Train Loss: 0.6881  Eval Loss: 0.6967   Accuracy: 0.5092\n",
      "Epoch 28:  Train Loss: 0.6883  Eval Loss: 0.6932   Accuracy: 0.5092\n",
      "Epoch 29:  Train Loss: 0.6879  Eval Loss: 0.6955   Accuracy: 0.5092\n",
      "Epoch 30:  Train Loss: 0.6877  Eval Loss: 0.6975   Accuracy: 0.5092\n",
      "Epoch 31:  Train Loss: 0.6873  Eval Loss: 0.6939   Accuracy: 0.5092\n",
      "Epoch 32:  Train Loss: 0.6865  Eval Loss: 0.6930   Accuracy: 0.5092\n",
      "Epoch 33:  Train Loss: 0.6879  Eval Loss: 0.6942   Accuracy: 0.5092\n",
      "Epoch 34:  Train Loss: 0.6871  Eval Loss: 0.6936   Accuracy: 0.5092\n",
      "Epoch 35:  Train Loss: 0.6873  Eval Loss: 0.6947   Accuracy: 0.5092\n",
      "Epoch 36:  Train Loss: 0.6879  Eval Loss: 0.6955   Accuracy: 0.5092\n",
      "Epoch 37:  Train Loss: 0.6875  Eval Loss: 0.6950   Accuracy: 0.5092\n",
      "Epoch 38:  Train Loss: 0.6877  Eval Loss: 0.6946   Accuracy: 0.5092\n",
      "Epoch 39:  Train Loss: 0.6873  Eval Loss: 0.6942   Accuracy: 0.5092\n",
      "Epoch 40:  Train Loss: 0.6875  Eval Loss: 0.6922   Accuracy: 0.5092\n",
      "Epoch 41:  Train Loss: 0.6876  Eval Loss: 0.6926   Accuracy: 0.5092\n",
      "Epoch 42:  Train Loss: 0.6872  Eval Loss: 0.6945   Accuracy: 0.5092\n",
      "Epoch 43:  Train Loss: 0.6871  Eval Loss: 0.6939   Accuracy: 0.5092\n",
      "Epoch 44:  Train Loss: 0.6873  Eval Loss: 0.6934   Accuracy: 0.5092\n",
      "Epoch 45:  Train Loss: 0.6868  Eval Loss: 0.6938   Accuracy: 0.5092\n",
      "Epoch 46:  Train Loss: 0.6870  Eval Loss: 0.6949   Accuracy: 0.5092\n",
      "Epoch 47:  Train Loss: 0.6869  Eval Loss: 0.6957   Accuracy: 0.5092\n",
      "Epoch 48:  Train Loss: 0.6875  Eval Loss: 0.6956   Accuracy: 0.5092\n",
      "Epoch 49:  Train Loss: 0.6873  Eval Loss: 0.6946   Accuracy: 0.5092\n",
      "Epoch 50:  Train Loss: 0.6870  Eval Loss: 0.6943   Accuracy: 0.5092\n",
      "    Final Results: {'eval_loss': 0.69432532787323, 'accuracy': 0.5091743119266054, 'best_accuracy': 0.5091743119266054}\n",
      "  Method: prefix\n",
      "Epoch 1:  Train Loss: 0.6984  Eval Loss: 0.6938   Accuracy: 0.4966\n",
      "Epoch 2:  Train Loss: 0.6883  Eval Loss: 0.6934   Accuracy: 0.5057\n",
      "Epoch 3:  Train Loss: 0.6863  Eval Loss: 0.6961   Accuracy: 0.5092\n",
      "Epoch 4:  Train Loss: 0.6853  Eval Loss: 0.6956   Accuracy: 0.5092\n",
      "Epoch 5:  Train Loss: 0.6844  Eval Loss: 0.6941   Accuracy: 0.5092\n",
      "Epoch 6:  Train Loss: 0.6841  Eval Loss: 0.6917   Accuracy: 0.5103\n",
      "Epoch 7:  Train Loss: 0.6835  Eval Loss: 0.6910   Accuracy: 0.5080\n",
      "Epoch 8:  Train Loss: 0.6830  Eval Loss: 0.6894   Accuracy: 0.5092\n",
      "Epoch 9:  Train Loss: 0.6818  Eval Loss: 0.6896   Accuracy: 0.5057\n",
      "Epoch 10:  Train Loss: 0.6812  Eval Loss: 0.6886   Accuracy: 0.5080\n",
      "Epoch 11:  Train Loss: 0.6805  Eval Loss: 0.6877   Accuracy: 0.5138\n",
      "Epoch 12:  Train Loss: 0.6808  Eval Loss: 0.6867   Accuracy: 0.5241\n",
      "Epoch 13:  Train Loss: 0.6802  Eval Loss: 0.6866   Accuracy: 0.5103\n",
      "Epoch 14:  Train Loss: 0.6794  Eval Loss: 0.6866   Accuracy: 0.5092\n",
      "Epoch 15:  Train Loss: 0.6792  Eval Loss: 0.6840   Accuracy: 0.5505\n",
      "Epoch 16:  Train Loss: 0.6797  Eval Loss: 0.6840   Accuracy: 0.5424\n",
      "Epoch 17:  Train Loss: 0.6796  Eval Loss: 0.6829   Accuracy: 0.5378\n",
      "Epoch 18:  Train Loss: 0.6785  Eval Loss: 0.6821   Accuracy: 0.5447\n",
      "Epoch 19:  Train Loss: 0.6774  Eval Loss: 0.6809   Accuracy: 0.5436\n",
      "Epoch 20:  Train Loss: 0.6763  Eval Loss: 0.6802   Accuracy: 0.5516\n",
      "Epoch 21:  Train Loss: 0.6753  Eval Loss: 0.6799   Accuracy: 0.5401\n",
      "Epoch 22:  Train Loss: 0.6751  Eval Loss: 0.6796   Accuracy: 0.5401\n",
      "Epoch 23:  Train Loss: 0.6749  Eval Loss: 0.6797   Accuracy: 0.5241\n",
      "Epoch 24:  Train Loss: 0.6744  Eval Loss: 0.6797   Accuracy: 0.5264\n",
      "Epoch 25:  Train Loss: 0.6754  Eval Loss: 0.6804   Accuracy: 0.5229\n",
      "Epoch 26:  Train Loss: 0.6740  Eval Loss: 0.6765   Accuracy: 0.5573\n",
      "Epoch 27:  Train Loss: 0.6733  Eval Loss: 0.6751   Accuracy: 0.5608\n",
      "Epoch 28:  Train Loss: 0.6732  Eval Loss: 0.6761   Accuracy: 0.5424\n",
      "Epoch 29:  Train Loss: 0.6730  Eval Loss: 0.6741   Accuracy: 0.5688\n",
      "Epoch 30:  Train Loss: 0.6713  Eval Loss: 0.6741   Accuracy: 0.5505\n",
      "Epoch 31:  Train Loss: 0.6728  Eval Loss: 0.6779   Accuracy: 0.5321\n",
      "Epoch 32:  Train Loss: 0.6733  Eval Loss: 0.6757   Accuracy: 0.5367\n",
      "Epoch 33:  Train Loss: 0.6723  Eval Loss: 0.6722   Accuracy: 0.5654\n",
      "Epoch 34:  Train Loss: 0.6713  Eval Loss: 0.6707   Accuracy: 0.5814\n",
      "Epoch 35:  Train Loss: 0.6714  Eval Loss: 0.6677   Accuracy: 0.5929\n",
      "Epoch 36:  Train Loss: 0.6714  Eval Loss: 0.6704   Accuracy: 0.5745\n",
      "Epoch 37:  Train Loss: 0.6710  Eval Loss: 0.6670   Accuracy: 0.5963\n",
      "Epoch 38:  Train Loss: 0.6717  Eval Loss: 0.6667   Accuracy: 0.5940\n",
      "Epoch 39:  Train Loss: 0.6711  Eval Loss: 0.6660   Accuracy: 0.5940\n",
      "Epoch 40:  Train Loss: 0.6702  Eval Loss: 0.6679   Accuracy: 0.5894\n",
      "Epoch 41:  Train Loss: 0.6694  Eval Loss: 0.6672   Accuracy: 0.5849\n",
      "Epoch 42:  Train Loss: 0.6678  Eval Loss: 0.6659   Accuracy: 0.5894\n",
      "Epoch 43:  Train Loss: 0.6677  Eval Loss: 0.6646   Accuracy: 0.5929\n",
      "Epoch 44:  Train Loss: 0.6667  Eval Loss: 0.6658   Accuracy: 0.5883\n",
      "Epoch 45:  Train Loss: 0.6664  Eval Loss: 0.6629   Accuracy: 0.5963\n",
      "Epoch 46:  Train Loss: 0.6661  Eval Loss: 0.6628   Accuracy: 0.5963\n",
      "Epoch 47:  Train Loss: 0.6658  Eval Loss: 0.6612   Accuracy: 0.6009\n",
      "Epoch 48:  Train Loss: 0.6653  Eval Loss: 0.6633   Accuracy: 0.5940\n",
      "Epoch 49:  Train Loss: 0.6647  Eval Loss: 0.6629   Accuracy: 0.5963\n",
      "Epoch 50:  Train Loss: 0.6640  Eval Loss: 0.6598   Accuracy: 0.5940\n",
      "    Final Results: {'eval_loss': 0.659805953502655, 'accuracy': 0.5940366972477065, 'best_accuracy': 0.6009174311926605}\n",
      "  Method: full_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.6838  Eval Loss: 0.6926   Accuracy: 0.5080\n",
      "Epoch 2:  Train Loss: 0.6819  Eval Loss: 0.6931   Accuracy: 0.5092\n",
      "Epoch 3:  Train Loss: 0.6815  Eval Loss: 0.6906   Accuracy: 0.5092\n",
      "Epoch 4:  Train Loss: 0.6813  Eval Loss: 0.6917   Accuracy: 0.5092\n",
      "Epoch 5:  Train Loss: 0.6802  Eval Loss: 0.6892   Accuracy: 0.5092\n",
      "Epoch 6:  Train Loss: 0.6789  Eval Loss: 0.6855   Accuracy: 0.5138\n",
      "Epoch 7:  Train Loss: 0.6772  Eval Loss: 0.6858   Accuracy: 0.5126\n",
      "Epoch 8:  Train Loss: 0.6760  Eval Loss: 0.6828   Accuracy: 0.5149\n",
      "Epoch 9:  Train Loss: 0.6745  Eval Loss: 0.6842   Accuracy: 0.5161\n",
      "Epoch 10:  Train Loss: 0.6753  Eval Loss: 0.6848   Accuracy: 0.5126\n",
      "Epoch 11:  Train Loss: 0.6750  Eval Loss: 0.6821   Accuracy: 0.5195\n",
      "Epoch 12:  Train Loss: 0.6747  Eval Loss: 0.6812   Accuracy: 0.5252\n",
      "Epoch 13:  Train Loss: 0.6732  Eval Loss: 0.6764   Accuracy: 0.5700\n",
      "Epoch 14:  Train Loss: 0.6713  Eval Loss: 0.6750   Accuracy: 0.5539\n",
      "Epoch 15:  Train Loss: 0.6702  Eval Loss: 0.6748   Accuracy: 0.5550\n",
      "Epoch 16:  Train Loss: 0.6696  Eval Loss: 0.6727   Accuracy: 0.5917\n",
      "Epoch 17:  Train Loss: 0.6685  Eval Loss: 0.6744   Accuracy: 0.5493\n",
      "Epoch 18:  Train Loss: 0.6689  Eval Loss: 0.6741   Accuracy: 0.5539\n",
      "Epoch 19:  Train Loss: 0.6669  Eval Loss: 0.6713   Accuracy: 0.5734\n",
      "Epoch 20:  Train Loss: 0.6656  Eval Loss: 0.6705   Accuracy: 0.5883\n",
      "Epoch 21:  Train Loss: 0.6647  Eval Loss: 0.6696   Accuracy: 0.5952\n",
      "Epoch 22:  Train Loss: 0.6635  Eval Loss: 0.6677   Accuracy: 0.5940\n",
      "Epoch 23:  Train Loss: 0.6614  Eval Loss: 0.6659   Accuracy: 0.6170\n",
      "Epoch 24:  Train Loss: 0.6616  Eval Loss: 0.6670   Accuracy: 0.5929\n",
      "Epoch 25:  Train Loss: 0.6626  Eval Loss: 0.6668   Accuracy: 0.5952\n",
      "Epoch 26:  Train Loss: 0.6609  Eval Loss: 0.6638   Accuracy: 0.5803\n",
      "Epoch 27:  Train Loss: 0.6590  Eval Loss: 0.6597   Accuracy: 0.6227\n",
      "Epoch 28:  Train Loss: 0.6571  Eval Loss: 0.6602   Accuracy: 0.6055\n",
      "Epoch 29:  Train Loss: 0.6566  Eval Loss: 0.6585   Accuracy: 0.6135\n",
      "Epoch 30:  Train Loss: 0.6549  Eval Loss: 0.6570   Accuracy: 0.6388\n",
      "Epoch 31:  Train Loss: 0.6554  Eval Loss: 0.6605   Accuracy: 0.5975\n",
      "Epoch 32:  Train Loss: 0.6550  Eval Loss: 0.6579   Accuracy: 0.6181\n",
      "Epoch 33:  Train Loss: 0.6541  Eval Loss: 0.6536   Accuracy: 0.6342\n",
      "Epoch 34:  Train Loss: 0.6533  Eval Loss: 0.6520   Accuracy: 0.6456\n",
      "Epoch 35:  Train Loss: 0.6517  Eval Loss: 0.6498   Accuracy: 0.6411\n",
      "Epoch 36:  Train Loss: 0.6500  Eval Loss: 0.6490   Accuracy: 0.6388\n",
      "Epoch 37:  Train Loss: 0.6494  Eval Loss: 0.6476   Accuracy: 0.6330\n",
      "Epoch 38:  Train Loss: 0.6469  Eval Loss: 0.6455   Accuracy: 0.6319\n",
      "Epoch 39:  Train Loss: 0.6448  Eval Loss: 0.6420   Accuracy: 0.6560\n",
      "Epoch 40:  Train Loss: 0.6440  Eval Loss: 0.6387   Accuracy: 0.6583\n",
      "Epoch 41:  Train Loss: 0.6426  Eval Loss: 0.6389   Accuracy: 0.6537\n",
      "Epoch 42:  Train Loss: 0.6397  Eval Loss: 0.6361   Accuracy: 0.6628\n",
      "Epoch 43:  Train Loss: 0.6409  Eval Loss: 0.6390   Accuracy: 0.6433\n",
      "Epoch 44:  Train Loss: 0.6385  Eval Loss: 0.6369   Accuracy: 0.6514\n",
      "Epoch 45:  Train Loss: 0.6398  Eval Loss: 0.6399   Accuracy: 0.6525\n",
      "Epoch 46:  Train Loss: 0.6392  Eval Loss: 0.6436   Accuracy: 0.6399\n",
      "Epoch 47:  Train Loss: 0.6368  Eval Loss: 0.6386   Accuracy: 0.6502\n",
      "Epoch 48:  Train Loss: 0.6345  Eval Loss: 0.6361   Accuracy: 0.6594\n",
      "Epoch 49:  Train Loss: 0.6348  Eval Loss: 0.6341   Accuracy: 0.6548\n",
      "Epoch 50:  Train Loss: 0.6333  Eval Loss: 0.6318   Accuracy: 0.6628\n",
      "    Final Results: {'eval_loss': 0.6317752599716187, 'accuracy': 0.6628440366972477, 'best_accuracy': 0.6628440366972477}\n",
      "  Method: lora\n",
      "Epoch 1:  Train Loss: 0.6930  Eval Loss: 0.7013   Accuracy: 0.4931\n",
      "Epoch 2:  Train Loss: 0.6890  Eval Loss: 0.7037   Accuracy: 0.5069\n",
      "Epoch 3:  Train Loss: 0.6873  Eval Loss: 0.7021   Accuracy: 0.5057\n",
      "Epoch 4:  Train Loss: 0.6859  Eval Loss: 0.7003   Accuracy: 0.5069\n",
      "Epoch 5:  Train Loss: 0.6843  Eval Loss: 0.6968   Accuracy: 0.5057\n",
      "Epoch 6:  Train Loss: 0.6837  Eval Loss: 0.6956   Accuracy: 0.5080\n",
      "Epoch 7:  Train Loss: 0.6827  Eval Loss: 0.6965   Accuracy: 0.5080\n",
      "Epoch 8:  Train Loss: 0.6827  Eval Loss: 0.7007   Accuracy: 0.5092\n",
      "Epoch 9:  Train Loss: 0.6826  Eval Loss: 0.6957   Accuracy: 0.5103\n",
      "Epoch 10:  Train Loss: 0.6824  Eval Loss: 0.6935   Accuracy: 0.5080\n",
      "Epoch 11:  Train Loss: 0.6817  Eval Loss: 0.6910   Accuracy: 0.5183\n",
      "Epoch 12:  Train Loss: 0.6822  Eval Loss: 0.6922   Accuracy: 0.5138\n",
      "Epoch 13:  Train Loss: 0.6811  Eval Loss: 0.6925   Accuracy: 0.5161\n",
      "Epoch 14:  Train Loss: 0.6807  Eval Loss: 0.6915   Accuracy: 0.5149\n",
      "Epoch 15:  Train Loss: 0.6797  Eval Loss: 0.6926   Accuracy: 0.5103\n",
      "Epoch 16:  Train Loss: 0.6783  Eval Loss: 0.6899   Accuracy: 0.5115\n",
      "Epoch 17:  Train Loss: 0.6779  Eval Loss: 0.6912   Accuracy: 0.5069\n",
      "Epoch 18:  Train Loss: 0.6773  Eval Loss: 0.6895   Accuracy: 0.5183\n",
      "Epoch 19:  Train Loss: 0.6780  Eval Loss: 0.6891   Accuracy: 0.5161\n",
      "Epoch 20:  Train Loss: 0.6772  Eval Loss: 0.6886   Accuracy: 0.5206\n",
      "Epoch 21:  Train Loss: 0.6770  Eval Loss: 0.6875   Accuracy: 0.5206\n",
      "Epoch 22:  Train Loss: 0.6759  Eval Loss: 0.6860   Accuracy: 0.5218\n",
      "Epoch 23:  Train Loss: 0.6755  Eval Loss: 0.6893   Accuracy: 0.5092\n",
      "Epoch 24:  Train Loss: 0.6746  Eval Loss: 0.6877   Accuracy: 0.5126\n",
      "Epoch 25:  Train Loss: 0.6744  Eval Loss: 0.6867   Accuracy: 0.5161\n",
      "Epoch 26:  Train Loss: 0.6736  Eval Loss: 0.6859   Accuracy: 0.5229\n",
      "Epoch 27:  Train Loss: 0.6735  Eval Loss: 0.6843   Accuracy: 0.5310\n",
      "Epoch 28:  Train Loss: 0.6735  Eval Loss: 0.6834   Accuracy: 0.5310\n",
      "Epoch 29:  Train Loss: 0.6726  Eval Loss: 0.6835   Accuracy: 0.5241\n",
      "Epoch 30:  Train Loss: 0.6724  Eval Loss: 0.6820   Accuracy: 0.5424\n",
      "Epoch 31:  Train Loss: 0.6719  Eval Loss: 0.6808   Accuracy: 0.5516\n",
      "Epoch 32:  Train Loss: 0.6714  Eval Loss: 0.6816   Accuracy: 0.5378\n",
      "Epoch 33:  Train Loss: 0.6712  Eval Loss: 0.6804   Accuracy: 0.5424\n",
      "Epoch 34:  Train Loss: 0.6707  Eval Loss: 0.6793   Accuracy: 0.5482\n",
      "Epoch 35:  Train Loss: 0.6703  Eval Loss: 0.6763   Accuracy: 0.5849\n",
      "Epoch 36:  Train Loss: 0.6696  Eval Loss: 0.6773   Accuracy: 0.5757\n",
      "Epoch 37:  Train Loss: 0.6696  Eval Loss: 0.6756   Accuracy: 0.5872\n",
      "Epoch 38:  Train Loss: 0.6691  Eval Loss: 0.6753   Accuracy: 0.5883\n",
      "Epoch 39:  Train Loss: 0.6682  Eval Loss: 0.6753   Accuracy: 0.5860\n",
      "Epoch 40:  Train Loss: 0.6689  Eval Loss: 0.6728   Accuracy: 0.5986\n",
      "Epoch 41:  Train Loss: 0.6678  Eval Loss: 0.6738   Accuracy: 0.5872\n",
      "Epoch 42:  Train Loss: 0.6679  Eval Loss: 0.6737   Accuracy: 0.5872\n",
      "Epoch 43:  Train Loss: 0.6675  Eval Loss: 0.6733   Accuracy: 0.5883\n",
      "Epoch 44:  Train Loss: 0.6668  Eval Loss: 0.6710   Accuracy: 0.5940\n",
      "Epoch 45:  Train Loss: 0.6665  Eval Loss: 0.6718   Accuracy: 0.5940\n",
      "Epoch 46:  Train Loss: 0.6667  Eval Loss: 0.6718   Accuracy: 0.5883\n",
      "Epoch 47:  Train Loss: 0.6661  Eval Loss: 0.6713   Accuracy: 0.5940\n",
      "Epoch 48:  Train Loss: 0.6651  Eval Loss: 0.6697   Accuracy: 0.5998\n",
      "Epoch 49:  Train Loss: 0.6650  Eval Loss: 0.6680   Accuracy: 0.6032\n",
      "Epoch 50:  Train Loss: 0.6639  Eval Loss: 0.6679   Accuracy: 0.6032\n",
      "    Final Results: {'eval_loss': 0.6679210066795349, 'accuracy': 0.6032110091743119, 'best_accuracy': 0.6032110091743119}\n",
      "  Method: ia3\n",
      "Epoch 1:  Train Loss: 0.6861  Eval Loss: 0.7014   Accuracy: 0.5092\n",
      "Epoch 2:  Train Loss: 0.6848  Eval Loss: 0.6975   Accuracy: 0.5092\n",
      "Epoch 3:  Train Loss: 0.6833  Eval Loss: 0.6963   Accuracy: 0.5092\n",
      "Epoch 4:  Train Loss: 0.6821  Eval Loss: 0.6940   Accuracy: 0.5092\n",
      "Epoch 5:  Train Loss: 0.6815  Eval Loss: 0.6929   Accuracy: 0.5080\n",
      "Epoch 6:  Train Loss: 0.6811  Eval Loss: 0.6909   Accuracy: 0.5080\n",
      "Epoch 7:  Train Loss: 0.6810  Eval Loss: 0.6908   Accuracy: 0.5092\n",
      "Epoch 8:  Train Loss: 0.6800  Eval Loss: 0.6939   Accuracy: 0.5092\n",
      "Epoch 9:  Train Loss: 0.6794  Eval Loss: 0.6929   Accuracy: 0.5092\n",
      "Epoch 10:  Train Loss: 0.6788  Eval Loss: 0.6876   Accuracy: 0.5115\n",
      "Epoch 11:  Train Loss: 0.6779  Eval Loss: 0.6868   Accuracy: 0.5069\n",
      "Epoch 12:  Train Loss: 0.6779  Eval Loss: 0.6866   Accuracy: 0.5103\n",
      "Epoch 13:  Train Loss: 0.6763  Eval Loss: 0.6866   Accuracy: 0.5115\n",
      "Epoch 14:  Train Loss: 0.6761  Eval Loss: 0.6856   Accuracy: 0.5103\n",
      "Epoch 15:  Train Loss: 0.6752  Eval Loss: 0.6868   Accuracy: 0.5103\n",
      "Epoch 16:  Train Loss: 0.6749  Eval Loss: 0.6855   Accuracy: 0.5103\n",
      "Epoch 17:  Train Loss: 0.6738  Eval Loss: 0.6833   Accuracy: 0.5172\n",
      "Epoch 18:  Train Loss: 0.6735  Eval Loss: 0.6845   Accuracy: 0.5149\n",
      "Epoch 19:  Train Loss: 0.6725  Eval Loss: 0.6841   Accuracy: 0.5183\n",
      "Epoch 20:  Train Loss: 0.6730  Eval Loss: 0.6820   Accuracy: 0.5367\n",
      "Epoch 21:  Train Loss: 0.6736  Eval Loss: 0.6833   Accuracy: 0.5275\n",
      "Epoch 22:  Train Loss: 0.6741  Eval Loss: 0.6823   Accuracy: 0.5287\n",
      "Epoch 23:  Train Loss: 0.6722  Eval Loss: 0.6834   Accuracy: 0.5287\n",
      "Epoch 24:  Train Loss: 0.6734  Eval Loss: 0.6836   Accuracy: 0.5206\n",
      "Epoch 25:  Train Loss: 0.6732  Eval Loss: 0.6817   Accuracy: 0.5298\n",
      "Epoch 26:  Train Loss: 0.6729  Eval Loss: 0.6821   Accuracy: 0.5264\n",
      "Epoch 27:  Train Loss: 0.6724  Eval Loss: 0.6797   Accuracy: 0.5321\n",
      "Epoch 28:  Train Loss: 0.6714  Eval Loss: 0.6771   Accuracy: 0.5631\n",
      "Epoch 29:  Train Loss: 0.6712  Eval Loss: 0.6780   Accuracy: 0.5493\n",
      "Epoch 30:  Train Loss: 0.6712  Eval Loss: 0.6784   Accuracy: 0.5424\n",
      "Epoch 31:  Train Loss: 0.6705  Eval Loss: 0.6786   Accuracy: 0.5459\n",
      "Epoch 32:  Train Loss: 0.6706  Eval Loss: 0.6801   Accuracy: 0.5321\n",
      "Epoch 33:  Train Loss: 0.6694  Eval Loss: 0.6790   Accuracy: 0.5367\n",
      "Epoch 34:  Train Loss: 0.6680  Eval Loss: 0.6747   Accuracy: 0.5596\n",
      "Epoch 35:  Train Loss: 0.6673  Eval Loss: 0.6734   Accuracy: 0.5780\n",
      "Epoch 36:  Train Loss: 0.6673  Eval Loss: 0.6757   Accuracy: 0.5528\n",
      "Epoch 37:  Train Loss: 0.6668  Eval Loss: 0.6739   Accuracy: 0.5608\n",
      "Epoch 38:  Train Loss: 0.6661  Eval Loss: 0.6716   Accuracy: 0.5803\n",
      "Epoch 39:  Train Loss: 0.6670  Eval Loss: 0.6712   Accuracy: 0.5803\n",
      "Epoch 40:  Train Loss: 0.6655  Eval Loss: 0.6700   Accuracy: 0.5883\n",
      "Epoch 41:  Train Loss: 0.6654  Eval Loss: 0.6684   Accuracy: 0.5940\n",
      "Epoch 42:  Train Loss: 0.6651  Eval Loss: 0.6681   Accuracy: 0.5906\n",
      "Epoch 43:  Train Loss: 0.6642  Eval Loss: 0.6680   Accuracy: 0.5940\n",
      "Epoch 44:  Train Loss: 0.6656  Eval Loss: 0.6684   Accuracy: 0.5906\n",
      "Epoch 45:  Train Loss: 0.6636  Eval Loss: 0.6700   Accuracy: 0.5631\n",
      "Epoch 46:  Train Loss: 0.6639  Eval Loss: 0.6705   Accuracy: 0.5596\n",
      "Epoch 47:  Train Loss: 0.6629  Eval Loss: 0.6697   Accuracy: 0.5642\n",
      "Epoch 48:  Train Loss: 0.6625  Eval Loss: 0.6695   Accuracy: 0.5700\n",
      "Epoch 49:  Train Loss: 0.6620  Eval Loss: 0.6707   Accuracy: 0.5539\n",
      "Epoch 50:  Train Loss: 0.6630  Eval Loss: 0.6702   Accuracy: 0.5665\n",
      "    Final Results: {'eval_loss': 0.6702107191085815, 'accuracy': 0.5665137614678899, 'best_accuracy': 0.5940366972477065}\n",
      "  Method: single_layer_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.7487  Eval Loss: 0.7636   Accuracy: 0.4610\n",
      "Epoch 2:  Train Loss: 0.7268  Eval Loss: 0.7494   Accuracy: 0.4358\n",
      "Epoch 3:  Train Loss: 0.7233  Eval Loss: 0.7453   Accuracy: 0.4278\n",
      "Epoch 4:  Train Loss: 0.7207  Eval Loss: 0.7430   Accuracy: 0.4358\n",
      "Epoch 5:  Train Loss: 0.7180  Eval Loss: 0.7397   Accuracy: 0.4346\n",
      "Epoch 6:  Train Loss: 0.7164  Eval Loss: 0.7388   Accuracy: 0.4461\n",
      "Epoch 7:  Train Loss: 0.7136  Eval Loss: 0.7332   Accuracy: 0.4507\n",
      "Epoch 8:  Train Loss: 0.7116  Eval Loss: 0.7312   Accuracy: 0.4450\n",
      "Epoch 9:  Train Loss: 0.7095  Eval Loss: 0.7247   Accuracy: 0.4346\n",
      "Epoch 10:  Train Loss: 0.7072  Eval Loss: 0.7268   Accuracy: 0.4461\n",
      "Epoch 11:  Train Loss: 0.7068  Eval Loss: 0.7228   Accuracy: 0.4530\n",
      "Epoch 12:  Train Loss: 0.7042  Eval Loss: 0.7197   Accuracy: 0.4507\n",
      "Epoch 13:  Train Loss: 0.7010  Eval Loss: 0.7178   Accuracy: 0.4633\n",
      "Epoch 14:  Train Loss: 0.7009  Eval Loss: 0.7186   Accuracy: 0.4736\n",
      "Epoch 15:  Train Loss: 0.6991  Eval Loss: 0.7129   Accuracy: 0.4507\n",
      "Epoch 16:  Train Loss: 0.6982  Eval Loss: 0.7088   Accuracy: 0.4335\n",
      "Epoch 17:  Train Loss: 0.6961  Eval Loss: 0.7092   Accuracy: 0.4782\n",
      "Epoch 18:  Train Loss: 0.6944  Eval Loss: 0.7044   Accuracy: 0.4725\n",
      "Epoch 19:  Train Loss: 0.6923  Eval Loss: 0.7023   Accuracy: 0.4851\n",
      "Epoch 20:  Train Loss: 0.6904  Eval Loss: 0.7022   Accuracy: 0.4943\n",
      "Epoch 21:  Train Loss: 0.6899  Eval Loss: 0.7004   Accuracy: 0.4908\n",
      "Epoch 22:  Train Loss: 0.6887  Eval Loss: 0.6999   Accuracy: 0.4954\n",
      "Epoch 23:  Train Loss: 0.6887  Eval Loss: 0.7012   Accuracy: 0.5011\n",
      "Epoch 24:  Train Loss: 0.6885  Eval Loss: 0.6968   Accuracy: 0.4977\n",
      "Epoch 25:  Train Loss: 0.6882  Eval Loss: 0.6992   Accuracy: 0.4954\n",
      "Epoch 26:  Train Loss: 0.6879  Eval Loss: 0.6980   Accuracy: 0.4966\n",
      "Epoch 27:  Train Loss: 0.6869  Eval Loss: 0.6985   Accuracy: 0.5023\n",
      "Epoch 28:  Train Loss: 0.6871  Eval Loss: 0.6949   Accuracy: 0.4989\n",
      "Epoch 29:  Train Loss: 0.6866  Eval Loss: 0.6946   Accuracy: 0.5115\n",
      "Epoch 30:  Train Loss: 0.6849  Eval Loss: 0.6909   Accuracy: 0.5241\n",
      "Epoch 31:  Train Loss: 0.6840  Eval Loss: 0.6903   Accuracy: 0.5241\n",
      "Epoch 32:  Train Loss: 0.6827  Eval Loss: 0.6903   Accuracy: 0.5264\n",
      "Epoch 33:  Train Loss: 0.6817  Eval Loss: 0.6897   Accuracy: 0.5298\n",
      "Epoch 34:  Train Loss: 0.6817  Eval Loss: 0.6905   Accuracy: 0.5287\n",
      "Epoch 35:  Train Loss: 0.6817  Eval Loss: 0.6895   Accuracy: 0.5390\n",
      "Epoch 36:  Train Loss: 0.6807  Eval Loss: 0.6867   Accuracy: 0.5401\n",
      "Epoch 37:  Train Loss: 0.6816  Eval Loss: 0.6862   Accuracy: 0.5447\n",
      "Epoch 38:  Train Loss: 0.6807  Eval Loss: 0.6865   Accuracy: 0.5367\n",
      "Epoch 39:  Train Loss: 0.6803  Eval Loss: 0.6855   Accuracy: 0.5378\n",
      "Epoch 40:  Train Loss: 0.6807  Eval Loss: 0.6862   Accuracy: 0.5447\n",
      "Epoch 41:  Train Loss: 0.6804  Eval Loss: 0.6852   Accuracy: 0.5482\n",
      "Epoch 42:  Train Loss: 0.6796  Eval Loss: 0.6830   Accuracy: 0.5539\n",
      "Epoch 43:  Train Loss: 0.6790  Eval Loss: 0.6812   Accuracy: 0.5665\n",
      "Epoch 44:  Train Loss: 0.6784  Eval Loss: 0.6808   Accuracy: 0.5642\n",
      "Epoch 45:  Train Loss: 0.6776  Eval Loss: 0.6818   Accuracy: 0.5619\n",
      "Epoch 46:  Train Loss: 0.6779  Eval Loss: 0.6817   Accuracy: 0.5573\n",
      "Epoch 47:  Train Loss: 0.6771  Eval Loss: 0.6800   Accuracy: 0.5631\n",
      "Epoch 48:  Train Loss: 0.6755  Eval Loss: 0.6774   Accuracy: 0.5734\n",
      "Epoch 49:  Train Loss: 0.6756  Eval Loss: 0.6751   Accuracy: 0.5826\n",
      "Epoch 50:  Train Loss: 0.6753  Eval Loss: 0.6752   Accuracy: 0.5872\n",
      "    Final Results: {'eval_loss': 0.6751946210861206, 'accuracy': 0.5871559633027523, 'best_accuracy': 0.5871559633027523}\n",
      "  Method: soft_prompt_lora\n",
      "Epoch 1:  Train Loss: 0.7539  Eval Loss: 0.7297   Accuracy: 0.4908\n",
      "Epoch 2:  Train Loss: 0.7536  Eval Loss: 0.7296   Accuracy: 0.4908\n",
      "Epoch 3:  Train Loss: 0.7535  Eval Loss: 0.7295   Accuracy: 0.4908\n",
      "Epoch 4:  Train Loss: 0.7533  Eval Loss: 0.7295   Accuracy: 0.4908\n",
      "Epoch 5:  Train Loss: 0.7531  Eval Loss: 0.7292   Accuracy: 0.4908\n",
      "Epoch 6:  Train Loss: 0.7530  Eval Loss: 0.7290   Accuracy: 0.4908\n",
      "Epoch 7:  Train Loss: 0.7529  Eval Loss: 0.7288   Accuracy: 0.4908\n",
      "Epoch 8:  Train Loss: 0.7527  Eval Loss: 0.7284   Accuracy: 0.4908\n",
      "Epoch 9:  Train Loss: 0.7522  Eval Loss: 0.7283   Accuracy: 0.4908\n",
      "Epoch 10:  Train Loss: 0.7526  Eval Loss: 0.7283   Accuracy: 0.4908\n",
      "Epoch 11:  Train Loss: 0.7526  Eval Loss: 0.7280   Accuracy: 0.4908\n",
      "Epoch 12:  Train Loss: 0.7523  Eval Loss: 0.7279   Accuracy: 0.4908\n",
      "Epoch 13:  Train Loss: 0.7518  Eval Loss: 0.7280   Accuracy: 0.4908\n",
      "Epoch 14:  Train Loss: 0.7523  Eval Loss: 0.7278   Accuracy: 0.4908\n",
      "Epoch 15:  Train Loss: 0.7522  Eval Loss: 0.7280   Accuracy: 0.4908\n",
      "Epoch 16:  Train Loss: 0.7517  Eval Loss: 0.7281   Accuracy: 0.4908\n",
      "Epoch 17:  Train Loss: 0.7525  Eval Loss: 0.7279   Accuracy: 0.4908\n",
      "Epoch 18:  Train Loss: 0.7524  Eval Loss: 0.7277   Accuracy: 0.4908\n",
      "Epoch 19:  Train Loss: 0.7520  Eval Loss: 0.7277   Accuracy: 0.4908\n",
      "Epoch 20:  Train Loss: 0.7522  Eval Loss: 0.7277   Accuracy: 0.4908\n",
      "Epoch 21:  Train Loss: 0.7519  Eval Loss: 0.7278   Accuracy: 0.4908\n",
      "Epoch 22:  Train Loss: 0.7516  Eval Loss: 0.7278   Accuracy: 0.4908\n",
      "Epoch 23:  Train Loss: 0.7516  Eval Loss: 0.7278   Accuracy: 0.4908\n",
      "Epoch 24:  Train Loss: 0.7517  Eval Loss: 0.7277   Accuracy: 0.4908\n",
      "Epoch 25:  Train Loss: 0.7513  Eval Loss: 0.7275   Accuracy: 0.4908\n",
      "Epoch 26:  Train Loss: 0.7509  Eval Loss: 0.7273   Accuracy: 0.4908\n",
      "Epoch 27:  Train Loss: 0.7509  Eval Loss: 0.7269   Accuracy: 0.4908\n",
      "Epoch 28:  Train Loss: 0.7505  Eval Loss: 0.7269   Accuracy: 0.4908\n",
      "Epoch 29:  Train Loss: 0.7504  Eval Loss: 0.7265   Accuracy: 0.4908\n",
      "Epoch 30:  Train Loss: 0.7501  Eval Loss: 0.7262   Accuracy: 0.4908\n",
      "Epoch 31:  Train Loss: 0.7491  Eval Loss: 0.7254   Accuracy: 0.4908\n",
      "Epoch 32:  Train Loss: 0.7488  Eval Loss: 0.7257   Accuracy: 0.4908\n",
      "Epoch 33:  Train Loss: 0.7491  Eval Loss: 0.7258   Accuracy: 0.4908\n",
      "Epoch 34:  Train Loss: 0.7498  Eval Loss: 0.7258   Accuracy: 0.4908\n",
      "Epoch 35:  Train Loss: 0.7493  Eval Loss: 0.7258   Accuracy: 0.4908\n",
      "Epoch 36:  Train Loss: 0.7493  Eval Loss: 0.7259   Accuracy: 0.4908\n",
      "Epoch 37:  Train Loss: 0.7488  Eval Loss: 0.7256   Accuracy: 0.4908\n",
      "Epoch 38:  Train Loss: 0.7485  Eval Loss: 0.7252   Accuracy: 0.4908\n",
      "Epoch 39:  Train Loss: 0.7485  Eval Loss: 0.7247   Accuracy: 0.4908\n",
      "Epoch 40:  Train Loss: 0.7488  Eval Loss: 0.7246   Accuracy: 0.4908\n",
      "Epoch 41:  Train Loss: 0.7484  Eval Loss: 0.7246   Accuracy: 0.4908\n",
      "Epoch 42:  Train Loss: 0.7484  Eval Loss: 0.7245   Accuracy: 0.4908\n",
      "Epoch 43:  Train Loss: 0.7485  Eval Loss: 0.7245   Accuracy: 0.4908\n",
      "Epoch 44:  Train Loss: 0.7482  Eval Loss: 0.7245   Accuracy: 0.4908\n",
      "Epoch 45:  Train Loss: 0.7484  Eval Loss: 0.7243   Accuracy: 0.4908\n",
      "Epoch 46:  Train Loss: 0.7476  Eval Loss: 0.7238   Accuracy: 0.4908\n",
      "Epoch 47:  Train Loss: 0.7473  Eval Loss: 0.7239   Accuracy: 0.4908\n",
      "Epoch 48:  Train Loss: 0.7476  Eval Loss: 0.7238   Accuracy: 0.4908\n",
      "Epoch 49:  Train Loss: 0.7477  Eval Loss: 0.7230   Accuracy: 0.4908\n",
      "Epoch 50:  Train Loss: 0.7470  Eval Loss: 0.7229   Accuracy: 0.4908\n",
      "    Final Results: {'eval_loss': 0.722938060760498, 'accuracy': 0.4908256880733945, 'best_accuracy': 0.4908256880733945}\n",
      "  Method: prefix_lora\n",
      "Epoch 1:  Train Loss: 0.6936  Eval Loss: 0.6938   Accuracy: 0.5023\n",
      "Epoch 2:  Train Loss: 0.6936  Eval Loss: 0.6938   Accuracy: 0.5011\n",
      "Epoch 3:  Train Loss: 0.6933  Eval Loss: 0.6939   Accuracy: 0.5023\n",
      "Epoch 4:  Train Loss: 0.6932  Eval Loss: 0.6939   Accuracy: 0.5023\n",
      "Epoch 5:  Train Loss: 0.6937  Eval Loss: 0.6939   Accuracy: 0.5011\n",
      "Epoch 6:  Train Loss: 0.6933  Eval Loss: 0.6938   Accuracy: 0.5000\n",
      "Epoch 7:  Train Loss: 0.6935  Eval Loss: 0.6938   Accuracy: 0.4989\n",
      "Epoch 8:  Train Loss: 0.6929  Eval Loss: 0.6938   Accuracy: 0.4989\n",
      "Epoch 9:  Train Loss: 0.6935  Eval Loss: 0.6938   Accuracy: 0.4966\n",
      "Epoch 10:  Train Loss: 0.6933  Eval Loss: 0.6937   Accuracy: 0.5034\n",
      "Epoch 11:  Train Loss: 0.6931  Eval Loss: 0.6937   Accuracy: 0.5011\n",
      "Epoch 12:  Train Loss: 0.6934  Eval Loss: 0.6937   Accuracy: 0.4954\n",
      "Epoch 13:  Train Loss: 0.6931  Eval Loss: 0.6938   Accuracy: 0.5034\n",
      "Epoch 14:  Train Loss: 0.6936  Eval Loss: 0.6937   Accuracy: 0.5011\n",
      "Epoch 15:  Train Loss: 0.6934  Eval Loss: 0.6936   Accuracy: 0.4989\n",
      "Epoch 16:  Train Loss: 0.6931  Eval Loss: 0.6936   Accuracy: 0.4931\n",
      "Epoch 17:  Train Loss: 0.6932  Eval Loss: 0.6936   Accuracy: 0.5000\n",
      "Epoch 18:  Train Loss: 0.6935  Eval Loss: 0.6936   Accuracy: 0.4989\n",
      "Epoch 19:  Train Loss: 0.6932  Eval Loss: 0.6937   Accuracy: 0.4989\n",
      "Epoch 20:  Train Loss: 0.6938  Eval Loss: 0.6937   Accuracy: 0.4977\n",
      "Epoch 21:  Train Loss: 0.6934  Eval Loss: 0.6937   Accuracy: 0.5011\n",
      "Epoch 22:  Train Loss: 0.6929  Eval Loss: 0.6937   Accuracy: 0.5000\n",
      "Epoch 23:  Train Loss: 0.6931  Eval Loss: 0.6937   Accuracy: 0.5000\n",
      "Epoch 24:  Train Loss: 0.6928  Eval Loss: 0.6937   Accuracy: 0.5034\n",
      "Epoch 25:  Train Loss: 0.6927  Eval Loss: 0.6937   Accuracy: 0.5023\n",
      "Epoch 26:  Train Loss: 0.6931  Eval Loss: 0.6938   Accuracy: 0.4989\n",
      "Epoch 27:  Train Loss: 0.6929  Eval Loss: 0.6939   Accuracy: 0.4989\n",
      "Epoch 28:  Train Loss: 0.6931  Eval Loss: 0.6939   Accuracy: 0.5011\n",
      "Epoch 29:  Train Loss: 0.6929  Eval Loss: 0.6939   Accuracy: 0.4989\n",
      "Epoch 30:  Train Loss: 0.6931  Eval Loss: 0.6939   Accuracy: 0.5034\n",
      "Epoch 31:  Train Loss: 0.6929  Eval Loss: 0.6939   Accuracy: 0.5011\n",
      "Epoch 32:  Train Loss: 0.6928  Eval Loss: 0.6939   Accuracy: 0.5046\n",
      "Epoch 33:  Train Loss: 0.6929  Eval Loss: 0.6939   Accuracy: 0.5057\n",
      "Epoch 34:  Train Loss: 0.6924  Eval Loss: 0.6938   Accuracy: 0.5023\n",
      "Epoch 35:  Train Loss: 0.6925  Eval Loss: 0.6938   Accuracy: 0.5057\n",
      "Epoch 36:  Train Loss: 0.6925  Eval Loss: 0.6935   Accuracy: 0.5011\n",
      "Epoch 37:  Train Loss: 0.6924  Eval Loss: 0.6935   Accuracy: 0.5011\n",
      "Epoch 38:  Train Loss: 0.6924  Eval Loss: 0.6934   Accuracy: 0.4977\n",
      "Epoch 39:  Train Loss: 0.6925  Eval Loss: 0.6935   Accuracy: 0.5011\n",
      "Epoch 40:  Train Loss: 0.6925  Eval Loss: 0.6935   Accuracy: 0.4966\n",
      "Epoch 41:  Train Loss: 0.6926  Eval Loss: 0.6934   Accuracy: 0.4943\n",
      "Epoch 42:  Train Loss: 0.6924  Eval Loss: 0.6935   Accuracy: 0.4943\n",
      "Epoch 43:  Train Loss: 0.6926  Eval Loss: 0.6934   Accuracy: 0.4920\n",
      "Epoch 44:  Train Loss: 0.6923  Eval Loss: 0.6933   Accuracy: 0.4977\n",
      "Epoch 45:  Train Loss: 0.6925  Eval Loss: 0.6934   Accuracy: 0.4977\n",
      "Epoch 46:  Train Loss: 0.6921  Eval Loss: 0.6932   Accuracy: 0.4966\n",
      "Epoch 47:  Train Loss: 0.6923  Eval Loss: 0.6933   Accuracy: 0.4977\n",
      "Epoch 48:  Train Loss: 0.6924  Eval Loss: 0.6932   Accuracy: 0.4966\n",
      "Epoch 49:  Train Loss: 0.6925  Eval Loss: 0.6933   Accuracy: 0.4977\n",
      "Epoch 50:  Train Loss: 0.6925  Eval Loss: 0.6933   Accuracy: 0.4943\n",
      "    Final Results: {'eval_loss': 0.6933218836784363, 'accuracy': 0.49426605504587157, 'best_accuracy': 0.5057339449541285}\n",
      "==================================================\n",
      "\n",
      "Results for sst2:\n",
      "  Method: soft_prompt, Accuracy: 0.5092, Loss: 0.6943\n",
      "  Method: prefix, Accuracy: 0.5940, Loss: 0.6598\n",
      "  Method: full_fine_tuning, Accuracy: 0.6628, Loss: 0.6318\n",
      "  Method: lora, Accuracy: 0.6032, Loss: 0.6679\n",
      "  Method: ia3, Accuracy: 0.5665, Loss: 0.6702\n",
      "  Method: single_layer_fine_tuning, Accuracy: 0.5872, Loss: 0.6752\n",
      "  Method: soft_prompt_lora, Accuracy: 0.4908, Loss: 0.7229\n",
      "  Method: prefix_lora, Accuracy: 0.4943, Loss: 0.6933\n",
      "\n",
      "Results have been appended to peft_experiment_results.txt\n"
     ]
    }
   ],
   "source": [
    "results = run_peft_experiments(epsilon=0,dataset=['sst2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf886c6f-34c2-404f-b4fa-4167a844b848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
