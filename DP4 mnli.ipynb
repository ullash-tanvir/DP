{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be948b88-1b5e-460d-83be-b204abf2912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tislam/.conda/envs/tfgpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tislam/.conda/envs/tfgpu/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer, Trainer, \n",
    "                        TrainingArguments, DataCollatorWithPadding, default_data_collator)\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    PromptTuningConfig,\n",
    "    PrefixTuningConfig,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    TaskType,\n",
    ")\n",
    "from opacus.privacy_engine import GradSampleModule\n",
    "from opacus.optimizers import DPOptimizer\n",
    "from opacus import PrivacyEngine\n",
    "from transformers import DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c3d767-904e-4c99-9087-8c03512ea5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44f61fd-2f3e-401b-aa36-0a00eecdb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "logging.getLogger(\"torch\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86705d8e-5f20-424a-b097-4b4d81416cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the model and tokenizer\n",
    "def setup_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "        print(f\"Using {n_gpu} GPU(s)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        n_gpu = 0\n",
    "        print(\"Using CPU\")\n",
    "    return device, n_gpu\n",
    "\n",
    "def load_model_and_tokenizer(model_name, num_labels):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=num_labels,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to prepare the dataset\n",
    "def prepare_dataset(dataset_name, tokenizer):\n",
    "    # Load the dataset from Hugging Face Datasets\n",
    "    dataset = load_dataset('glue', dataset_name)\n",
    "\n",
    "    # Tokenization function depending on the dataset\n",
    "    def tokenize_function(examples):\n",
    "        if dataset_name.lower() == \"sst2\":\n",
    "            return tokenizer(\n",
    "                examples[\"sentence\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"qqp\":\n",
    "            return tokenizer(\n",
    "                examples[\"question1\"],\n",
    "                examples[\"question2\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"qnli\":\n",
    "            return tokenizer(\n",
    "                examples[\"question\"],\n",
    "                examples[\"sentence\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"mnli\":\n",
    "            return tokenizer(\n",
    "                examples[\"premise\"],\n",
    "                examples[\"hypothesis\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Dataset {dataset_name} is not supported.\")\n",
    "\n",
    "    # Determine which columns to remove\n",
    "    columns_to_remove = set(dataset[\"train\"].column_names) - {\"label\"}\n",
    "\n",
    "    # Apply the tokenization to the dataset\n",
    "    tokenized_datasets = dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=list(columns_to_remove)  # Remove all columns except 'label'\n",
    "    )\n",
    "\n",
    "    # Rename 'label' to 'labels'\n",
    "    tokenized_datasets = tokenized_datasets.map(\n",
    "        lambda examples: {\"labels\": examples[\"label\"]},\n",
    "        remove_columns=[\"label\"]\n",
    "    )\n",
    "\n",
    "    # Convert the datasets to PyTorch tensors\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "    return tokenized_datasets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to compute metrics during evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Get the predictions by taking the argmax over logits\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Compute accuracy by comparing predictions and labels\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    # Return the accuracy inside a dictionary\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Function to get the PEFT configuration based on the method\n",
    "def get_peft_config(method):\n",
    "    if method == \"soft_prompt\":\n",
    "        peft_config = PromptTuningConfig(\n",
    "            task_type=TaskType.SEQ_CLS, num_virtual_tokens=20\n",
    "        )\n",
    "    elif method == \"prefix\":\n",
    "        peft_config = PrefixTuningConfig(\n",
    "            task_type=TaskType.SEQ_CLS, num_virtual_tokens=20\n",
    "        )\n",
    "    elif method == \"lora\":\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "        )\n",
    "    elif method == \"ia3\":\n",
    "        peft_config = IA3Config(task_type=TaskType.SEQ_CLS)\n",
    "    elif method == \"soft_prompt_lora\":\n",
    "        # Combine Prompt Tuning and LoRA\n",
    "        peft_config = [\n",
    "            PromptTuningConfig(task_type=TaskType.SEQ_CLS, num_virtual_tokens=20),\n",
    "            LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "            ),\n",
    "        ]\n",
    "    elif method == \"prefix_lora\":\n",
    "        # Combine Prefix Tuning and LoRA\n",
    "        peft_config = [\n",
    "            PrefixTuningConfig(task_type=TaskType.SEQ_CLS, num_virtual_tokens=20),\n",
    "            LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "            ),\n",
    "        ]\n",
    "    else:\n",
    "        peft_config = None\n",
    "    return peft_config\n",
    "\n",
    "def get_validation_dataset(tokenized_datasets):\n",
    "    # Check for common validation set names and return the first that exists\n",
    "    for val_name in [\"validation\", \"validation_matched\", \"validation_mismatched\"]:\n",
    "        if val_name in tokenized_datasets:\n",
    "            return tokenized_datasets[val_name]\n",
    "    raise ValueError(\"No valid validation set found.\")\n",
    "\n",
    "\n",
    "def create_dp_optimizer(model, learning_rate, epsilon, delta, expected_batch_size):\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    \n",
    "    # Wrap the model with GradSampleModule\n",
    "    model = GradSampleModule(model)\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Make optimizer differentially private\n",
    "    dp_optimizer = DPOptimizer(\n",
    "        optimizer=optimizer,\n",
    "        noise_multiplier=1.3,\n",
    "        max_grad_norm=1.0,\n",
    "        expected_batch_size=expected_batch_size\n",
    "    )\n",
    "\n",
    "    return model, dp_optimizer\n",
    "\n",
    "def compute_dp_noise_scale(epsilon, delta, sample_rate, steps):\n",
    "    \"\"\"Compute noise scale for DP-SGD.\"\"\"\n",
    "    return np.sqrt(2 * np.log(1.25 / delta)) / (epsilon * np.sqrt(steps * sample_rate))\n",
    "\n",
    "def add_noise_to_grads(model, noise_scale, max_grad_norm):\n",
    "    \"\"\"Add noise to gradients for Differential Privacy.\"\"\"\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** 0.5\n",
    "\n",
    "    clip_coef = max_grad_norm / (total_norm + 1e-6)\n",
    "    clip_coef = min(clip_coef, 1.0)  # Clamp without using torch.clamp\n",
    "\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            p.grad.data.mul_(clip_coef)\n",
    "            noise = torch.randn_like(p.grad) * noise_scale * max_grad_norm\n",
    "            p.grad.data.add_(noise)\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_results_to_file(results, epsilon):\n",
    "    filename = \"peft_experiment_results.txt\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Read existing content\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            existing_content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        existing_content = \"\"\n",
    "    \n",
    "    # Prepare new content\n",
    "    new_content = f\"\\n\\n--- Experiment Results ({timestamp}) ---\\n\"\n",
    "    new_content += f\"Epsilon: {epsilon}\\n\" if epsilon is not None else \"No Differential Privacy\\n\"\n",
    "    new_content += json.dumps(results, indent=2)\n",
    "    \n",
    "    # Combine existing and new content\n",
    "    updated_content = existing_content + new_content\n",
    "    \n",
    "    # Write updated content back to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(updated_content)\n",
    "    \n",
    "    print(f\"\\nResults have been appended to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe3d190-183c-49b9-8923-6d18d7cb158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_peft_experiments(dataset, epsilon=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model_name = \"prajjwal1/bert-tiny\"\n",
    "    # datasets = [\"sst2\", \"qnli\", \"qqp\", \"mnli\"]\n",
    "    methods = [\n",
    "        \"soft_prompt\",\n",
    "        \"prefix\",\n",
    "        \"full_fine_tuning\",\n",
    "        \"lora\",\n",
    "        \"ia3\",\n",
    "        \"single_layer_fine_tuning\",\n",
    "        \"soft_prompt_lora\",\n",
    "        \"prefix_lora\",\n",
    "    ]\n",
    "    \n",
    "    # Dataset-specific parameters\n",
    "    dataset_params = {\n",
    "        \"sst2\": {\"lambda\": 1e-5, \"noise_multiplier\": 0.92, \"num_labels\": 2},\n",
    "        \"qnli\": {\"lambda\": 1e-5, \"noise_multiplier\": 0.83, \"num_labels\": 2},\n",
    "        \"qqp\": {\"lambda\": 1e-6, \"noise_multiplier\": 0.66, \"num_labels\": 2},\n",
    "        \"mnli\": {\"lambda\": 1e-6, \"noise_multiplier\": 0.65, \"num_labels\": 3},\n",
    "    }\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    for dataset_name in dataset:\n",
    "        print(f\"Processing dataset: {dataset_name}\")\n",
    "        \n",
    "        params = dataset_params[dataset_name]\n",
    "        num_labels = params[\"num_labels\"]\n",
    "        \n",
    "        model, tokenizer = load_model_and_tokenizer(model_name, num_labels)\n",
    "        tokenized_dataset = prepare_dataset(dataset_name, tokenizer)\n",
    "        \n",
    "        results_dict[dataset_name] = {}\n",
    "        \n",
    "        for method in methods:\n",
    "            print(f\"  Method: {method}\")\n",
    "            model, tokenizer = load_model_and_tokenizer(model_name, num_labels)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            if method == \"full_fine_tuning\":\n",
    "                peft_model = model\n",
    "            elif method == \"single_layer_fine_tuning\":\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "                model.classifier = torch.nn.Linear(model.config.hidden_size, num_labels).to(device)\n",
    "                peft_model = model\n",
    "            else:\n",
    "                peft_config = get_peft_config(method)\n",
    "                if isinstance(peft_config, list):\n",
    "                    peft_model = model\n",
    "                    for config in peft_config:\n",
    "                        peft_model = get_peft_model(peft_model, config)\n",
    "                else:\n",
    "                    peft_model = get_peft_model(model, peft_config)\n",
    "            peft_model = peft_model.to(device)\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=f\"./results/{dataset_name}_{method}\",\n",
    "                num_train_epochs=50,\n",
    "                per_device_train_batch_size=1024,\n",
    "                per_device_eval_batch_size=1024,\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                save_strategy=\"epoch\",\n",
    "                logging_dir=f\"./logs/{dataset_name}_{method}\",\n",
    "                logging_steps=100,\n",
    "                learning_rate=5e-4,\n",
    "                load_best_model_at_end=False,\n",
    "                save_total_limit=1,\n",
    "            )\n",
    "            \n",
    "            train_dataloader = torch.utils.data.DataLoader(\n",
    "                tokenized_dataset[\"train\"],\n",
    "                batch_size=training_args.per_device_train_batch_size,\n",
    "                shuffle=True,\n",
    "                collate_fn=default_data_collator,\n",
    "            )\n",
    "            \n",
    "            eval_dataloader = torch.utils.data.DataLoader(\n",
    "                get_validation_dataset(tokenized_dataset),\n",
    "                batch_size=training_args.per_device_eval_batch_size,\n",
    "                collate_fn=default_data_collator,\n",
    "            )\n",
    "            \n",
    "            if epsilon is not None:\n",
    "                results = train_with_dp(\n",
    "                    peft_model=peft_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    eval_dataloader=eval_dataloader,\n",
    "                    device=device,\n",
    "                    epsilon=epsilon,\n",
    "                    delta=params[\"lambda\"],\n",
    "                    noise_multiplier=params[\"noise_multiplier\"],\n",
    "                    epochs=int(training_args.num_train_epochs),\n",
    "                    batch_size=training_args.per_device_train_batch_size,\n",
    "                    max_grad_norm=1.0,\n",
    "                    learning_rate=training_args.learning_rate,\n",
    "                    weight_decay=1e-2\n",
    "                )\n",
    "            else:\n",
    "                # Train without differential privacy\n",
    "                results = train_without_dp(\n",
    "                    peft_model=peft_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    eval_dataloader=eval_dataloader,\n",
    "                    device=device,\n",
    "                    epochs=int(training_args.num_train_epochs),\n",
    "                    learning_rate=training_args.learning_rate,\n",
    "                    weight_decay=1e-2\n",
    "                )\n",
    "            \n",
    "            results_dict[dataset_name][method] = results\n",
    "            print(f\"    Final Results: {results}\")\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"=\"*50)\n",
    "    for dataset_name in dataset:\n",
    "        print(f\"\\nResults for {dataset_name}:\")\n",
    "        for method, result in results_dict[dataset_name].items():\n",
    "            accuracy = result.get(\"accuracy\", \"N/A\")\n",
    "            loss = result.get(\"eval_loss\", \"N/A\")\n",
    "            print(f\"  Method: {method}, Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    # Save results to file\n",
    "    save_results_to_file(results_dict, epsilon)\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "def train_with_dp(peft_model, train_dataloader, eval_dataloader, device, epsilon, delta, noise_multiplier, epochs, batch_size, max_grad_norm, learning_rate, weight_decay):\n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        peft_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = peft_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(peft_model.parameters(), max_grad_norm)\n",
    "            \n",
    "            # Add noise to gradients\n",
    "            for param in peft_model.parameters():\n",
    "                if param.requires_grad and param.grad is not None:\n",
    "                    noise = torch.randn_like(param.grad) * noise_multiplier * max_grad_norm\n",
    "                    param.grad.add_(noise)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_results = evaluate(peft_model, eval_dataloader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:  Train Loss: {avg_train_loss:.4f}  Eval Loss: {eval_results['eval_loss']:.4f}   Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "\n",
    "        \n",
    "        if eval_results['accuracy'] > best_accuracy:\n",
    "            best_accuracy = eval_results['accuracy']\n",
    "            # print(f\"  New best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    return {\"eval_loss\": eval_results['eval_loss'], \"accuracy\": eval_results['accuracy'], \"best_accuracy\": best_accuracy}\n",
    "\n",
    "def train_without_dp(peft_model, train_dataloader, eval_dataloader, device, epochs, learning_rate, weight_decay):\n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        peft_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = peft_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_results = evaluate(peft_model, eval_dataloader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:   Train Loss: {avg_train_loss:.4f}   Eval Loss: {eval_results['eval_loss']:.4f}   Accuracy: {eval_results['accuracy']:.4f} \")\n",
    "\n",
    "        \n",
    "        if eval_results['accuracy'] > best_accuracy:\n",
    "            best_accuracy = eval_results['accuracy']\n",
    "            # print(f\"  New best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    return {\"eval_loss\": eval_results['eval_loss'], \"accuracy\": eval_results['accuracy'], \"best_accuracy\": best_accuracy}\n",
    "\n",
    "def evaluate(model, eval_dataloader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_steps = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            eval_loss += outputs.loss.item()\n",
    "            eval_steps += 1\n",
    "            all_preds.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "    \n",
    "    eval_loss = eval_loss / eval_steps\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    return {\"eval_loss\": eval_loss, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd36835-b0a4-47ee-ac08-150a0b0b62d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing dataset: mnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 392702/392702 [00:31<00:00, 12349.07 examples/s]\n",
      "Map: 100%|██████████| 9815/9815 [00:00<00:00, 13397.61 examples/s]\n",
      "Map: 100%|██████████| 9832/9832 [00:00<00:00, 10000.03 examples/s]\n",
      "Map: 100%|██████████| 9796/9796 [00:00<00:00, 13682.20 examples/s]\n",
      "Map: 100%|██████████| 9847/9847 [00:00<00:00, 13031.35 examples/s]\n",
      "Map: 100%|██████████| 392702/392702 [00:22<00:00, 17258.15 examples/s]\n",
      "Map: 100%|██████████| 9815/9815 [00:00<00:00, 16400.62 examples/s]\n",
      "Map: 100%|██████████| 9832/9832 [00:00<00:00, 25097.88 examples/s]\n",
      "Map: 100%|██████████| 9796/9796 [00:00<00:00, 25527.70 examples/s]\n",
      "Map: 100%|██████████| 9847/9847 [00:00<00:00, 24633.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Method: soft_prompt\n",
      "Epoch 1:  Train Loss: 1.1001  Eval Loss: 1.0972   Accuracy: 0.3555\n",
      "Epoch 2:  Train Loss: 1.0989  Eval Loss: 1.0953   Accuracy: 0.3710\n",
      "Epoch 3:  Train Loss: 1.0984  Eval Loss: 1.0977   Accuracy: 0.3443\n",
      "Epoch 4:  Train Loss: 1.0990  Eval Loss: 1.0978   Accuracy: 0.3464\n",
      "Epoch 5:  Train Loss: 1.0986  Eval Loss: 1.0945   Accuracy: 0.3692\n",
      "Epoch 6:  Train Loss: 1.0981  Eval Loss: 1.0941   Accuracy: 0.3697\n",
      "Epoch 7:  Train Loss: 1.0980  Eval Loss: 1.0953   Accuracy: 0.3632\n",
      "Epoch 8:  Train Loss: 1.0985  Eval Loss: 1.0935   Accuracy: 0.3730\n",
      "Epoch 9:  Train Loss: 1.0987  Eval Loss: 1.0931   Accuracy: 0.3724\n",
      "Epoch 10:  Train Loss: 1.0983  Eval Loss: 1.0925   Accuracy: 0.3749\n",
      "Epoch 11:  Train Loss: 1.0983  Eval Loss: 1.0931   Accuracy: 0.3737\n",
      "Epoch 12:  Train Loss: 1.0987  Eval Loss: 1.0930   Accuracy: 0.3715\n",
      "Epoch 13:  Train Loss: 1.0991  Eval Loss: 1.0945   Accuracy: 0.3642\n",
      "Epoch 14:  Train Loss: 1.0993  Eval Loss: 1.0927   Accuracy: 0.3724\n",
      "Epoch 15:  Train Loss: 1.0985  Eval Loss: 1.0921   Accuracy: 0.3761\n",
      "Epoch 16:  Train Loss: 1.0989  Eval Loss: 1.0922   Accuracy: 0.3789\n",
      "Epoch 17:  Train Loss: 1.0989  Eval Loss: 1.0925   Accuracy: 0.3765\n",
      "Epoch 18:  Train Loss: 1.0985  Eval Loss: 1.0904   Accuracy: 0.3856\n",
      "Epoch 19:  Train Loss: 1.0984  Eval Loss: 1.0912   Accuracy: 0.3788\n",
      "Epoch 20:  Train Loss: 1.0981  Eval Loss: 1.0927   Accuracy: 0.3706\n",
      "Epoch 21:  Train Loss: 1.0985  Eval Loss: 1.0923   Accuracy: 0.3756\n",
      "Epoch 22:  Train Loss: 1.0978  Eval Loss: 1.0900   Accuracy: 0.3768\n",
      "Epoch 23:  Train Loss: 1.0972  Eval Loss: 1.0899   Accuracy: 0.3806\n",
      "Epoch 24:  Train Loss: 1.0971  Eval Loss: 1.0893   Accuracy: 0.3841\n",
      "Epoch 25:  Train Loss: 1.0973  Eval Loss: 1.0930   Accuracy: 0.3665\n",
      "Epoch 26:  Train Loss: 1.0974  Eval Loss: 1.0900   Accuracy: 0.3781\n",
      "Epoch 27:  Train Loss: 1.0976  Eval Loss: 1.0931   Accuracy: 0.3686\n",
      "Epoch 28:  Train Loss: 1.0982  Eval Loss: 1.0907   Accuracy: 0.3744\n",
      "Epoch 29:  Train Loss: 1.0978  Eval Loss: 1.0923   Accuracy: 0.3653\n",
      "Epoch 30:  Train Loss: 1.0980  Eval Loss: 1.0905   Accuracy: 0.3765\n",
      "Epoch 31:  Train Loss: 1.0985  Eval Loss: 1.0924   Accuracy: 0.3698\n",
      "Epoch 32:  Train Loss: 1.0989  Eval Loss: 1.0914   Accuracy: 0.3744\n",
      "Epoch 33:  Train Loss: 1.0989  Eval Loss: 1.0948   Accuracy: 0.3637\n",
      "Epoch 34:  Train Loss: 1.0996  Eval Loss: 1.0916   Accuracy: 0.3720\n",
      "Epoch 35:  Train Loss: 1.0999  Eval Loss: 1.0913   Accuracy: 0.3741\n",
      "Epoch 36:  Train Loss: 1.0996  Eval Loss: 1.0916   Accuracy: 0.3732\n",
      "Epoch 37:  Train Loss: 1.1000  Eval Loss: 1.0907   Accuracy: 0.3712\n",
      "Epoch 38:  Train Loss: 1.1001  Eval Loss: 1.0927   Accuracy: 0.3714\n",
      "Epoch 39:  Train Loss: 1.1010  Eval Loss: 1.0920   Accuracy: 0.3730\n",
      "Epoch 40:  Train Loss: 1.1007  Eval Loss: 1.0907   Accuracy: 0.3743\n",
      "Epoch 41:  Train Loss: 1.1009  Eval Loss: 1.0905   Accuracy: 0.3770\n",
      "Epoch 42:  Train Loss: 1.1013  Eval Loss: 1.0909   Accuracy: 0.3728\n",
      "Epoch 43:  Train Loss: 1.1010  Eval Loss: 1.0921   Accuracy: 0.3733\n",
      "Epoch 44:  Train Loss: 1.1020  Eval Loss: 1.0914   Accuracy: 0.3728\n",
      "Epoch 45:  Train Loss: 1.1017  Eval Loss: 1.0904   Accuracy: 0.3742\n",
      "Epoch 46:  Train Loss: 1.1014  Eval Loss: 1.0917   Accuracy: 0.3727\n",
      "Epoch 47:  Train Loss: 1.1016  Eval Loss: 1.0923   Accuracy: 0.3724\n",
      "Epoch 48:  Train Loss: 1.1009  Eval Loss: 1.0901   Accuracy: 0.3767\n",
      "Epoch 49:  Train Loss: 1.1013  Eval Loss: 1.0909   Accuracy: 0.3779\n",
      "Epoch 50:  Train Loss: 1.1014  Eval Loss: 1.0911   Accuracy: 0.3752\n",
      "    Final Results: {'eval_loss': 1.0911033868789672, 'accuracy': 0.3752419765664799, 'best_accuracy': 0.38563423331635255}\n",
      "  Method: prefix\n",
      "Epoch 1:  Train Loss: 1.1006  Eval Loss: 1.0907   Accuracy: 0.3810\n",
      "Epoch 2:  Train Loss: 1.0935  Eval Loss: 1.0880   Accuracy: 0.3899\n",
      "Epoch 3:  Train Loss: 1.0915  Eval Loss: 1.0854   Accuracy: 0.3977\n",
      "Epoch 4:  Train Loss: 1.0906  Eval Loss: 1.0855   Accuracy: 0.4004\n",
      "Epoch 5:  Train Loss: 1.0909  Eval Loss: 1.0858   Accuracy: 0.3974\n",
      "Epoch 6:  Train Loss: 1.0917  Eval Loss: 1.0850   Accuracy: 0.3991\n",
      "Epoch 7:  Train Loss: 1.0916  Eval Loss: 1.0850   Accuracy: 0.4019\n",
      "Epoch 8:  Train Loss: 1.0918  Eval Loss: 1.0846   Accuracy: 0.3978\n",
      "Epoch 9:  Train Loss: 1.0918  Eval Loss: 1.0839   Accuracy: 0.3991\n",
      "Epoch 10:  Train Loss: 1.0909  Eval Loss: 1.0865   Accuracy: 0.3944\n",
      "Epoch 11:  Train Loss: 1.0912  Eval Loss: 1.0855   Accuracy: 0.3972\n",
      "Epoch 12:  Train Loss: 1.0916  Eval Loss: 1.0845   Accuracy: 0.3993\n",
      "Epoch 13:  Train Loss: 1.0919  Eval Loss: 1.0847   Accuracy: 0.4016\n",
      "Epoch 14:  Train Loss: 1.0919  Eval Loss: 1.0863   Accuracy: 0.3983\n",
      "Epoch 15:  Train Loss: 1.0917  Eval Loss: 1.0844   Accuracy: 0.4016\n",
      "Epoch 16:  Train Loss: 1.0921  Eval Loss: 1.0831   Accuracy: 0.4028\n",
      "Epoch 17:  Train Loss: 1.0918  Eval Loss: 1.0838   Accuracy: 0.4007\n",
      "Epoch 18:  Train Loss: 1.0924  Eval Loss: 1.0838   Accuracy: 0.4016\n",
      "Epoch 19:  Train Loss: 1.0925  Eval Loss: 1.0831   Accuracy: 0.4024\n",
      "Epoch 20:  Train Loss: 1.0920  Eval Loss: 1.0830   Accuracy: 0.4060\n",
      "Epoch 21:  Train Loss: 1.0920  Eval Loss: 1.0829   Accuracy: 0.4063\n",
      "Epoch 22:  Train Loss: 1.0929  Eval Loss: 1.0827   Accuracy: 0.4029\n",
      "Epoch 23:  Train Loss: 1.0929  Eval Loss: 1.0835   Accuracy: 0.4035\n",
      "Epoch 24:  Train Loss: 1.0934  Eval Loss: 1.0828   Accuracy: 0.4077\n",
      "Epoch 25:  Train Loss: 1.0938  Eval Loss: 1.0809   Accuracy: 0.4067\n",
      "Epoch 26:  Train Loss: 1.0948  Eval Loss: 1.0811   Accuracy: 0.4062\n",
      "Epoch 27:  Train Loss: 1.0941  Eval Loss: 1.0824   Accuracy: 0.4061\n",
      "Epoch 28:  Train Loss: 1.0946  Eval Loss: 1.0833   Accuracy: 0.4048\n",
      "Epoch 29:  Train Loss: 1.0941  Eval Loss: 1.0810   Accuracy: 0.4092\n",
      "Epoch 30:  Train Loss: 1.0947  Eval Loss: 1.0822   Accuracy: 0.4052\n",
      "Epoch 31:  Train Loss: 1.0944  Eval Loss: 1.0825   Accuracy: 0.4039\n",
      "Epoch 32:  Train Loss: 1.0938  Eval Loss: 1.0806   Accuracy: 0.4094\n",
      "Epoch 33:  Train Loss: 1.0946  Eval Loss: 1.0816   Accuracy: 0.4056\n",
      "Epoch 34:  Train Loss: 1.0942  Eval Loss: 1.0822   Accuracy: 0.4060\n",
      "Epoch 35:  Train Loss: 1.0936  Eval Loss: 1.0826   Accuracy: 0.4059\n",
      "Epoch 36:  Train Loss: 1.0947  Eval Loss: 1.0824   Accuracy: 0.4045\n",
      "Epoch 37:  Train Loss: 1.0954  Eval Loss: 1.0836   Accuracy: 0.4019\n",
      "Epoch 38:  Train Loss: 1.0954  Eval Loss: 1.0838   Accuracy: 0.4021\n",
      "Epoch 39:  Train Loss: 1.0950  Eval Loss: 1.0824   Accuracy: 0.4050\n",
      "Epoch 40:  Train Loss: 1.0950  Eval Loss: 1.0821   Accuracy: 0.4025\n",
      "Epoch 41:  Train Loss: 1.0954  Eval Loss: 1.0836   Accuracy: 0.4009\n",
      "Epoch 42:  Train Loss: 1.0950  Eval Loss: 1.0851   Accuracy: 0.4022\n",
      "Epoch 43:  Train Loss: 1.0949  Eval Loss: 1.0826   Accuracy: 0.4052\n",
      "Epoch 44:  Train Loss: 1.0956  Eval Loss: 1.0842   Accuracy: 0.4042\n",
      "Epoch 45:  Train Loss: 1.0949  Eval Loss: 1.0838   Accuracy: 0.4010\n",
      "Epoch 46:  Train Loss: 1.0960  Eval Loss: 1.0841   Accuracy: 0.4013\n",
      "Epoch 47:  Train Loss: 1.0944  Eval Loss: 1.0827   Accuracy: 0.4038\n",
      "Epoch 48:  Train Loss: 1.0942  Eval Loss: 1.0830   Accuracy: 0.4033\n",
      "Epoch 49:  Train Loss: 1.0954  Eval Loss: 1.0823   Accuracy: 0.4073\n",
      "Epoch 50:  Train Loss: 1.0947  Eval Loss: 1.0840   Accuracy: 0.3988\n",
      "    Final Results: {'eval_loss': 1.0840466141700744, 'accuracy': 0.3987773815588385, 'best_accuracy': 0.40937340804890476}\n",
      "  Method: full_fine_tuning\n",
      "Epoch 1:  Train Loss: 1.0952  Eval Loss: 1.0879   Accuracy: 0.3891\n",
      "Epoch 2:  Train Loss: 1.0881  Eval Loss: 1.0787   Accuracy: 0.3994\n",
      "Epoch 3:  Train Loss: 1.0855  Eval Loss: 1.0780   Accuracy: 0.4002\n",
      "Epoch 4:  Train Loss: 1.0853  Eval Loss: 1.0765   Accuracy: 0.4119\n",
      "Epoch 5:  Train Loss: 1.0853  Eval Loss: 1.0760   Accuracy: 0.4052\n",
      "Epoch 6:  Train Loss: 1.0854  Eval Loss: 1.0731   Accuracy: 0.4178\n",
      "Epoch 7:  Train Loss: 1.0863  Eval Loss: 1.0736   Accuracy: 0.4170\n",
      "Epoch 8:  Train Loss: 1.0879  Eval Loss: 1.0763   Accuracy: 0.4151\n",
      "Epoch 9:  Train Loss: 1.0904  Eval Loss: 1.0755   Accuracy: 0.4159\n",
      "Epoch 10:  Train Loss: 1.0900  Eval Loss: 1.0769   Accuracy: 0.4178\n",
      "Epoch 11:  Train Loss: 1.0906  Eval Loss: 1.0760   Accuracy: 0.4154\n",
      "Epoch 12:  Train Loss: 1.0912  Eval Loss: 1.0785   Accuracy: 0.4190\n",
      "Epoch 13:  Train Loss: 1.0931  Eval Loss: 1.0797   Accuracy: 0.4085\n",
      "Epoch 14:  Train Loss: 1.0941  Eval Loss: 1.0828   Accuracy: 0.3998\n",
      "Epoch 15:  Train Loss: 1.0939  Eval Loss: 1.0844   Accuracy: 0.3983\n",
      "Epoch 16:  Train Loss: 1.0956  Eval Loss: 1.0861   Accuracy: 0.3928\n",
      "Epoch 17:  Train Loss: 1.0968  Eval Loss: 1.0874   Accuracy: 0.3893\n",
      "Epoch 18:  Train Loss: 1.0983  Eval Loss: 1.0911   Accuracy: 0.3752\n",
      "Epoch 19:  Train Loss: 1.1001  Eval Loss: 1.0922   Accuracy: 0.3721\n",
      "Epoch 20:  Train Loss: 1.1004  Eval Loss: 1.0915   Accuracy: 0.3721\n",
      "Epoch 21:  Train Loss: 1.1006  Eval Loss: 1.0920   Accuracy: 0.3710\n",
      "Epoch 22:  Train Loss: 1.1011  Eval Loss: 1.0905   Accuracy: 0.3781\n",
      "Epoch 23:  Train Loss: 1.1029  Eval Loss: 1.0938   Accuracy: 0.3706\n",
      "Epoch 24:  Train Loss: 1.1031  Eval Loss: 1.0934   Accuracy: 0.3707\n",
      "Epoch 25:  Train Loss: 1.1026  Eval Loss: 1.0943   Accuracy: 0.3624\n",
      "Epoch 26:  Train Loss: 1.1020  Eval Loss: 1.0933   Accuracy: 0.3630\n",
      "Epoch 27:  Train Loss: 1.1026  Eval Loss: 1.0940   Accuracy: 0.3635\n",
      "Epoch 28:  Train Loss: 1.1025  Eval Loss: 1.0932   Accuracy: 0.3624\n",
      "Epoch 29:  Train Loss: 1.1030  Eval Loss: 1.0949   Accuracy: 0.3589\n",
      "Epoch 30:  Train Loss: 1.1036  Eval Loss: 1.0945   Accuracy: 0.3582\n",
      "Epoch 31:  Train Loss: 1.1034  Eval Loss: 1.0946   Accuracy: 0.3575\n",
      "Epoch 32:  Train Loss: 1.1039  Eval Loss: 1.0945   Accuracy: 0.3594\n",
      "Epoch 33:  Train Loss: 1.1030  Eval Loss: 1.0918   Accuracy: 0.3693\n",
      "Epoch 34:  Train Loss: 1.1041  Eval Loss: 1.0939   Accuracy: 0.3590\n",
      "Epoch 35:  Train Loss: 1.1047  Eval Loss: 1.0958   Accuracy: 0.3540\n",
      "Epoch 36:  Train Loss: 1.1055  Eval Loss: 1.0954   Accuracy: 0.3569\n",
      "Epoch 37:  Train Loss: 1.1052  Eval Loss: 1.0973   Accuracy: 0.3548\n",
      "Epoch 38:  Train Loss: 1.1054  Eval Loss: 1.0953   Accuracy: 0.3605\n",
      "Epoch 39:  Train Loss: 1.1064  Eval Loss: 1.0946   Accuracy: 0.3631\n",
      "Epoch 40:  Train Loss: 1.1061  Eval Loss: 1.0934   Accuracy: 0.3578\n",
      "Epoch 41:  Train Loss: 1.1066  Eval Loss: 1.0944   Accuracy: 0.3543\n",
      "Epoch 42:  Train Loss: 1.1066  Eval Loss: 1.0945   Accuracy: 0.3562\n",
      "Epoch 43:  Train Loss: 1.1058  Eval Loss: 1.0955   Accuracy: 0.3566\n",
      "Epoch 44:  Train Loss: 1.1052  Eval Loss: 1.0956   Accuracy: 0.3562\n",
      "Epoch 45:  Train Loss: 1.1059  Eval Loss: 1.0943   Accuracy: 0.3602\n",
      "Epoch 46:  Train Loss: 1.1068  Eval Loss: 1.0966   Accuracy: 0.3589\n",
      "Epoch 47:  Train Loss: 1.1073  Eval Loss: 1.0947   Accuracy: 0.3546\n",
      "Epoch 48:  Train Loss: 1.1063  Eval Loss: 1.0927   Accuracy: 0.3611\n",
      "Epoch 49:  Train Loss: 1.1062  Eval Loss: 1.0947   Accuracy: 0.3553\n",
      "Epoch 50:  Train Loss: 1.1061  Eval Loss: 1.0952   Accuracy: 0.3555\n",
      "    Final Results: {'eval_loss': 1.0951581239700316, 'accuracy': 0.3554763117677025, 'best_accuracy': 0.41895058583800304}\n",
      "  Method: lora\n",
      "Epoch 1:  Train Loss: 1.0958  Eval Loss: 1.0889   Accuracy: 0.3876\n",
      "Epoch 2:  Train Loss: 1.0877  Eval Loss: 1.0851   Accuracy: 0.4021\n",
      "Epoch 3:  Train Loss: 1.0854  Eval Loss: 1.0817   Accuracy: 0.4077\n",
      "Epoch 4:  Train Loss: 1.0834  Eval Loss: 1.0788   Accuracy: 0.4110\n",
      "Epoch 5:  Train Loss: 1.0822  Eval Loss: 1.0778   Accuracy: 0.4164\n",
      "Epoch 6:  Train Loss: 1.0819  Eval Loss: 1.0764   Accuracy: 0.4204\n",
      "Epoch 7:  Train Loss: 1.0801  Eval Loss: 1.0753   Accuracy: 0.4119\n",
      "Epoch 8:  Train Loss: 1.0802  Eval Loss: 1.0744   Accuracy: 0.4166\n",
      "Epoch 9:  Train Loss: 1.0794  Eval Loss: 1.0734   Accuracy: 0.4145\n",
      "Epoch 10:  Train Loss: 1.0792  Eval Loss: 1.0729   Accuracy: 0.4195\n",
      "Epoch 11:  Train Loss: 1.0793  Eval Loss: 1.0730   Accuracy: 0.4191\n",
      "Epoch 12:  Train Loss: 1.0798  Eval Loss: 1.0727   Accuracy: 0.4175\n",
      "Epoch 13:  Train Loss: 1.0794  Eval Loss: 1.0714   Accuracy: 0.4260\n",
      "Epoch 14:  Train Loss: 1.0793  Eval Loss: 1.0722   Accuracy: 0.4227\n",
      "Epoch 15:  Train Loss: 1.0794  Eval Loss: 1.0714   Accuracy: 0.4209\n",
      "Epoch 16:  Train Loss: 1.0794  Eval Loss: 1.0716   Accuracy: 0.4231\n",
      "Epoch 17:  Train Loss: 1.0788  Eval Loss: 1.0699   Accuracy: 0.4249\n",
      "Epoch 18:  Train Loss: 1.0786  Eval Loss: 1.0695   Accuracy: 0.4250\n",
      "Epoch 19:  Train Loss: 1.0786  Eval Loss: 1.0688   Accuracy: 0.4280\n",
      "Epoch 20:  Train Loss: 1.0788  Eval Loss: 1.0682   Accuracy: 0.4288\n",
      "Epoch 21:  Train Loss: 1.0784  Eval Loss: 1.0671   Accuracy: 0.4291\n",
      "Epoch 22:  Train Loss: 1.0784  Eval Loss: 1.0679   Accuracy: 0.4298\n",
      "Epoch 23:  Train Loss: 1.0780  Eval Loss: 1.0694   Accuracy: 0.4294\n",
      "Epoch 24:  Train Loss: 1.0785  Eval Loss: 1.0669   Accuracy: 0.4338\n",
      "Epoch 25:  Train Loss: 1.0781  Eval Loss: 1.0670   Accuracy: 0.4308\n",
      "Epoch 26:  Train Loss: 1.0786  Eval Loss: 1.0676   Accuracy: 0.4299\n",
      "Epoch 27:  Train Loss: 1.0769  Eval Loss: 1.0677   Accuracy: 0.4246\n",
      "Epoch 28:  Train Loss: 1.0774  Eval Loss: 1.0665   Accuracy: 0.4287\n",
      "Epoch 29:  Train Loss: 1.0779  Eval Loss: 1.0660   Accuracy: 0.4318\n",
      "Epoch 30:  Train Loss: 1.0779  Eval Loss: 1.0654   Accuracy: 0.4322\n",
      "Epoch 31:  Train Loss: 1.0772  Eval Loss: 1.0657   Accuracy: 0.4317\n",
      "Epoch 32:  Train Loss: 1.0776  Eval Loss: 1.0675   Accuracy: 0.4321\n",
      "Epoch 33:  Train Loss: 1.0772  Eval Loss: 1.0656   Accuracy: 0.4340\n",
      "Epoch 34:  Train Loss: 1.0765  Eval Loss: 1.0646   Accuracy: 0.4368\n",
      "Epoch 35:  Train Loss: 1.0768  Eval Loss: 1.0649   Accuracy: 0.4357\n",
      "Epoch 36:  Train Loss: 1.0771  Eval Loss: 1.0673   Accuracy: 0.4273\n",
      "Epoch 37:  Train Loss: 1.0783  Eval Loss: 1.0666   Accuracy: 0.4269\n",
      "Epoch 38:  Train Loss: 1.0777  Eval Loss: 1.0656   Accuracy: 0.4306\n",
      "Epoch 39:  Train Loss: 1.0781  Eval Loss: 1.0650   Accuracy: 0.4278\n",
      "Epoch 40:  Train Loss: 1.0784  Eval Loss: 1.0636   Accuracy: 0.4311\n",
      "Epoch 41:  Train Loss: 1.0786  Eval Loss: 1.0639   Accuracy: 0.4282\n",
      "Epoch 42:  Train Loss: 1.0779  Eval Loss: 1.0636   Accuracy: 0.4339\n",
      "Epoch 43:  Train Loss: 1.0781  Eval Loss: 1.0648   Accuracy: 0.4313\n",
      "Epoch 44:  Train Loss: 1.0785  Eval Loss: 1.0644   Accuracy: 0.4337\n",
      "Epoch 45:  Train Loss: 1.0789  Eval Loss: 1.0654   Accuracy: 0.4343\n",
      "Epoch 46:  Train Loss: 1.0790  Eval Loss: 1.0647   Accuracy: 0.4329\n",
      "Epoch 47:  Train Loss: 1.0784  Eval Loss: 1.0635   Accuracy: 0.4327\n",
      "Epoch 48:  Train Loss: 1.0778  Eval Loss: 1.0646   Accuracy: 0.4306\n",
      "Epoch 49:  Train Loss: 1.0782  Eval Loss: 1.0639   Accuracy: 0.4370\n",
      "Epoch 50:  Train Loss: 1.0786  Eval Loss: 1.0644   Accuracy: 0.4362\n",
      "    Final Results: {'eval_loss': 1.0644146084785462, 'accuracy': 0.43616912888436066, 'best_accuracy': 0.436984207845135}\n",
      "  Method: ia3\n",
      "Epoch 1:  Train Loss: 1.0928  Eval Loss: 1.0905   Accuracy: 0.3813\n",
      "Epoch 2:  Train Loss: 1.0893  Eval Loss: 1.0866   Accuracy: 0.3846\n",
      "Epoch 3:  Train Loss: 1.0867  Eval Loss: 1.0835   Accuracy: 0.3887\n",
      "Epoch 4:  Train Loss: 1.0850  Eval Loss: 1.0827   Accuracy: 0.3975\n",
      "Epoch 5:  Train Loss: 1.0840  Eval Loss: 1.0820   Accuracy: 0.3956\n",
      "Epoch 6:  Train Loss: 1.0835  Eval Loss: 1.0809   Accuracy: 0.4020\n",
      "Epoch 7:  Train Loss: 1.0833  Eval Loss: 1.0796   Accuracy: 0.4047\n",
      "Epoch 8:  Train Loss: 1.0819  Eval Loss: 1.0787   Accuracy: 0.4109\n",
      "Epoch 9:  Train Loss: 1.0816  Eval Loss: 1.0779   Accuracy: 0.4119\n",
      "Epoch 10:  Train Loss: 1.0809  Eval Loss: 1.0777   Accuracy: 0.4138\n",
      "Epoch 11:  Train Loss: 1.0804  Eval Loss: 1.0764   Accuracy: 0.4105\n",
      "Epoch 12:  Train Loss: 1.0808  Eval Loss: 1.0769   Accuracy: 0.4124\n",
      "Epoch 13:  Train Loss: 1.0811  Eval Loss: 1.0776   Accuracy: 0.4109\n",
      "Epoch 14:  Train Loss: 1.0808  Eval Loss: 1.0742   Accuracy: 0.4197\n",
      "Epoch 15:  Train Loss: 1.0801  Eval Loss: 1.0749   Accuracy: 0.4167\n",
      "Epoch 16:  Train Loss: 1.0809  Eval Loss: 1.0756   Accuracy: 0.4181\n",
      "Epoch 17:  Train Loss: 1.0804  Eval Loss: 1.0742   Accuracy: 0.4213\n",
      "Epoch 18:  Train Loss: 1.0805  Eval Loss: 1.0736   Accuracy: 0.4175\n",
      "Epoch 19:  Train Loss: 1.0804  Eval Loss: 1.0730   Accuracy: 0.4198\n",
      "Epoch 20:  Train Loss: 1.0801  Eval Loss: 1.0713   Accuracy: 0.4250\n",
      "Epoch 21:  Train Loss: 1.0796  Eval Loss: 1.0707   Accuracy: 0.4293\n",
      "Epoch 22:  Train Loss: 1.0796  Eval Loss: 1.0700   Accuracy: 0.4259\n",
      "Epoch 23:  Train Loss: 1.0794  Eval Loss: 1.0698   Accuracy: 0.4290\n",
      "Epoch 24:  Train Loss: 1.0791  Eval Loss: 1.0682   Accuracy: 0.4314\n",
      "Epoch 25:  Train Loss: 1.0794  Eval Loss: 1.0678   Accuracy: 0.4309\n",
      "Epoch 26:  Train Loss: 1.0793  Eval Loss: 1.0682   Accuracy: 0.4345\n",
      "Epoch 27:  Train Loss: 1.0794  Eval Loss: 1.0675   Accuracy: 0.4339\n",
      "Epoch 28:  Train Loss: 1.0787  Eval Loss: 1.0683   Accuracy: 0.4290\n",
      "Epoch 29:  Train Loss: 1.0790  Eval Loss: 1.0673   Accuracy: 0.4291\n",
      "Epoch 30:  Train Loss: 1.0802  Eval Loss: 1.0683   Accuracy: 0.4273\n",
      "Epoch 31:  Train Loss: 1.0797  Eval Loss: 1.0670   Accuracy: 0.4306\n",
      "Epoch 32:  Train Loss: 1.0789  Eval Loss: 1.0672   Accuracy: 0.4294\n",
      "Epoch 33:  Train Loss: 1.0788  Eval Loss: 1.0678   Accuracy: 0.4288\n",
      "Epoch 34:  Train Loss: 1.0782  Eval Loss: 1.0660   Accuracy: 0.4314\n",
      "Epoch 35:  Train Loss: 1.0780  Eval Loss: 1.0659   Accuracy: 0.4321\n",
      "Epoch 36:  Train Loss: 1.0787  Eval Loss: 1.0650   Accuracy: 0.4334\n",
      "Epoch 37:  Train Loss: 1.0777  Eval Loss: 1.0661   Accuracy: 0.4276\n",
      "Epoch 38:  Train Loss: 1.0785  Eval Loss: 1.0657   Accuracy: 0.4317\n",
      "Epoch 39:  Train Loss: 1.0786  Eval Loss: 1.0679   Accuracy: 0.4280\n",
      "Epoch 40:  Train Loss: 1.0785  Eval Loss: 1.0673   Accuracy: 0.4285\n",
      "Epoch 41:  Train Loss: 1.0790  Eval Loss: 1.0673   Accuracy: 0.4299\n",
      "Epoch 42:  Train Loss: 1.0792  Eval Loss: 1.0664   Accuracy: 0.4334\n",
      "Epoch 43:  Train Loss: 1.0798  Eval Loss: 1.0672   Accuracy: 0.4282\n",
      "Epoch 44:  Train Loss: 1.0792  Eval Loss: 1.0653   Accuracy: 0.4291\n",
      "Epoch 45:  Train Loss: 1.0796  Eval Loss: 1.0659   Accuracy: 0.4313\n",
      "Epoch 46:  Train Loss: 1.0801  Eval Loss: 1.0670   Accuracy: 0.4311\n",
      "Epoch 47:  Train Loss: 1.0806  Eval Loss: 1.0688   Accuracy: 0.4252\n",
      "Epoch 48:  Train Loss: 1.0815  Eval Loss: 1.0674   Accuracy: 0.4271\n",
      "Epoch 49:  Train Loss: 1.0815  Eval Loss: 1.0680   Accuracy: 0.4278\n",
      "Epoch 50:  Train Loss: 1.0807  Eval Loss: 1.0679   Accuracy: 0.4293\n",
      "    Final Results: {'eval_loss': 1.067877757549286, 'accuracy': 0.4293428425878757, 'best_accuracy': 0.434538970962812}\n",
      "  Method: single_layer_fine_tuning\n",
      "Epoch 1:  Train Loss: 1.1113  Eval Loss: 1.0977   Accuracy: 0.3716\n",
      "Epoch 2:  Train Loss: 1.1031  Eval Loss: 1.0927   Accuracy: 0.3893\n",
      "Epoch 3:  Train Loss: 1.0989  Eval Loss: 1.0909   Accuracy: 0.3905\n",
      "Epoch 4:  Train Loss: 1.0982  Eval Loss: 1.0900   Accuracy: 0.3939\n",
      "Epoch 5:  Train Loss: 1.0970  Eval Loss: 1.0892   Accuracy: 0.3981\n",
      "Epoch 6:  Train Loss: 1.0962  Eval Loss: 1.0880   Accuracy: 0.3983\n",
      "Epoch 7:  Train Loss: 1.0937  Eval Loss: 1.0860   Accuracy: 0.4041\n",
      "Epoch 8:  Train Loss: 1.0920  Eval Loss: 1.0846   Accuracy: 0.4067\n",
      "Epoch 9:  Train Loss: 1.0908  Eval Loss: 1.0837   Accuracy: 0.4048\n",
      "Epoch 10:  Train Loss: 1.0917  Eval Loss: 1.0844   Accuracy: 0.4060\n",
      "Epoch 11:  Train Loss: 1.0915  Eval Loss: 1.0831   Accuracy: 0.4054\n",
      "Epoch 12:  Train Loss: 1.0903  Eval Loss: 1.0823   Accuracy: 0.4042\n",
      "Epoch 13:  Train Loss: 1.0897  Eval Loss: 1.0825   Accuracy: 0.4016\n",
      "Epoch 14:  Train Loss: 1.0906  Eval Loss: 1.0801   Accuracy: 0.4088\n",
      "Epoch 15:  Train Loss: 1.0886  Eval Loss: 1.0793   Accuracy: 0.4076\n",
      "Epoch 16:  Train Loss: 1.0895  Eval Loss: 1.0796   Accuracy: 0.4098\n",
      "Epoch 17:  Train Loss: 1.0895  Eval Loss: 1.0806   Accuracy: 0.4079\n",
      "Epoch 18:  Train Loss: 1.0895  Eval Loss: 1.0830   Accuracy: 0.4075\n",
      "Epoch 19:  Train Loss: 1.0893  Eval Loss: 1.0790   Accuracy: 0.4072\n",
      "Epoch 20:  Train Loss: 1.0887  Eval Loss: 1.0788   Accuracy: 0.4097\n",
      "Epoch 21:  Train Loss: 1.0882  Eval Loss: 1.0782   Accuracy: 0.4130\n",
      "Epoch 22:  Train Loss: 1.0881  Eval Loss: 1.0770   Accuracy: 0.4157\n",
      "Epoch 23:  Train Loss: 1.0864  Eval Loss: 1.0766   Accuracy: 0.4129\n",
      "Epoch 24:  Train Loss: 1.0858  Eval Loss: 1.0768   Accuracy: 0.4130\n",
      "Epoch 25:  Train Loss: 1.0848  Eval Loss: 1.0751   Accuracy: 0.4142\n",
      "Epoch 26:  Train Loss: 1.0848  Eval Loss: 1.0751   Accuracy: 0.4151\n",
      "Epoch 27:  Train Loss: 1.0863  Eval Loss: 1.0750   Accuracy: 0.4159\n",
      "Epoch 28:  Train Loss: 1.0861  Eval Loss: 1.0755   Accuracy: 0.4146\n",
      "Epoch 29:  Train Loss: 1.0858  Eval Loss: 1.0751   Accuracy: 0.4185\n",
      "Epoch 30:  Train Loss: 1.0856  Eval Loss: 1.0751   Accuracy: 0.4172\n",
      "Epoch 31:  Train Loss: 1.0852  Eval Loss: 1.0747   Accuracy: 0.4174\n",
      "Epoch 32:  Train Loss: 1.0842  Eval Loss: 1.0749   Accuracy: 0.4186\n",
      "Epoch 33:  Train Loss: 1.0841  Eval Loss: 1.0737   Accuracy: 0.4208\n",
      "Epoch 34:  Train Loss: 1.0835  Eval Loss: 1.0734   Accuracy: 0.4221\n",
      "Epoch 35:  Train Loss: 1.0832  Eval Loss: 1.0751   Accuracy: 0.4133\n",
      "Epoch 36:  Train Loss: 1.0836  Eval Loss: 1.0739   Accuracy: 0.4158\n",
      "Epoch 37:  Train Loss: 1.0838  Eval Loss: 1.0735   Accuracy: 0.4191\n",
      "Epoch 38:  Train Loss: 1.0832  Eval Loss: 1.0727   Accuracy: 0.4160\n",
      "Epoch 39:  Train Loss: 1.0836  Eval Loss: 1.0739   Accuracy: 0.4124\n",
      "Epoch 40:  Train Loss: 1.0840  Eval Loss: 1.0739   Accuracy: 0.4158\n",
      "Epoch 41:  Train Loss: 1.0837  Eval Loss: 1.0735   Accuracy: 0.4152\n",
      "Epoch 42:  Train Loss: 1.0846  Eval Loss: 1.0722   Accuracy: 0.4192\n",
      "Epoch 43:  Train Loss: 1.0832  Eval Loss: 1.0708   Accuracy: 0.4240\n",
      "Epoch 44:  Train Loss: 1.0831  Eval Loss: 1.0709   Accuracy: 0.4210\n",
      "Epoch 45:  Train Loss: 1.0828  Eval Loss: 1.0719   Accuracy: 0.4198\n",
      "Epoch 46:  Train Loss: 1.0826  Eval Loss: 1.0725   Accuracy: 0.4197\n",
      "Epoch 47:  Train Loss: 1.0830  Eval Loss: 1.0703   Accuracy: 0.4241\n",
      "Epoch 48:  Train Loss: 1.0833  Eval Loss: 1.0721   Accuracy: 0.4215\n",
      "Epoch 49:  Train Loss: 1.0826  Eval Loss: 1.0718   Accuracy: 0.4206\n",
      "Epoch 50:  Train Loss: 1.0830  Eval Loss: 1.0703   Accuracy: 0.4241\n",
      "    Final Results: {'eval_loss': 1.0702787160873413, 'accuracy': 0.42414671421293937, 'best_accuracy': 0.42414671421293937}\n",
      "  Method: soft_prompt_lora\n",
      "Epoch 1:  Train Loss: 1.1172  Eval Loss: 1.1230   Accuracy: 0.3274\n",
      "Epoch 2:  Train Loss: 1.1172  Eval Loss: 1.1232   Accuracy: 0.3274\n",
      "Epoch 3:  Train Loss: 1.1168  Eval Loss: 1.1228   Accuracy: 0.3274\n",
      "Epoch 4:  Train Loss: 1.1169  Eval Loss: 1.1226   Accuracy: 0.3274\n",
      "Epoch 5:  Train Loss: 1.1163  Eval Loss: 1.1218   Accuracy: 0.3274\n",
      "Epoch 6:  Train Loss: 1.1157  Eval Loss: 1.1216   Accuracy: 0.3274\n",
      "Epoch 7:  Train Loss: 1.1158  Eval Loss: 1.1212   Accuracy: 0.3274\n",
      "Epoch 8:  Train Loss: 1.1154  Eval Loss: 1.1212   Accuracy: 0.3274\n",
      "Epoch 9:  Train Loss: 1.1151  Eval Loss: 1.1204   Accuracy: 0.3274\n",
      "Epoch 10:  Train Loss: 1.1149  Eval Loss: 1.1202   Accuracy: 0.3274\n",
      "Epoch 11:  Train Loss: 1.1147  Eval Loss: 1.1203   Accuracy: 0.3274\n",
      "Epoch 12:  Train Loss: 1.1147  Eval Loss: 1.1199   Accuracy: 0.3274\n",
      "Epoch 13:  Train Loss: 1.1144  Eval Loss: 1.1192   Accuracy: 0.3274\n",
      "Epoch 14:  Train Loss: 1.1142  Eval Loss: 1.1186   Accuracy: 0.3274\n",
      "Epoch 15:  Train Loss: 1.1136  Eval Loss: 1.1175   Accuracy: 0.3274\n",
      "Epoch 16:  Train Loss: 1.1134  Eval Loss: 1.1173   Accuracy: 0.3274\n",
      "Epoch 17:  Train Loss: 1.1124  Eval Loss: 1.1162   Accuracy: 0.3274\n",
      "Epoch 18:  Train Loss: 1.1122  Eval Loss: 1.1154   Accuracy: 0.3274\n",
      "Epoch 19:  Train Loss: 1.1117  Eval Loss: 1.1157   Accuracy: 0.3274\n",
      "Epoch 20:  Train Loss: 1.1118  Eval Loss: 1.1159   Accuracy: 0.3274\n",
      "Epoch 21:  Train Loss: 1.1118  Eval Loss: 1.1158   Accuracy: 0.3274\n",
      "Epoch 22:  Train Loss: 1.1113  Eval Loss: 1.1144   Accuracy: 0.3274\n",
      "Epoch 23:  Train Loss: 1.1106  Eval Loss: 1.1139   Accuracy: 0.3274\n",
      "Epoch 24:  Train Loss: 1.1102  Eval Loss: 1.1140   Accuracy: 0.3274\n",
      "Epoch 25:  Train Loss: 1.1102  Eval Loss: 1.1136   Accuracy: 0.3274\n",
      "Epoch 26:  Train Loss: 1.1105  Eval Loss: 1.1130   Accuracy: 0.3274\n",
      "Epoch 27:  Train Loss: 1.1098  Eval Loss: 1.1125   Accuracy: 0.3274\n",
      "Epoch 28:  Train Loss: 1.1095  Eval Loss: 1.1112   Accuracy: 0.3275\n",
      "Epoch 29:  Train Loss: 1.1093  Eval Loss: 1.1119   Accuracy: 0.3274\n",
      "Epoch 30:  Train Loss: 1.1094  Eval Loss: 1.1114   Accuracy: 0.3275\n",
      "Epoch 31:  Train Loss: 1.1090  Eval Loss: 1.1112   Accuracy: 0.3274\n",
      "Epoch 32:  Train Loss: 1.1090  Eval Loss: 1.1107   Accuracy: 0.3274\n",
      "Epoch 33:  Train Loss: 1.1087  Eval Loss: 1.1103   Accuracy: 0.3275\n",
      "Epoch 34:  Train Loss: 1.1083  Eval Loss: 1.1097   Accuracy: 0.3274\n",
      "Epoch 35:  Train Loss: 1.1078  Eval Loss: 1.1091   Accuracy: 0.3277\n",
      "Epoch 36:  Train Loss: 1.1078  Eval Loss: 1.1092   Accuracy: 0.3276\n",
      "Epoch 37:  Train Loss: 1.1078  Eval Loss: 1.1089   Accuracy: 0.3277\n",
      "Epoch 38:  Train Loss: 1.1072  Eval Loss: 1.1075   Accuracy: 0.3278\n",
      "Epoch 39:  Train Loss: 1.1065  Eval Loss: 1.1070   Accuracy: 0.3277\n",
      "Epoch 40:  Train Loss: 1.1063  Eval Loss: 1.1069   Accuracy: 0.3277\n",
      "Epoch 41:  Train Loss: 1.1063  Eval Loss: 1.1066   Accuracy: 0.3279\n",
      "Epoch 42:  Train Loss: 1.1057  Eval Loss: 1.1054   Accuracy: 0.3268\n",
      "Epoch 43:  Train Loss: 1.1052  Eval Loss: 1.1048   Accuracy: 0.3271\n",
      "Epoch 44:  Train Loss: 1.1051  Eval Loss: 1.1046   Accuracy: 0.3275\n",
      "Epoch 45:  Train Loss: 1.1049  Eval Loss: 1.1038   Accuracy: 0.3275\n",
      "Epoch 46:  Train Loss: 1.1047  Eval Loss: 1.1039   Accuracy: 0.3283\n",
      "Epoch 47:  Train Loss: 1.1044  Eval Loss: 1.1032   Accuracy: 0.3267\n",
      "Epoch 48:  Train Loss: 1.1039  Eval Loss: 1.1028   Accuracy: 0.3280\n",
      "Epoch 49:  Train Loss: 1.1034  Eval Loss: 1.1021   Accuracy: 0.3296\n",
      "Epoch 50:  Train Loss: 1.1030  Eval Loss: 1.1021   Accuracy: 0.3274\n",
      "    Final Results: {'eval_loss': 1.102110469341278, 'accuracy': 0.3273560876209883, 'best_accuracy': 0.3295975547631177}\n",
      "  Method: prefix_lora\n",
      "Epoch 1:  Train Loss: 1.0974  Eval Loss: 1.0944   Accuracy: 0.3729\n",
      "Epoch 2:  Train Loss: 1.0971  Eval Loss: 1.0943   Accuracy: 0.3736\n",
      "Epoch 3:  Train Loss: 1.0974  Eval Loss: 1.0945   Accuracy: 0.3721\n",
      "Epoch 4:  Train Loss: 1.0973  Eval Loss: 1.0945   Accuracy: 0.3715\n",
      "Epoch 5:  Train Loss: 1.0974  Eval Loss: 1.0942   Accuracy: 0.3716\n",
      "Epoch 6:  Train Loss: 1.0971  Eval Loss: 1.0942   Accuracy: 0.3708\n",
      "Epoch 7:  Train Loss: 1.0969  Eval Loss: 1.0942   Accuracy: 0.3734\n",
      "Epoch 8:  Train Loss: 1.0969  Eval Loss: 1.0939   Accuracy: 0.3738\n",
      "Epoch 9:  Train Loss: 1.0967  Eval Loss: 1.0937   Accuracy: 0.3745\n",
      "Epoch 10:  Train Loss: 1.0967  Eval Loss: 1.0936   Accuracy: 0.3744\n",
      "Epoch 11:  Train Loss: 1.0965  Eval Loss: 1.0936   Accuracy: 0.3750\n",
      "Epoch 12:  Train Loss: 1.0966  Eval Loss: 1.0935   Accuracy: 0.3772\n",
      "Epoch 13:  Train Loss: 1.0966  Eval Loss: 1.0935   Accuracy: 0.3777\n",
      "Epoch 14:  Train Loss: 1.0962  Eval Loss: 1.0935   Accuracy: 0.3777\n",
      "Epoch 15:  Train Loss: 1.0965  Eval Loss: 1.0934   Accuracy: 0.3779\n",
      "Epoch 16:  Train Loss: 1.0962  Eval Loss: 1.0934   Accuracy: 0.3769\n",
      "Epoch 17:  Train Loss: 1.0961  Eval Loss: 1.0932   Accuracy: 0.3768\n",
      "Epoch 18:  Train Loss: 1.0959  Eval Loss: 1.0930   Accuracy: 0.3758\n",
      "Epoch 19:  Train Loss: 1.0960  Eval Loss: 1.0930   Accuracy: 0.3751\n",
      "Epoch 20:  Train Loss: 1.0958  Eval Loss: 1.0929   Accuracy: 0.3775\n",
      "Epoch 21:  Train Loss: 1.0960  Eval Loss: 1.0926   Accuracy: 0.3774\n",
      "Epoch 22:  Train Loss: 1.0957  Eval Loss: 1.0925   Accuracy: 0.3787\n",
      "Epoch 23:  Train Loss: 1.0957  Eval Loss: 1.0925   Accuracy: 0.3760\n",
      "Epoch 24:  Train Loss: 1.0955  Eval Loss: 1.0926   Accuracy: 0.3772\n",
      "Epoch 25:  Train Loss: 1.0957  Eval Loss: 1.0926   Accuracy: 0.3781\n",
      "Epoch 26:  Train Loss: 1.0956  Eval Loss: 1.0926   Accuracy: 0.3785\n",
      "Epoch 27:  Train Loss: 1.0957  Eval Loss: 1.0926   Accuracy: 0.3795\n",
      "Epoch 28:  Train Loss: 1.0957  Eval Loss: 1.0930   Accuracy: 0.3773\n",
      "Epoch 29:  Train Loss: 1.0959  Eval Loss: 1.0930   Accuracy: 0.3764\n",
      "Epoch 30:  Train Loss: 1.0960  Eval Loss: 1.0928   Accuracy: 0.3764\n",
      "Epoch 31:  Train Loss: 1.0958  Eval Loss: 1.0928   Accuracy: 0.3768\n",
      "Epoch 32:  Train Loss: 1.0959  Eval Loss: 1.0928   Accuracy: 0.3778\n",
      "Epoch 33:  Train Loss: 1.0957  Eval Loss: 1.0925   Accuracy: 0.3795\n",
      "Epoch 34:  Train Loss: 1.0959  Eval Loss: 1.0923   Accuracy: 0.3807\n",
      "Epoch 35:  Train Loss: 1.0956  Eval Loss: 1.0923   Accuracy: 0.3802\n",
      "Epoch 36:  Train Loss: 1.0954  Eval Loss: 1.0921   Accuracy: 0.3806\n",
      "Epoch 37:  Train Loss: 1.0955  Eval Loss: 1.0918   Accuracy: 0.3827\n",
      "Epoch 38:  Train Loss: 1.0953  Eval Loss: 1.0920   Accuracy: 0.3814\n",
      "Epoch 39:  Train Loss: 1.0952  Eval Loss: 1.0920   Accuracy: 0.3840\n",
      "Epoch 40:  Train Loss: 1.0949  Eval Loss: 1.0918   Accuracy: 0.3843\n",
      "Epoch 41:  Train Loss: 1.0950  Eval Loss: 1.0917   Accuracy: 0.3818\n",
      "Epoch 42:  Train Loss: 1.0950  Eval Loss: 1.0915   Accuracy: 0.3836\n",
      "Epoch 43:  Train Loss: 1.0951  Eval Loss: 1.0915   Accuracy: 0.3852\n",
      "Epoch 44:  Train Loss: 1.0951  Eval Loss: 1.0916   Accuracy: 0.3839\n",
      "Epoch 45:  Train Loss: 1.0953  Eval Loss: 1.0917   Accuracy: 0.3834\n",
      "Epoch 46:  Train Loss: 1.0954  Eval Loss: 1.0916   Accuracy: 0.3845\n",
      "Epoch 47:  Train Loss: 1.0952  Eval Loss: 1.0916   Accuracy: 0.3834\n",
      "Epoch 48:  Train Loss: 1.0951  Eval Loss: 1.0914   Accuracy: 0.3846\n",
      "Epoch 49:  Train Loss: 1.0951  Eval Loss: 1.0914   Accuracy: 0.3861\n",
      "Epoch 50:  Train Loss: 1.0950  Eval Loss: 1.0913   Accuracy: 0.3872\n",
      "    Final Results: {'eval_loss': 1.0912744522094726, 'accuracy': 0.38716250636780436, 'best_accuracy': 0.38716250636780436}\n",
      "==================================================\n",
      "\n",
      "Results for mnli:\n",
      "  Method: soft_prompt, Accuracy: 0.3752, Loss: 1.0911\n",
      "  Method: prefix, Accuracy: 0.3988, Loss: 1.0840\n",
      "  Method: full_fine_tuning, Accuracy: 0.3555, Loss: 1.0952\n",
      "  Method: lora, Accuracy: 0.4362, Loss: 1.0644\n",
      "  Method: ia3, Accuracy: 0.4293, Loss: 1.0679\n",
      "  Method: single_layer_fine_tuning, Accuracy: 0.4241, Loss: 1.0703\n",
      "  Method: soft_prompt_lora, Accuracy: 0.3274, Loss: 1.1021\n",
      "  Method: prefix_lora, Accuracy: 0.3872, Loss: 1.0913\n",
      "\n",
      "Results have been appended to peft_experiment_results.txt\n"
     ]
    }
   ],
   "source": [
    "results = run_peft_experiments(epsilon=8,dataset=['mnli'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc8af28-f1ab-4c55-912f-4f8775c3b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing dataset: mnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9815/9815 [00:00<00:00, 13124.50 examples/s]\n",
      "Map: 100%|██████████| 9815/9815 [00:00<00:00, 25776.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Method: soft_prompt\n",
      "Epoch 1:  Train Loss: 1.1036  Eval Loss: 1.0999   Accuracy: 0.3341\n",
      "Epoch 2:  Train Loss: 1.1009  Eval Loss: 1.1003   Accuracy: 0.3236\n",
      "Epoch 3:  Train Loss: 1.1012  Eval Loss: 1.1000   Accuracy: 0.3266\n",
      "Epoch 4:  Train Loss: 1.1015  Eval Loss: 1.0985   Accuracy: 0.3398\n",
      "Epoch 5:  Train Loss: 1.1016  Eval Loss: 1.0987   Accuracy: 0.3407\n",
      "Epoch 6:  Train Loss: 1.1024  Eval Loss: 1.0986   Accuracy: 0.3480\n",
      "Epoch 7:  Train Loss: 1.1022  Eval Loss: 1.0986   Accuracy: 0.3436\n",
      "Epoch 8:  Train Loss: 1.1019  Eval Loss: 1.0993   Accuracy: 0.3464\n",
      "Epoch 9:  Train Loss: 1.1018  Eval Loss: 1.0976   Accuracy: 0.3509\n",
      "Epoch 10:  Train Loss: 1.1016  Eval Loss: 1.0984   Accuracy: 0.3453\n",
      "Epoch 11:  Train Loss: 1.1020  Eval Loss: 1.0985   Accuracy: 0.3447\n",
      "Epoch 12:  Train Loss: 1.1029  Eval Loss: 1.0978   Accuracy: 0.3533\n",
      "Epoch 13:  Train Loss: 1.1029  Eval Loss: 1.0990   Accuracy: 0.3452\n",
      "Epoch 14:  Train Loss: 1.1026  Eval Loss: 1.0993   Accuracy: 0.3465\n",
      "Epoch 15:  Train Loss: 1.1034  Eval Loss: 1.0996   Accuracy: 0.3437\n",
      "Epoch 16:  Train Loss: 1.1030  Eval Loss: 1.1004   Accuracy: 0.3381\n",
      "Epoch 17:  Train Loss: 1.1033  Eval Loss: 1.0983   Accuracy: 0.3440\n",
      "Epoch 18:  Train Loss: 1.1033  Eval Loss: 1.0990   Accuracy: 0.3379\n",
      "Epoch 19:  Train Loss: 1.1043  Eval Loss: 1.0978   Accuracy: 0.3463\n",
      "Epoch 20:  Train Loss: 1.1043  Eval Loss: 1.1002   Accuracy: 0.3383\n",
      "Epoch 21:  Train Loss: 1.1054  Eval Loss: 1.0993   Accuracy: 0.3377\n",
      "Epoch 22:  Train Loss: 1.1054  Eval Loss: 1.0999   Accuracy: 0.3359\n",
      "Epoch 23:  Train Loss: 1.1059  Eval Loss: 1.0988   Accuracy: 0.3391\n",
      "Epoch 24:  Train Loss: 1.1058  Eval Loss: 1.0995   Accuracy: 0.3434\n",
      "Epoch 25:  Train Loss: 1.1060  Eval Loss: 1.0987   Accuracy: 0.3417\n",
      "Epoch 26:  Train Loss: 1.1055  Eval Loss: 1.0993   Accuracy: 0.3420\n",
      "Epoch 27:  Train Loss: 1.1058  Eval Loss: 1.0993   Accuracy: 0.3364\n",
      "Epoch 28:  Train Loss: 1.1055  Eval Loss: 1.0999   Accuracy: 0.3416\n",
      "Epoch 29:  Train Loss: 1.1053  Eval Loss: 1.0988   Accuracy: 0.3401\n",
      "Epoch 30:  Train Loss: 1.1057  Eval Loss: 1.0985   Accuracy: 0.3411\n",
      "Epoch 31:  Train Loss: 1.1049  Eval Loss: 1.0975   Accuracy: 0.3464\n",
      "Epoch 32:  Train Loss: 1.1054  Eval Loss: 1.0980   Accuracy: 0.3442\n",
      "Epoch 33:  Train Loss: 1.1055  Eval Loss: 1.0979   Accuracy: 0.3490\n",
      "Epoch 34:  Train Loss: 1.1050  Eval Loss: 1.0978   Accuracy: 0.3483\n",
      "Epoch 35:  Train Loss: 1.1056  Eval Loss: 1.0972   Accuracy: 0.3531\n",
      "Epoch 36:  Train Loss: 1.1054  Eval Loss: 1.0973   Accuracy: 0.3488\n",
      "Epoch 37:  Train Loss: 1.1057  Eval Loss: 1.0978   Accuracy: 0.3475\n",
      "Epoch 38:  Train Loss: 1.1063  Eval Loss: 1.0982   Accuracy: 0.3512\n",
      "Epoch 39:  Train Loss: 1.1062  Eval Loss: 1.0974   Accuracy: 0.3516\n",
      "Epoch 40:  Train Loss: 1.1058  Eval Loss: 1.0965   Accuracy: 0.3559\n",
      "Epoch 41:  Train Loss: 1.1065  Eval Loss: 1.0977   Accuracy: 0.3493\n",
      "Epoch 42:  Train Loss: 1.1068  Eval Loss: 1.0996   Accuracy: 0.3481\n",
      "Epoch 43:  Train Loss: 1.1064  Eval Loss: 1.0967   Accuracy: 0.3535\n",
      "Epoch 44:  Train Loss: 1.1064  Eval Loss: 1.0975   Accuracy: 0.3493\n",
      "Epoch 45:  Train Loss: 1.1063  Eval Loss: 1.0976   Accuracy: 0.3524\n",
      "Epoch 46:  Train Loss: 1.1063  Eval Loss: 1.0964   Accuracy: 0.3512\n",
      "Epoch 47:  Train Loss: 1.1063  Eval Loss: 1.0979   Accuracy: 0.3535\n",
      "Epoch 48:  Train Loss: 1.1066  Eval Loss: 1.0979   Accuracy: 0.3524\n",
      "Epoch 49:  Train Loss: 1.1069  Eval Loss: 1.0985   Accuracy: 0.3500\n",
      "Epoch 50:  Train Loss: 1.1064  Eval Loss: 1.0994   Accuracy: 0.3440\n",
      "    Final Results: {'eval_loss': 1.0994138598442078, 'accuracy': 0.34396332144676517, 'best_accuracy': 0.35588385124808963}\n",
      "  Method: prefix\n",
      "Epoch 1:  Train Loss: 1.1006  Eval Loss: 1.0922   Accuracy: 0.3849\n",
      "Epoch 2:  Train Loss: 1.0930  Eval Loss: 1.0880   Accuracy: 0.3910\n",
      "Epoch 3:  Train Loss: 1.0918  Eval Loss: 1.0871   Accuracy: 0.3925\n",
      "Epoch 4:  Train Loss: 1.0916  Eval Loss: 1.0867   Accuracy: 0.3924\n",
      "Epoch 5:  Train Loss: 1.0919  Eval Loss: 1.0867   Accuracy: 0.3910\n",
      "Epoch 6:  Train Loss: 1.0921  Eval Loss: 1.0867   Accuracy: 0.3932\n",
      "Epoch 7:  Train Loss: 1.0919  Eval Loss: 1.0853   Accuracy: 0.3960\n",
      "Epoch 8:  Train Loss: 1.0924  Eval Loss: 1.0840   Accuracy: 0.3995\n",
      "Epoch 9:  Train Loss: 1.0923  Eval Loss: 1.0850   Accuracy: 0.4006\n",
      "Epoch 10:  Train Loss: 1.0923  Eval Loss: 1.0832   Accuracy: 0.3994\n",
      "Epoch 11:  Train Loss: 1.0916  Eval Loss: 1.0827   Accuracy: 0.4021\n",
      "Epoch 12:  Train Loss: 1.0918  Eval Loss: 1.0829   Accuracy: 0.4023\n",
      "Epoch 13:  Train Loss: 1.0922  Eval Loss: 1.0838   Accuracy: 0.4068\n",
      "Epoch 14:  Train Loss: 1.0929  Eval Loss: 1.0858   Accuracy: 0.4000\n",
      "Epoch 15:  Train Loss: 1.0928  Eval Loss: 1.0836   Accuracy: 0.4009\n",
      "Epoch 16:  Train Loss: 1.0916  Eval Loss: 1.0827   Accuracy: 0.4065\n",
      "Epoch 17:  Train Loss: 1.0926  Eval Loss: 1.0837   Accuracy: 0.4019\n",
      "Epoch 18:  Train Loss: 1.0924  Eval Loss: 1.0826   Accuracy: 0.4102\n",
      "Epoch 19:  Train Loss: 1.0926  Eval Loss: 1.0832   Accuracy: 0.3998\n",
      "Epoch 20:  Train Loss: 1.0928  Eval Loss: 1.0824   Accuracy: 0.4064\n",
      "Epoch 21:  Train Loss: 1.0923  Eval Loss: 1.0818   Accuracy: 0.4069\n",
      "Epoch 22:  Train Loss: 1.0929  Eval Loss: 1.0822   Accuracy: 0.4043\n",
      "Epoch 23:  Train Loss: 1.0917  Eval Loss: 1.0813   Accuracy: 0.4080\n",
      "Epoch 24:  Train Loss: 1.0915  Eval Loss: 1.0813   Accuracy: 0.4092\n",
      "Epoch 25:  Train Loss: 1.0913  Eval Loss: 1.0822   Accuracy: 0.4014\n",
      "Epoch 26:  Train Loss: 1.0915  Eval Loss: 1.0822   Accuracy: 0.4016\n",
      "Epoch 27:  Train Loss: 1.0913  Eval Loss: 1.0803   Accuracy: 0.4072\n",
      "Epoch 28:  Train Loss: 1.0920  Eval Loss: 1.0813   Accuracy: 0.4084\n",
      "Epoch 29:  Train Loss: 1.0918  Eval Loss: 1.0817   Accuracy: 0.4089\n",
      "Epoch 30:  Train Loss: 1.0915  Eval Loss: 1.0814   Accuracy: 0.4074\n",
      "Epoch 31:  Train Loss: 1.0918  Eval Loss: 1.0815   Accuracy: 0.4089\n",
      "Epoch 32:  Train Loss: 1.0914  Eval Loss: 1.0800   Accuracy: 0.4112\n",
      "Epoch 33:  Train Loss: 1.0924  Eval Loss: 1.0807   Accuracy: 0.4095\n",
      "Epoch 34:  Train Loss: 1.0930  Eval Loss: 1.0806   Accuracy: 0.4083\n",
      "Epoch 35:  Train Loss: 1.0936  Eval Loss: 1.0824   Accuracy: 0.4069\n",
      "Epoch 36:  Train Loss: 1.0939  Eval Loss: 1.0832   Accuracy: 0.4068\n",
      "Epoch 37:  Train Loss: 1.0937  Eval Loss: 1.0817   Accuracy: 0.4099\n",
      "Epoch 38:  Train Loss: 1.0934  Eval Loss: 1.0813   Accuracy: 0.4094\n",
      "Epoch 39:  Train Loss: 1.0927  Eval Loss: 1.0812   Accuracy: 0.4054\n",
      "Epoch 40:  Train Loss: 1.0926  Eval Loss: 1.0809   Accuracy: 0.4098\n",
      "Epoch 41:  Train Loss: 1.0932  Eval Loss: 1.0821   Accuracy: 0.4057\n",
      "Epoch 42:  Train Loss: 1.0935  Eval Loss: 1.0805   Accuracy: 0.4107\n",
      "Epoch 43:  Train Loss: 1.0927  Eval Loss: 1.0806   Accuracy: 0.4094\n",
      "Epoch 44:  Train Loss: 1.0933  Eval Loss: 1.0825   Accuracy: 0.4093\n",
      "Epoch 45:  Train Loss: 1.0940  Eval Loss: 1.0810   Accuracy: 0.4059\n",
      "Epoch 46:  Train Loss: 1.0946  Eval Loss: 1.0834   Accuracy: 0.4036\n",
      "Epoch 47:  Train Loss: 1.0940  Eval Loss: 1.0819   Accuracy: 0.4050\n",
      "Epoch 48:  Train Loss: 1.0939  Eval Loss: 1.0811   Accuracy: 0.4116\n",
      "Epoch 49:  Train Loss: 1.0937  Eval Loss: 1.0800   Accuracy: 0.4148\n",
      "Epoch 50:  Train Loss: 1.0935  Eval Loss: 1.0806   Accuracy: 0.4087\n",
      "    Final Results: {'eval_loss': 1.0806485891342164, 'accuracy': 0.4086602139582272, 'best_accuracy': 0.4147733061640346}\n",
      "  Method: full_fine_tuning\n",
      "Epoch 1:  Train Loss: 1.0982  Eval Loss: 1.0894   Accuracy: 0.3930\n",
      "Epoch 2:  Train Loss: 1.0878  Eval Loss: 1.0806   Accuracy: 0.4059\n",
      "Epoch 3:  Train Loss: 1.0833  Eval Loss: 1.0761   Accuracy: 0.4156\n",
      "Epoch 4:  Train Loss: 1.0806  Eval Loss: 1.0689   Accuracy: 0.4245\n",
      "Epoch 5:  Train Loss: 1.0795  Eval Loss: 1.0656   Accuracy: 0.4236\n",
      "Epoch 6:  Train Loss: 1.0817  Eval Loss: 1.0690   Accuracy: 0.4219\n",
      "Epoch 7:  Train Loss: 1.0818  Eval Loss: 1.0692   Accuracy: 0.4147\n",
      "Epoch 8:  Train Loss: 1.0835  Eval Loss: 1.0710   Accuracy: 0.4190\n",
      "Epoch 9:  Train Loss: 1.0844  Eval Loss: 1.0703   Accuracy: 0.4124\n",
      "Epoch 10:  Train Loss: 1.0867  Eval Loss: 1.0748   Accuracy: 0.4109\n",
      "Epoch 11:  Train Loss: 1.0895  Eval Loss: 1.0765   Accuracy: 0.4051\n",
      "Epoch 12:  Train Loss: 1.0903  Eval Loss: 1.0728   Accuracy: 0.4150\n",
      "Epoch 13:  Train Loss: 1.0905  Eval Loss: 1.0758   Accuracy: 0.4094\n",
      "Epoch 14:  Train Loss: 1.0914  Eval Loss: 1.0760   Accuracy: 0.4134\n",
      "Epoch 15:  Train Loss: 1.0929  Eval Loss: 1.0766   Accuracy: 0.4117\n",
      "Epoch 16:  Train Loss: 1.0939  Eval Loss: 1.0798   Accuracy: 0.4094\n",
      "Epoch 17:  Train Loss: 1.0944  Eval Loss: 1.0799   Accuracy: 0.4035\n",
      "Epoch 18:  Train Loss: 1.0939  Eval Loss: 1.0807   Accuracy: 0.4020\n",
      "Epoch 19:  Train Loss: 1.0944  Eval Loss: 1.0818   Accuracy: 0.4022\n",
      "Epoch 20:  Train Loss: 1.0959  Eval Loss: 1.0863   Accuracy: 0.3908\n",
      "Epoch 21:  Train Loss: 1.0975  Eval Loss: 1.0890   Accuracy: 0.3831\n",
      "Epoch 22:  Train Loss: 1.0986  Eval Loss: 1.0868   Accuracy: 0.3937\n",
      "Epoch 23:  Train Loss: 1.0983  Eval Loss: 1.0874   Accuracy: 0.3935\n",
      "Epoch 24:  Train Loss: 1.0989  Eval Loss: 1.0898   Accuracy: 0.3802\n",
      "Epoch 25:  Train Loss: 1.0990  Eval Loss: 1.0892   Accuracy: 0.3849\n",
      "Epoch 26:  Train Loss: 1.0995  Eval Loss: 1.0866   Accuracy: 0.3872\n",
      "Epoch 27:  Train Loss: 1.0988  Eval Loss: 1.0870   Accuracy: 0.3826\n",
      "Epoch 28:  Train Loss: 1.0992  Eval Loss: 1.0918   Accuracy: 0.3710\n",
      "Epoch 29:  Train Loss: 1.1005  Eval Loss: 1.0948   Accuracy: 0.3659\n",
      "Epoch 30:  Train Loss: 1.1028  Eval Loss: 1.0935   Accuracy: 0.3688\n",
      "Epoch 31:  Train Loss: 1.1036  Eval Loss: 1.0958   Accuracy: 0.3600\n",
      "Epoch 32:  Train Loss: 1.1035  Eval Loss: 1.0951   Accuracy: 0.3629\n",
      "Epoch 33:  Train Loss: 1.1033  Eval Loss: 1.0926   Accuracy: 0.3680\n",
      "Epoch 34:  Train Loss: 1.1046  Eval Loss: 1.0928   Accuracy: 0.3677\n",
      "Epoch 35:  Train Loss: 1.1042  Eval Loss: 1.0907   Accuracy: 0.3701\n",
      "Epoch 36:  Train Loss: 1.1054  Eval Loss: 1.0908   Accuracy: 0.3719\n",
      "Epoch 37:  Train Loss: 1.1055  Eval Loss: 1.0906   Accuracy: 0.3694\n",
      "Epoch 38:  Train Loss: 1.1050  Eval Loss: 1.0908   Accuracy: 0.3714\n",
      "Epoch 39:  Train Loss: 1.1055  Eval Loss: 1.0922   Accuracy: 0.3716\n",
      "Epoch 40:  Train Loss: 1.1067  Eval Loss: 1.0941   Accuracy: 0.3603\n",
      "Epoch 41:  Train Loss: 1.1074  Eval Loss: 1.0943   Accuracy: 0.3564\n",
      "Epoch 42:  Train Loss: 1.1078  Eval Loss: 1.0943   Accuracy: 0.3615\n",
      "Epoch 43:  Train Loss: 1.1065  Eval Loss: 1.0957   Accuracy: 0.3571\n",
      "Epoch 44:  Train Loss: 1.1064  Eval Loss: 1.0935   Accuracy: 0.3609\n",
      "Epoch 45:  Train Loss: 1.1073  Eval Loss: 1.0933   Accuracy: 0.3629\n",
      "Epoch 46:  Train Loss: 1.1071  Eval Loss: 1.0945   Accuracy: 0.3544\n",
      "Epoch 47:  Train Loss: 1.1066  Eval Loss: 1.0941   Accuracy: 0.3616\n",
      "Epoch 48:  Train Loss: 1.1068  Eval Loss: 1.0936   Accuracy: 0.3646\n",
      "Epoch 49:  Train Loss: 1.1072  Eval Loss: 1.0958   Accuracy: 0.3554\n",
      "Epoch 50:  Train Loss: 1.1074  Eval Loss: 1.0938   Accuracy: 0.3641\n",
      "    Final Results: {'eval_loss': 1.093754231929779, 'accuracy': 0.3641365257259297, 'best_accuracy': 0.42445236882322973}\n",
      "  Method: lora\n",
      "Epoch 1:  Train Loss: 1.1039  Eval Loss: 1.0926   Accuracy: 0.3793\n",
      "Epoch 2:  Train Loss: 1.0909  Eval Loss: 1.0865   Accuracy: 0.3921\n",
      "Epoch 3:  Train Loss: 1.0881  Eval Loss: 1.0853   Accuracy: 0.3947\n",
      "Epoch 4:  Train Loss: 1.0860  Eval Loss: 1.0846   Accuracy: 0.3937\n",
      "Epoch 5:  Train Loss: 1.0860  Eval Loss: 1.0842   Accuracy: 0.3946\n",
      "Epoch 6:  Train Loss: 1.0861  Eval Loss: 1.0842   Accuracy: 0.3969\n",
      "Epoch 7:  Train Loss: 1.0856  Eval Loss: 1.0830   Accuracy: 0.3995\n",
      "Epoch 8:  Train Loss: 1.0842  Eval Loss: 1.0818   Accuracy: 0.4006\n",
      "Epoch 9:  Train Loss: 1.0832  Eval Loss: 1.0805   Accuracy: 0.4023\n",
      "Epoch 10:  Train Loss: 1.0820  Eval Loss: 1.0794   Accuracy: 0.4001\n",
      "Epoch 11:  Train Loss: 1.0821  Eval Loss: 1.0788   Accuracy: 0.4021\n",
      "Epoch 12:  Train Loss: 1.0812  Eval Loss: 1.0773   Accuracy: 0.4075\n",
      "Epoch 13:  Train Loss: 1.0809  Eval Loss: 1.0768   Accuracy: 0.4083\n",
      "Epoch 14:  Train Loss: 1.0803  Eval Loss: 1.0756   Accuracy: 0.4124\n",
      "Epoch 15:  Train Loss: 1.0801  Eval Loss: 1.0758   Accuracy: 0.4129\n",
      "Epoch 16:  Train Loss: 1.0811  Eval Loss: 1.0756   Accuracy: 0.4193\n",
      "Epoch 17:  Train Loss: 1.0806  Eval Loss: 1.0750   Accuracy: 0.4161\n",
      "Epoch 18:  Train Loss: 1.0814  Eval Loss: 1.0759   Accuracy: 0.4188\n",
      "Epoch 19:  Train Loss: 1.0815  Eval Loss: 1.0762   Accuracy: 0.4124\n",
      "Epoch 20:  Train Loss: 1.0809  Eval Loss: 1.0752   Accuracy: 0.4182\n",
      "Epoch 21:  Train Loss: 1.0808  Eval Loss: 1.0755   Accuracy: 0.4126\n",
      "Epoch 22:  Train Loss: 1.0801  Eval Loss: 1.0750   Accuracy: 0.4157\n",
      "Epoch 23:  Train Loss: 1.0805  Eval Loss: 1.0749   Accuracy: 0.4204\n",
      "Epoch 24:  Train Loss: 1.0815  Eval Loss: 1.0756   Accuracy: 0.4184\n",
      "Epoch 25:  Train Loss: 1.0816  Eval Loss: 1.0749   Accuracy: 0.4187\n",
      "Epoch 26:  Train Loss: 1.0802  Eval Loss: 1.0740   Accuracy: 0.4204\n",
      "Epoch 27:  Train Loss: 1.0803  Eval Loss: 1.0740   Accuracy: 0.4174\n",
      "Epoch 28:  Train Loss: 1.0800  Eval Loss: 1.0723   Accuracy: 0.4223\n",
      "Epoch 29:  Train Loss: 1.0801  Eval Loss: 1.0722   Accuracy: 0.4225\n",
      "Epoch 30:  Train Loss: 1.0787  Eval Loss: 1.0721   Accuracy: 0.4227\n",
      "Epoch 31:  Train Loss: 1.0791  Eval Loss: 1.0702   Accuracy: 0.4260\n",
      "Epoch 32:  Train Loss: 1.0792  Eval Loss: 1.0687   Accuracy: 0.4233\n",
      "Epoch 33:  Train Loss: 1.0789  Eval Loss: 1.0687   Accuracy: 0.4272\n",
      "Epoch 34:  Train Loss: 1.0782  Eval Loss: 1.0683   Accuracy: 0.4265\n",
      "Epoch 35:  Train Loss: 1.0789  Eval Loss: 1.0674   Accuracy: 0.4268\n",
      "Epoch 36:  Train Loss: 1.0785  Eval Loss: 1.0679   Accuracy: 0.4258\n",
      "Epoch 37:  Train Loss: 1.0782  Eval Loss: 1.0693   Accuracy: 0.4264\n",
      "Epoch 38:  Train Loss: 1.0790  Eval Loss: 1.0695   Accuracy: 0.4307\n",
      "Epoch 39:  Train Loss: 1.0798  Eval Loss: 1.0680   Accuracy: 0.4299\n",
      "Epoch 40:  Train Loss: 1.0787  Eval Loss: 1.0689   Accuracy: 0.4304\n",
      "Epoch 41:  Train Loss: 1.0790  Eval Loss: 1.0689   Accuracy: 0.4298\n",
      "Epoch 42:  Train Loss: 1.0775  Eval Loss: 1.0675   Accuracy: 0.4328\n",
      "Epoch 43:  Train Loss: 1.0774  Eval Loss: 1.0695   Accuracy: 0.4280\n",
      "Epoch 44:  Train Loss: 1.0786  Eval Loss: 1.0678   Accuracy: 0.4309\n",
      "Epoch 45:  Train Loss: 1.0774  Eval Loss: 1.0697   Accuracy: 0.4273\n",
      "Epoch 46:  Train Loss: 1.0769  Eval Loss: 1.0672   Accuracy: 0.4312\n",
      "Epoch 47:  Train Loss: 1.0773  Eval Loss: 1.0671   Accuracy: 0.4313\n",
      "Epoch 48:  Train Loss: 1.0763  Eval Loss: 1.0653   Accuracy: 0.4300\n",
      "Epoch 49:  Train Loss: 1.0776  Eval Loss: 1.0646   Accuracy: 0.4263\n",
      "Epoch 50:  Train Loss: 1.0776  Eval Loss: 1.0650   Accuracy: 0.4281\n",
      "    Final Results: {'eval_loss': 1.065006673336029, 'accuracy': 0.4281202241467142, 'best_accuracy': 0.43280692817116656}\n",
      "  Method: ia3\n",
      "Epoch 1:  Train Loss: 1.1032  Eval Loss: 1.0935   Accuracy: 0.3793\n",
      "Epoch 2:  Train Loss: 1.0905  Eval Loss: 1.0863   Accuracy: 0.3922\n",
      "Epoch 3:  Train Loss: 1.0862  Eval Loss: 1.0847   Accuracy: 0.3964\n",
      "Epoch 4:  Train Loss: 1.0840  Eval Loss: 1.0820   Accuracy: 0.4044\n",
      "Epoch 5:  Train Loss: 1.0831  Eval Loss: 1.0803   Accuracy: 0.4087\n",
      "Epoch 6:  Train Loss: 1.0829  Eval Loss: 1.0807   Accuracy: 0.4044\n",
      "Epoch 7:  Train Loss: 1.0829  Eval Loss: 1.0807   Accuracy: 0.4050\n",
      "Epoch 8:  Train Loss: 1.0834  Eval Loss: 1.0812   Accuracy: 0.4035\n",
      "Epoch 9:  Train Loss: 1.0833  Eval Loss: 1.0819   Accuracy: 0.4001\n",
      "Epoch 10:  Train Loss: 1.0833  Eval Loss: 1.0803   Accuracy: 0.4051\n",
      "Epoch 11:  Train Loss: 1.0827  Eval Loss: 1.0792   Accuracy: 0.4066\n",
      "Epoch 12:  Train Loss: 1.0821  Eval Loss: 1.0791   Accuracy: 0.4066\n",
      "Epoch 13:  Train Loss: 1.0823  Eval Loss: 1.0782   Accuracy: 0.4080\n",
      "Epoch 14:  Train Loss: 1.0815  Eval Loss: 1.0780   Accuracy: 0.4041\n",
      "Epoch 15:  Train Loss: 1.0813  Eval Loss: 1.0784   Accuracy: 0.4025\n",
      "Epoch 16:  Train Loss: 1.0818  Eval Loss: 1.0785   Accuracy: 0.4054\n",
      "Epoch 17:  Train Loss: 1.0817  Eval Loss: 1.0775   Accuracy: 0.4048\n",
      "Epoch 18:  Train Loss: 1.0810  Eval Loss: 1.0762   Accuracy: 0.4098\n",
      "Epoch 19:  Train Loss: 1.0815  Eval Loss: 1.0764   Accuracy: 0.4094\n",
      "Epoch 20:  Train Loss: 1.0816  Eval Loss: 1.0766   Accuracy: 0.4085\n",
      "Epoch 21:  Train Loss: 1.0813  Eval Loss: 1.0754   Accuracy: 0.4094\n",
      "Epoch 22:  Train Loss: 1.0813  Eval Loss: 1.0750   Accuracy: 0.4091\n",
      "Epoch 23:  Train Loss: 1.0818  Eval Loss: 1.0751   Accuracy: 0.4104\n",
      "Epoch 24:  Train Loss: 1.0813  Eval Loss: 1.0749   Accuracy: 0.4125\n",
      "Epoch 25:  Train Loss: 1.0815  Eval Loss: 1.0740   Accuracy: 0.4142\n",
      "Epoch 26:  Train Loss: 1.0817  Eval Loss: 1.0747   Accuracy: 0.4165\n",
      "Epoch 27:  Train Loss: 1.0819  Eval Loss: 1.0742   Accuracy: 0.4131\n",
      "Epoch 28:  Train Loss: 1.0816  Eval Loss: 1.0733   Accuracy: 0.4123\n",
      "Epoch 29:  Train Loss: 1.0812  Eval Loss: 1.0721   Accuracy: 0.4176\n",
      "Epoch 30:  Train Loss: 1.0814  Eval Loss: 1.0726   Accuracy: 0.4128\n",
      "Epoch 31:  Train Loss: 1.0811  Eval Loss: 1.0723   Accuracy: 0.4164\n",
      "Epoch 32:  Train Loss: 1.0811  Eval Loss: 1.0713   Accuracy: 0.4208\n",
      "Epoch 33:  Train Loss: 1.0805  Eval Loss: 1.0707   Accuracy: 0.4225\n",
      "Epoch 34:  Train Loss: 1.0800  Eval Loss: 1.0710   Accuracy: 0.4240\n",
      "Epoch 35:  Train Loss: 1.0796  Eval Loss: 1.0701   Accuracy: 0.4273\n",
      "Epoch 36:  Train Loss: 1.0790  Eval Loss: 1.0691   Accuracy: 0.4197\n",
      "Epoch 37:  Train Loss: 1.0793  Eval Loss: 1.0698   Accuracy: 0.4231\n",
      "Epoch 38:  Train Loss: 1.0795  Eval Loss: 1.0688   Accuracy: 0.4274\n",
      "Epoch 39:  Train Loss: 1.0789  Eval Loss: 1.0682   Accuracy: 0.4251\n",
      "Epoch 40:  Train Loss: 1.0795  Eval Loss: 1.0685   Accuracy: 0.4241\n",
      "Epoch 41:  Train Loss: 1.0791  Eval Loss: 1.0670   Accuracy: 0.4255\n",
      "Epoch 42:  Train Loss: 1.0788  Eval Loss: 1.0682   Accuracy: 0.4231\n",
      "Epoch 43:  Train Loss: 1.0788  Eval Loss: 1.0670   Accuracy: 0.4274\n",
      "Epoch 44:  Train Loss: 1.0796  Eval Loss: 1.0684   Accuracy: 0.4246\n",
      "Epoch 45:  Train Loss: 1.0801  Eval Loss: 1.0685   Accuracy: 0.4226\n",
      "Epoch 46:  Train Loss: 1.0798  Eval Loss: 1.0691   Accuracy: 0.4247\n",
      "Epoch 47:  Train Loss: 1.0801  Eval Loss: 1.0687   Accuracy: 0.4241\n",
      "Epoch 48:  Train Loss: 1.0807  Eval Loss: 1.0682   Accuracy: 0.4257\n",
      "Epoch 49:  Train Loss: 1.0805  Eval Loss: 1.0685   Accuracy: 0.4264\n",
      "Epoch 50:  Train Loss: 1.0807  Eval Loss: 1.0691   Accuracy: 0.4253\n",
      "    Final Results: {'eval_loss': 1.0690789461135863, 'accuracy': 0.42526744778400405, 'best_accuracy': 0.4274070300560367}\n",
      "  Method: single_layer_fine_tuning\n",
      "Epoch 1:  Train Loss: 1.1296  Eval Loss: 1.1127   Accuracy: 0.3628\n",
      "Epoch 2:  Train Loss: 1.1123  Eval Loss: 1.1077   Accuracy: 0.3584\n",
      "Epoch 3:  Train Loss: 1.1071  Eval Loss: 1.1014   Accuracy: 0.3805\n",
      "Epoch 4:  Train Loss: 1.1033  Eval Loss: 1.0977   Accuracy: 0.3851\n",
      "Epoch 5:  Train Loss: 1.0995  Eval Loss: 1.0938   Accuracy: 0.3890\n",
      "Epoch 6:  Train Loss: 1.0972  Eval Loss: 1.0918   Accuracy: 0.3878\n",
      "Epoch 7:  Train Loss: 1.0940  Eval Loss: 1.0864   Accuracy: 0.4005\n",
      "Epoch 8:  Train Loss: 1.0917  Eval Loss: 1.0851   Accuracy: 0.4013\n",
      "Epoch 9:  Train Loss: 1.0912  Eval Loss: 1.0836   Accuracy: 0.4020\n",
      "Epoch 10:  Train Loss: 1.0908  Eval Loss: 1.0838   Accuracy: 0.4053\n",
      "Epoch 11:  Train Loss: 1.0911  Eval Loss: 1.0850   Accuracy: 0.4030\n",
      "Epoch 12:  Train Loss: 1.0904  Eval Loss: 1.0812   Accuracy: 0.4055\n",
      "Epoch 13:  Train Loss: 1.0888  Eval Loss: 1.0812   Accuracy: 0.4057\n",
      "Epoch 14:  Train Loss: 1.0892  Eval Loss: 1.0813   Accuracy: 0.4082\n",
      "Epoch 15:  Train Loss: 1.0886  Eval Loss: 1.0809   Accuracy: 0.4063\n",
      "Epoch 16:  Train Loss: 1.0883  Eval Loss: 1.0798   Accuracy: 0.4094\n",
      "Epoch 17:  Train Loss: 1.0880  Eval Loss: 1.0792   Accuracy: 0.4113\n",
      "Epoch 18:  Train Loss: 1.0877  Eval Loss: 1.0781   Accuracy: 0.4151\n",
      "Epoch 19:  Train Loss: 1.0864  Eval Loss: 1.0776   Accuracy: 0.4143\n",
      "Epoch 20:  Train Loss: 1.0865  Eval Loss: 1.0775   Accuracy: 0.4156\n",
      "Epoch 21:  Train Loss: 1.0861  Eval Loss: 1.0768   Accuracy: 0.4178\n",
      "Epoch 22:  Train Loss: 1.0848  Eval Loss: 1.0770   Accuracy: 0.4168\n",
      "Epoch 23:  Train Loss: 1.0848  Eval Loss: 1.0750   Accuracy: 0.4183\n",
      "Epoch 24:  Train Loss: 1.0849  Eval Loss: 1.0748   Accuracy: 0.4207\n",
      "Epoch 25:  Train Loss: 1.0845  Eval Loss: 1.0758   Accuracy: 0.4197\n",
      "Epoch 26:  Train Loss: 1.0843  Eval Loss: 1.0751   Accuracy: 0.4205\n",
      "Epoch 27:  Train Loss: 1.0850  Eval Loss: 1.0755   Accuracy: 0.4192\n",
      "Epoch 28:  Train Loss: 1.0847  Eval Loss: 1.0747   Accuracy: 0.4224\n",
      "Epoch 29:  Train Loss: 1.0849  Eval Loss: 1.0740   Accuracy: 0.4257\n",
      "Epoch 30:  Train Loss: 1.0848  Eval Loss: 1.0736   Accuracy: 0.4199\n",
      "Epoch 31:  Train Loss: 1.0853  Eval Loss: 1.0748   Accuracy: 0.4259\n",
      "Epoch 33:  Train Loss: 1.0845  Eval Loss: 1.0731   Accuracy: 0.4203\n",
      "Epoch 34:  Train Loss: 1.0850  Eval Loss: 1.0745   Accuracy: 0.4220\n",
      "Epoch 35:  Train Loss: 1.0844  Eval Loss: 1.0735   Accuracy: 0.4222\n",
      "Epoch 36:  Train Loss: 1.0852  Eval Loss: 1.0754   Accuracy: 0.4241\n",
      "Epoch 37:  Train Loss: 1.0854  Eval Loss: 1.0737   Accuracy: 0.4197\n",
      "Epoch 38:  Train Loss: 1.0845  Eval Loss: 1.0740   Accuracy: 0.4241\n",
      "Epoch 39:  Train Loss: 1.0848  Eval Loss: 1.0743   Accuracy: 0.4225\n",
      "Epoch 40:  Train Loss: 1.0853  Eval Loss: 1.0746   Accuracy: 0.4219\n",
      "Epoch 41:  Train Loss: 1.0854  Eval Loss: 1.0737   Accuracy: 0.4203\n",
      "Epoch 42:  Train Loss: 1.0850  Eval Loss: 1.0739   Accuracy: 0.4213\n",
      "Epoch 43:  Train Loss: 1.0843  Eval Loss: 1.0733   Accuracy: 0.4206\n",
      "Epoch 44:  Train Loss: 1.0850  Eval Loss: 1.0731   Accuracy: 0.4220\n",
      "Epoch 45:  Train Loss: 1.0841  Eval Loss: 1.0739   Accuracy: 0.4195\n",
      "Epoch 46:  Train Loss: 1.0842  Eval Loss: 1.0723   Accuracy: 0.4215\n",
      "Epoch 47:  Train Loss: 1.0839  Eval Loss: 1.0721   Accuracy: 0.4227\n",
      "Epoch 48:  Train Loss: 1.0841  Eval Loss: 1.0715   Accuracy: 0.4237\n",
      "Epoch 49:  Train Loss: 1.0839  Eval Loss: 1.0734   Accuracy: 0.4230\n",
      "Epoch 50:  Train Loss: 1.0839  Eval Loss: 1.0708   Accuracy: 0.4264\n",
      "    Final Results: {'eval_loss': 1.0708276510238648, 'accuracy': 0.4263881813550688, 'best_accuracy': 0.4263881813550688}\n",
      "  Method: soft_prompt_lora\n",
      "Epoch 1:  Train Loss: 1.1263  Eval Loss: 1.1181   Accuracy: 0.3545\n",
      "Epoch 2:  Train Loss: 1.1263  Eval Loss: 1.1184   Accuracy: 0.3545\n",
      "Epoch 3:  Train Loss: 1.1265  Eval Loss: 1.1180   Accuracy: 0.3545\n",
      "Epoch 4:  Train Loss: 1.1264  Eval Loss: 1.1183   Accuracy: 0.3545\n",
      "Epoch 5:  Train Loss: 1.1258  Eval Loss: 1.1177   Accuracy: 0.3545\n",
      "Epoch 6:  Train Loss: 1.1258  Eval Loss: 1.1177   Accuracy: 0.3545\n",
      "Epoch 7:  Train Loss: 1.1259  Eval Loss: 1.1181   Accuracy: 0.3545\n",
      "Epoch 8:  Train Loss: 1.1259  Eval Loss: 1.1180   Accuracy: 0.3545\n",
      "Epoch 9:  Train Loss: 1.1259  Eval Loss: 1.1177   Accuracy: 0.3545\n",
      "Epoch 10:  Train Loss: 1.1254  Eval Loss: 1.1172   Accuracy: 0.3545\n",
      "Epoch 11:  Train Loss: 1.1250  Eval Loss: 1.1167   Accuracy: 0.3545\n",
      "Epoch 12:  Train Loss: 1.1247  Eval Loss: 1.1166   Accuracy: 0.3545\n",
      "Epoch 13:  Train Loss: 1.1246  Eval Loss: 1.1166   Accuracy: 0.3545\n",
      "Epoch 14:  Train Loss: 1.1241  Eval Loss: 1.1157   Accuracy: 0.3545\n",
      "Epoch 15:  Train Loss: 1.1235  Eval Loss: 1.1152   Accuracy: 0.3545\n",
      "Epoch 16:  Train Loss: 1.1230  Eval Loss: 1.1146   Accuracy: 0.3545\n",
      "Epoch 17:  Train Loss: 1.1226  Eval Loss: 1.1146   Accuracy: 0.3545\n",
      "Epoch 18:  Train Loss: 1.1221  Eval Loss: 1.1139   Accuracy: 0.3545\n",
      "Epoch 19:  Train Loss: 1.1221  Eval Loss: 1.1137   Accuracy: 0.3545\n",
      "Epoch 20:  Train Loss: 1.1213  Eval Loss: 1.1134   Accuracy: 0.3545\n",
      "Epoch 21:  Train Loss: 1.1204  Eval Loss: 1.1121   Accuracy: 0.3545\n",
      "Epoch 22:  Train Loss: 1.1184  Eval Loss: 1.1097   Accuracy: 0.3545\n",
      "Epoch 23:  Train Loss: 1.1169  Eval Loss: 1.1093   Accuracy: 0.3546\n",
      "Epoch 24:  Train Loss: 1.1160  Eval Loss: 1.1083   Accuracy: 0.3544\n",
      "Epoch 25:  Train Loss: 1.1157  Eval Loss: 1.1084   Accuracy: 0.3544\n",
      "Epoch 26:  Train Loss: 1.1147  Eval Loss: 1.1069   Accuracy: 0.3536\n",
      "Epoch 27:  Train Loss: 1.1134  Eval Loss: 1.1052   Accuracy: 0.3532\n",
      "Epoch 28:  Train Loss: 1.1120  Eval Loss: 1.1046   Accuracy: 0.3523\n",
      "Epoch 29:  Train Loss: 1.1104  Eval Loss: 1.1022   Accuracy: 0.3537\n",
      "Epoch 30:  Train Loss: 1.1085  Eval Loss: 1.1017   Accuracy: 0.3570\n",
      "Epoch 31:  Train Loss: 1.1087  Eval Loss: 1.1012   Accuracy: 0.3539\n",
      "Epoch 32:  Train Loss: 1.1077  Eval Loss: 1.1008   Accuracy: 0.3537\n",
      "Epoch 33:  Train Loss: 1.1075  Eval Loss: 1.1010   Accuracy: 0.3535\n",
      "Epoch 34:  Train Loss: 1.1079  Eval Loss: 1.1019   Accuracy: 0.3516\n",
      "Epoch 35:  Train Loss: 1.1087  Eval Loss: 1.1017   Accuracy: 0.3517\n",
      "Epoch 36:  Train Loss: 1.1087  Eval Loss: 1.1016   Accuracy: 0.3533\n",
      "Epoch 37:  Train Loss: 1.1083  Eval Loss: 1.1003   Accuracy: 0.3519\n",
      "Epoch 38:  Train Loss: 1.1071  Eval Loss: 1.0996   Accuracy: 0.3517\n",
      "Epoch 39:  Train Loss: 1.1060  Eval Loss: 1.0992   Accuracy: 0.3530\n",
      "Epoch 40:  Train Loss: 1.1059  Eval Loss: 1.0994   Accuracy: 0.3488\n",
      "Epoch 41:  Train Loss: 1.1062  Eval Loss: 1.0995   Accuracy: 0.3445\n",
      "Epoch 42:  Train Loss: 1.1053  Eval Loss: 1.0991   Accuracy: 0.3436\n",
      "Epoch 43:  Train Loss: 1.1050  Eval Loss: 1.0986   Accuracy: 0.3450\n",
      "Epoch 44:  Train Loss: 1.1046  Eval Loss: 1.0987   Accuracy: 0.3440\n",
      "Epoch 45:  Train Loss: 1.1045  Eval Loss: 1.0987   Accuracy: 0.3462\n",
      "Epoch 46:  Train Loss: 1.1041  Eval Loss: 1.0984   Accuracy: 0.3455\n",
      "Epoch 47:  Train Loss: 1.1035  Eval Loss: 1.0988   Accuracy: 0.3387\n",
      "Epoch 48:  Train Loss: 1.1033  Eval Loss: 1.0991   Accuracy: 0.3373\n",
      "Epoch 49:  Train Loss: 1.1028  Eval Loss: 1.0993   Accuracy: 0.3349\n",
      "Epoch 50:  Train Loss: 1.1021  Eval Loss: 1.0992   Accuracy: 0.3364\n",
      "    Final Results: {'eval_loss': 1.09920175075531, 'accuracy': 0.33642384105960266, 'best_accuracy': 0.35700458481915437}\n",
      "  Method: prefix_lora\n",
      "Epoch 1:  Train Loss: 1.1108  Eval Loss: 1.1130   Accuracy: 0.3029\n",
      "Epoch 2:  Train Loss: 1.1106  Eval Loss: 1.1132   Accuracy: 0.3032\n",
      "Epoch 3:  Train Loss: 1.1109  Eval Loss: 1.1131   Accuracy: 0.3024\n",
      "Epoch 4:  Train Loss: 1.1106  Eval Loss: 1.1129   Accuracy: 0.3026\n",
      "Epoch 5:  Train Loss: 1.1104  Eval Loss: 1.1127   Accuracy: 0.3024\n",
      "Epoch 6:  Train Loss: 1.1106  Eval Loss: 1.1130   Accuracy: 0.3017\n",
      "Epoch 7:  Train Loss: 1.1105  Eval Loss: 1.1128   Accuracy: 0.3011\n",
      "Epoch 8:  Train Loss: 1.1104  Eval Loss: 1.1130   Accuracy: 0.3024\n",
      "Epoch 9:  Train Loss: 1.1105  Eval Loss: 1.1130   Accuracy: 0.3035\n",
      "Epoch 10:  Train Loss: 1.1102  Eval Loss: 1.1128   Accuracy: 0.3050\n",
      "Epoch 11:  Train Loss: 1.1102  Eval Loss: 1.1129   Accuracy: 0.3040\n",
      "Epoch 12:  Train Loss: 1.1099  Eval Loss: 1.1128   Accuracy: 0.3037\n",
      "Epoch 13:  Train Loss: 1.1099  Eval Loss: 1.1130   Accuracy: 0.3058\n",
      "Epoch 14:  Train Loss: 1.1099  Eval Loss: 1.1128   Accuracy: 0.3046\n",
      "Epoch 15:  Train Loss: 1.1101  Eval Loss: 1.1126   Accuracy: 0.3029\n",
      "Epoch 16:  Train Loss: 1.1096  Eval Loss: 1.1127   Accuracy: 0.3053\n",
      "Epoch 17:  Train Loss: 1.1096  Eval Loss: 1.1129   Accuracy: 0.3077\n",
      "Epoch 18:  Train Loss: 1.1096  Eval Loss: 1.1125   Accuracy: 0.3046\n",
      "Epoch 19:  Train Loss: 1.1095  Eval Loss: 1.1123   Accuracy: 0.3045\n",
      "Epoch 20:  Train Loss: 1.1096  Eval Loss: 1.1123   Accuracy: 0.3029\n",
      "Epoch 21:  Train Loss: 1.1091  Eval Loss: 1.1119   Accuracy: 0.3029\n",
      "Epoch 22:  Train Loss: 1.1092  Eval Loss: 1.1117   Accuracy: 0.3028\n",
      "Epoch 23:  Train Loss: 1.1090  Eval Loss: 1.1117   Accuracy: 0.3019\n",
      "Epoch 24:  Train Loss: 1.1089  Eval Loss: 1.1117   Accuracy: 0.3020\n",
      "Epoch 25:  Train Loss: 1.1085  Eval Loss: 1.1118   Accuracy: 0.3009\n",
      "Epoch 26:  Train Loss: 1.1086  Eval Loss: 1.1118   Accuracy: 0.3011\n",
      "Epoch 27:  Train Loss: 1.1087  Eval Loss: 1.1118   Accuracy: 0.3012\n",
      "Epoch 28:  Train Loss: 1.1085  Eval Loss: 1.1116   Accuracy: 0.3027\n",
      "Epoch 29:  Train Loss: 1.1084  Eval Loss: 1.1119   Accuracy: 0.3051\n",
      "Epoch 30:  Train Loss: 1.1086  Eval Loss: 1.1116   Accuracy: 0.3043\n",
      "Epoch 31:  Train Loss: 1.1085  Eval Loss: 1.1115   Accuracy: 0.3045\n",
      "Epoch 32:  Train Loss: 1.1081  Eval Loss: 1.1116   Accuracy: 0.3078\n",
      "Epoch 33:  Train Loss: 1.1082  Eval Loss: 1.1118   Accuracy: 0.3087\n",
      "Epoch 34:  Train Loss: 1.1082  Eval Loss: 1.1119   Accuracy: 0.3074\n",
      "Epoch 35:  Train Loss: 1.1082  Eval Loss: 1.1120   Accuracy: 0.3081\n",
      "Epoch 36:  Train Loss: 1.1082  Eval Loss: 1.1123   Accuracy: 0.3094\n",
      "Epoch 37:  Train Loss: 1.1084  Eval Loss: 1.1121   Accuracy: 0.3101\n",
      "Epoch 38:  Train Loss: 1.1082  Eval Loss: 1.1118   Accuracy: 0.3084\n",
      "Epoch 39:  Train Loss: 1.1082  Eval Loss: 1.1117   Accuracy: 0.3070\n",
      "Epoch 40:  Train Loss: 1.1083  Eval Loss: 1.1115   Accuracy: 0.3043\n",
      "Epoch 41:  Train Loss: 1.1079  Eval Loss: 1.1112   Accuracy: 0.3028\n",
      "Epoch 42:  Train Loss: 1.1080  Eval Loss: 1.1110   Accuracy: 0.3043\n",
      "Epoch 43:  Train Loss: 1.1078  Eval Loss: 1.1109   Accuracy: 0.3032\n",
      "Epoch 44:  Train Loss: 1.1077  Eval Loss: 1.1111   Accuracy: 0.3046\n",
      "Epoch 45:  Train Loss: 1.1078  Eval Loss: 1.1111   Accuracy: 0.3055\n",
      "Epoch 46:  Train Loss: 1.1078  Eval Loss: 1.1111   Accuracy: 0.3079\n",
      "Epoch 47:  Train Loss: 1.1081  Eval Loss: 1.1113   Accuracy: 0.3076\n",
      "Epoch 48:  Train Loss: 1.1079  Eval Loss: 1.1114   Accuracy: 0.3074\n",
      "Epoch 49:  Train Loss: 1.1080  Eval Loss: 1.1113   Accuracy: 0.3099\n",
      "Epoch 50:  Train Loss: 1.1080  Eval Loss: 1.1113   Accuracy: 0.3103\n",
      "    Final Results: {'eval_loss': 1.1112775564193726, 'accuracy': 0.31034131431482426, 'best_accuracy': 0.31034131431482426}\n",
      "==================================================\n",
      "\n",
      "Results for mnli:\n",
      "  Method: soft_prompt, Accuracy: 0.3440, Loss: 1.0994\n",
      "  Method: prefix, Accuracy: 0.4087, Loss: 1.0806\n",
      "  Method: full_fine_tuning, Accuracy: 0.3641, Loss: 1.0938\n",
      "  Method: lora, Accuracy: 0.4281, Loss: 1.0650\n",
      "  Method: ia3, Accuracy: 0.4253, Loss: 1.0691\n",
      "  Method: single_layer_fine_tuning, Accuracy: 0.4264, Loss: 1.0708\n",
      "  Method: soft_prompt_lora, Accuracy: 0.3364, Loss: 1.0992\n",
      "  Method: prefix_lora, Accuracy: 0.3103, Loss: 1.1113\n",
      "\n",
      "Results have been appended to peft_experiment_results.txt\n"
     ]
    }
   ],
   "source": [
    "results = run_peft_experiments(epsilon=0,dataset=['mnli'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf886c6f-34c2-404f-b4fa-4167a844b848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
