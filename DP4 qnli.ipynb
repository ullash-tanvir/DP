{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be948b88-1b5e-460d-83be-b204abf2912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tislam/.conda/envs/tfgpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tislam/.conda/envs/tfgpu/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer, Trainer, \n",
    "                        TrainingArguments, DataCollatorWithPadding, default_data_collator)\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    PromptTuningConfig,\n",
    "    PrefixTuningConfig,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    TaskType,\n",
    ")\n",
    "from opacus.privacy_engine import GradSampleModule\n",
    "from opacus.optimizers import DPOptimizer\n",
    "from opacus import PrivacyEngine\n",
    "from transformers import DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c3d767-904e-4c99-9087-8c03512ea5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44f61fd-2f3e-401b-aa36-0a00eecdb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "logging.getLogger(\"torch\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86705d8e-5f20-424a-b097-4b4d81416cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the model and tokenizer\n",
    "def setup_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "        print(f\"Using {n_gpu} GPU(s)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        n_gpu = 0\n",
    "        print(\"Using CPU\")\n",
    "    return device, n_gpu\n",
    "\n",
    "def load_model_and_tokenizer(model_name, num_labels):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=num_labels,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to prepare the dataset\n",
    "def prepare_dataset(dataset_name, tokenizer):\n",
    "    # Load the dataset from Hugging Face Datasets\n",
    "    dataset = load_dataset('glue', dataset_name)\n",
    "\n",
    "    # Tokenization function depending on the dataset\n",
    "    def tokenize_function(examples):\n",
    "        if dataset_name.lower() == \"sst2\":\n",
    "            return tokenizer(\n",
    "                examples[\"sentence\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"qqp\":\n",
    "            return tokenizer(\n",
    "                examples[\"question1\"],\n",
    "                examples[\"question2\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"qnli\":\n",
    "            return tokenizer(\n",
    "                examples[\"question\"],\n",
    "                examples[\"sentence\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        elif dataset_name.lower() == \"mnli\":\n",
    "            return tokenizer(\n",
    "                examples[\"premise\"],\n",
    "                examples[\"hypothesis\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Dataset {dataset_name} is not supported.\")\n",
    "\n",
    "    # Determine which columns to remove\n",
    "    columns_to_remove = set(dataset[\"train\"].column_names) - {\"label\"}\n",
    "\n",
    "    # Apply the tokenization to the dataset\n",
    "    tokenized_datasets = dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=list(columns_to_remove)  # Remove all columns except 'label'\n",
    "    )\n",
    "\n",
    "    # Rename 'label' to 'labels'\n",
    "    tokenized_datasets = tokenized_datasets.map(\n",
    "        lambda examples: {\"labels\": examples[\"label\"]},\n",
    "        remove_columns=[\"label\"]\n",
    "    )\n",
    "\n",
    "    # Convert the datasets to PyTorch tensors\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "    return tokenized_datasets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to compute metrics during evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Get the predictions by taking the argmax over logits\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Compute accuracy by comparing predictions and labels\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    # Return the accuracy inside a dictionary\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Function to get the PEFT configuration based on the method\n",
    "def get_peft_config(method):\n",
    "    if method == \"soft_prompt\":\n",
    "        peft_config = PromptTuningConfig(\n",
    "            task_type=TaskType.SEQ_CLS, num_virtual_tokens=20\n",
    "        )\n",
    "    elif method == \"prefix\":\n",
    "        peft_config = PrefixTuningConfig(\n",
    "            task_type=TaskType.SEQ_CLS, num_virtual_tokens=20\n",
    "        )\n",
    "    elif method == \"lora\":\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "        )\n",
    "    elif method == \"ia3\":\n",
    "        peft_config = IA3Config(task_type=TaskType.SEQ_CLS)\n",
    "    elif method == \"soft_prompt_lora\":\n",
    "        # Combine Prompt Tuning and LoRA\n",
    "        peft_config = [\n",
    "            PromptTuningConfig(task_type=TaskType.SEQ_CLS, num_virtual_tokens=20),\n",
    "            LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "            ),\n",
    "        ]\n",
    "    elif method == \"prefix_lora\":\n",
    "        # Combine Prefix Tuning and LoRA\n",
    "        peft_config = [\n",
    "            PrefixTuningConfig(task_type=TaskType.SEQ_CLS, num_virtual_tokens=20),\n",
    "            LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "            ),\n",
    "        ]\n",
    "    else:\n",
    "        peft_config = None\n",
    "    return peft_config\n",
    "\n",
    "def get_validation_dataset(tokenized_datasets):\n",
    "    # Check for common validation set names and return the first that exists\n",
    "    for val_name in [\"validation\", \"validation_matched\", \"validation_mismatched\"]:\n",
    "        if val_name in tokenized_datasets:\n",
    "            return tokenized_datasets[val_name]\n",
    "    raise ValueError(\"No valid validation set found.\")\n",
    "\n",
    "\n",
    "def create_dp_optimizer(model, learning_rate, epsilon, delta, expected_batch_size):\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    \n",
    "    # Wrap the model with GradSampleModule\n",
    "    model = GradSampleModule(model)\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Make optimizer differentially private\n",
    "    dp_optimizer = DPOptimizer(\n",
    "        optimizer=optimizer,\n",
    "        noise_multiplier=1.3,\n",
    "        max_grad_norm=1.0,\n",
    "        expected_batch_size=expected_batch_size\n",
    "    )\n",
    "\n",
    "    return model, dp_optimizer\n",
    "\n",
    "def compute_dp_noise_scale(epsilon, delta, sample_rate, steps):\n",
    "    \"\"\"Compute noise scale for DP-SGD.\"\"\"\n",
    "    return np.sqrt(2 * np.log(1.25 / delta)) / (epsilon * np.sqrt(steps * sample_rate))\n",
    "\n",
    "def add_noise_to_grads(model, noise_scale, max_grad_norm):\n",
    "    \"\"\"Add noise to gradients for Differential Privacy.\"\"\"\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** 0.5\n",
    "\n",
    "    clip_coef = max_grad_norm / (total_norm + 1e-6)\n",
    "    clip_coef = min(clip_coef, 1.0)  # Clamp without using torch.clamp\n",
    "\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            p.grad.data.mul_(clip_coef)\n",
    "            noise = torch.randn_like(p.grad) * noise_scale * max_grad_norm\n",
    "            p.grad.data.add_(noise)\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_results_to_file(results, epsilon):\n",
    "    filename = \"peft_experiment_results.txt\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Read existing content\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            existing_content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        existing_content = \"\"\n",
    "    \n",
    "    # Prepare new content\n",
    "    new_content = f\"\\n\\n--- Experiment Results ({timestamp}) ---\\n\"\n",
    "    new_content += f\"Epsilon: {epsilon}\\n\" if epsilon is not None else \"No Differential Privacy\\n\"\n",
    "    new_content += json.dumps(results, indent=2)\n",
    "    \n",
    "    # Combine existing and new content\n",
    "    updated_content = existing_content + new_content\n",
    "    \n",
    "    # Write updated content back to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(updated_content)\n",
    "    \n",
    "    print(f\"\\nResults have been appended to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe3d190-183c-49b9-8923-6d18d7cb158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_peft_experiments(dataset, epsilon=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model_name = \"prajjwal1/bert-tiny\"\n",
    "    # datasets = [\"sst2\", \"qnli\", \"qqp\", \"mnli\"]\n",
    "    methods = [\n",
    "        \"soft_prompt\",\n",
    "        \"prefix\",\n",
    "        \"full_fine_tuning\",\n",
    "        \"lora\",\n",
    "        \"ia3\",\n",
    "        \"single_layer_fine_tuning\",\n",
    "        \"soft_prompt_lora\",\n",
    "        \"prefix_lora\",\n",
    "    ]\n",
    "    \n",
    "    # Dataset-specific parameters\n",
    "    dataset_params = {\n",
    "        \"sst2\": {\"lambda\": 1e-5, \"noise_multiplier\": 0.92, \"num_labels\": 2},\n",
    "        \"qnli\": {\"lambda\": 1e-5, \"noise_multiplier\": 0.83, \"num_labels\": 2},\n",
    "        \"qqp\": {\"lambda\": 1e-6, \"noise_multiplier\": 0.66, \"num_labels\": 2},\n",
    "        \"mnli\": {\"lambda\": 1e-6, \"noise_multiplier\": 0.65, \"num_labels\": 3},\n",
    "    }\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    for dataset_name in dataset:\n",
    "        print(f\"Processing dataset: {dataset_name}\")\n",
    "        \n",
    "        params = dataset_params[dataset_name]\n",
    "        num_labels = params[\"num_labels\"]\n",
    "        \n",
    "        model, tokenizer = load_model_and_tokenizer(model_name, num_labels)\n",
    "        tokenized_dataset = prepare_dataset(dataset_name, tokenizer)\n",
    "        \n",
    "        results_dict[dataset_name] = {}\n",
    "        \n",
    "        for method in methods:\n",
    "            print(f\"  Method: {method}\")\n",
    "            model, tokenizer = load_model_and_tokenizer(model_name, num_labels)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            if method == \"full_fine_tuning\":\n",
    "                peft_model = model\n",
    "            elif method == \"single_layer_fine_tuning\":\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "                model.classifier = torch.nn.Linear(model.config.hidden_size, num_labels).to(device)\n",
    "                peft_model = model\n",
    "            else:\n",
    "                peft_config = get_peft_config(method)\n",
    "                if isinstance(peft_config, list):\n",
    "                    peft_model = model\n",
    "                    for config in peft_config:\n",
    "                        peft_model = get_peft_model(peft_model, config)\n",
    "                else:\n",
    "                    peft_model = get_peft_model(model, peft_config)\n",
    "            peft_model = peft_model.to(device)\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=f\"./results/{dataset_name}_{method}\",\n",
    "                num_train_epochs=50,\n",
    "                per_device_train_batch_size=1024,\n",
    "                per_device_eval_batch_size=1024,\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                save_strategy=\"epoch\",\n",
    "                logging_dir=f\"./logs/{dataset_name}_{method}\",\n",
    "                logging_steps=100,\n",
    "                learning_rate=5e-4,\n",
    "                load_best_model_at_end=False,\n",
    "                save_total_limit=1,\n",
    "            )\n",
    "            \n",
    "            train_dataloader = torch.utils.data.DataLoader(\n",
    "                tokenized_dataset[\"train\"],\n",
    "                batch_size=training_args.per_device_train_batch_size,\n",
    "                shuffle=True,\n",
    "                collate_fn=default_data_collator,\n",
    "            )\n",
    "            \n",
    "            eval_dataloader = torch.utils.data.DataLoader(\n",
    "                get_validation_dataset(tokenized_dataset),\n",
    "                batch_size=training_args.per_device_eval_batch_size,\n",
    "                collate_fn=default_data_collator,\n",
    "            )\n",
    "            \n",
    "            if epsilon is not None:\n",
    "                results = train_with_dp(\n",
    "                    peft_model=peft_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    eval_dataloader=eval_dataloader,\n",
    "                    device=device,\n",
    "                    epsilon=epsilon,\n",
    "                    delta=params[\"lambda\"],\n",
    "                    noise_multiplier=params[\"noise_multiplier\"],\n",
    "                    epochs=int(training_args.num_train_epochs),\n",
    "                    batch_size=training_args.per_device_train_batch_size,\n",
    "                    max_grad_norm=1.0,\n",
    "                    learning_rate=training_args.learning_rate,\n",
    "                    weight_decay=1e-2\n",
    "                )\n",
    "            else:\n",
    "                # Train without differential privacy\n",
    "                results = train_without_dp(\n",
    "                    peft_model=peft_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    eval_dataloader=eval_dataloader,\n",
    "                    device=device,\n",
    "                    epochs=int(training_args.num_train_epochs),\n",
    "                    learning_rate=training_args.learning_rate,\n",
    "                    weight_decay=1e-2\n",
    "                )\n",
    "            \n",
    "            results_dict[dataset_name][method] = results\n",
    "            print(f\"    Final Results: {results}\")\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"=\"*50)\n",
    "    for dataset_name in dataset:\n",
    "        print(f\"\\nResults for {dataset_name}:\")\n",
    "        for method, result in results_dict[dataset_name].items():\n",
    "            accuracy = result.get(\"accuracy\", \"N/A\")\n",
    "            loss = result.get(\"eval_loss\", \"N/A\")\n",
    "            print(f\"  Method: {method}, Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    # Save results to file\n",
    "    save_results_to_file(results_dict, epsilon)\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "def train_with_dp(peft_model, train_dataloader, eval_dataloader, device, epsilon, delta, noise_multiplier, epochs, batch_size, max_grad_norm, learning_rate, weight_decay):\n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        peft_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = peft_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(peft_model.parameters(), max_grad_norm)\n",
    "            \n",
    "            # Add noise to gradients\n",
    "            for param in peft_model.parameters():\n",
    "                if param.requires_grad and param.grad is not None:\n",
    "                    noise = torch.randn_like(param.grad) * noise_multiplier * max_grad_norm\n",
    "                    param.grad.add_(noise)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_results = evaluate(peft_model, eval_dataloader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:  Train Loss: {avg_train_loss:.4f}  Eval Loss: {eval_results['eval_loss']:.4f}   Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "\n",
    "        \n",
    "        if eval_results['accuracy'] > best_accuracy:\n",
    "            best_accuracy = eval_results['accuracy']\n",
    "            # print(f\"  New best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    return {\"eval_loss\": eval_results['eval_loss'], \"accuracy\": eval_results['accuracy'], \"best_accuracy\": best_accuracy}\n",
    "\n",
    "def train_without_dp(peft_model, train_dataloader, eval_dataloader, device, epochs, learning_rate, weight_decay):\n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        peft_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = peft_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_results = evaluate(peft_model, eval_dataloader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:   Train Loss: {avg_train_loss:.4f}   Eval Loss: {eval_results['eval_loss']:.4f}   Accuracy: {eval_results['accuracy']:.4f} \")\n",
    "\n",
    "        \n",
    "        if eval_results['accuracy'] > best_accuracy:\n",
    "            best_accuracy = eval_results['accuracy']\n",
    "            # print(f\"  New best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    return {\"eval_loss\": eval_results['eval_loss'], \"accuracy\": eval_results['accuracy'], \"best_accuracy\": best_accuracy}\n",
    "\n",
    "def evaluate(model, eval_dataloader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_steps = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            eval_loss += outputs.loss.item()\n",
    "            eval_steps += 1\n",
    "            all_preds.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "    \n",
    "    eval_loss = eval_loss / eval_steps\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    return {\"eval_loss\": eval_loss, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd36835-b0a4-47ee-ac08-150a0b0b62d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing dataset: qnli\n",
      "  Method: soft_prompt\n",
      "Epoch 1:  Train Loss: 0.6950  Eval Loss: 0.6933   Accuracy: 0.5017\n",
      "Epoch 2:  Train Loss: 0.6947  Eval Loss: 0.6931   Accuracy: 0.5078\n",
      "Epoch 3:  Train Loss: 0.6950  Eval Loss: 0.6937   Accuracy: 0.4972\n",
      "Epoch 4:  Train Loss: 0.6945  Eval Loss: 0.6929   Accuracy: 0.5096\n",
      "Epoch 5:  Train Loss: 0.6944  Eval Loss: 0.6931   Accuracy: 0.5017\n",
      "Epoch 6:  Train Loss: 0.6942  Eval Loss: 0.6925   Accuracy: 0.5136\n",
      "Epoch 7:  Train Loss: 0.6940  Eval Loss: 0.6921   Accuracy: 0.5147\n",
      "Epoch 8:  Train Loss: 0.6940  Eval Loss: 0.6919   Accuracy: 0.5157\n",
      "Epoch 9:  Train Loss: 0.6936  Eval Loss: 0.6910   Accuracy: 0.5200\n",
      "Epoch 10:  Train Loss: 0.6928  Eval Loss: 0.6897   Accuracy: 0.5329\n",
      "Epoch 11:  Train Loss: 0.6930  Eval Loss: 0.6894   Accuracy: 0.5332\n",
      "Epoch 12:  Train Loss: 0.6928  Eval Loss: 0.6898   Accuracy: 0.5312\n",
      "Epoch 13:  Train Loss: 0.6931  Eval Loss: 0.6897   Accuracy: 0.5354\n",
      "Epoch 14:  Train Loss: 0.6932  Eval Loss: 0.6902   Accuracy: 0.5283\n",
      "Epoch 15:  Train Loss: 0.6930  Eval Loss: 0.6894   Accuracy: 0.5360\n",
      "Epoch 16:  Train Loss: 0.6932  Eval Loss: 0.6897   Accuracy: 0.5319\n",
      "Epoch 17:  Train Loss: 0.6935  Eval Loss: 0.6891   Accuracy: 0.5299\n",
      "Epoch 18:  Train Loss: 0.6932  Eval Loss: 0.6891   Accuracy: 0.5340\n",
      "Epoch 19:  Train Loss: 0.6926  Eval Loss: 0.6885   Accuracy: 0.5394\n",
      "Epoch 20:  Train Loss: 0.6927  Eval Loss: 0.6877   Accuracy: 0.5426\n",
      "Epoch 21:  Train Loss: 0.6922  Eval Loss: 0.6882   Accuracy: 0.5378\n",
      "Epoch 22:  Train Loss: 0.6927  Eval Loss: 0.6876   Accuracy: 0.5431\n",
      "Epoch 23:  Train Loss: 0.6924  Eval Loss: 0.6870   Accuracy: 0.5444\n",
      "Epoch 24:  Train Loss: 0.6928  Eval Loss: 0.6874   Accuracy: 0.5389\n",
      "Epoch 25:  Train Loss: 0.6919  Eval Loss: 0.6869   Accuracy: 0.5394\n",
      "Epoch 26:  Train Loss: 0.6930  Eval Loss: 0.6882   Accuracy: 0.5371\n",
      "Epoch 27:  Train Loss: 0.6930  Eval Loss: 0.6871   Accuracy: 0.5431\n",
      "Epoch 28:  Train Loss: 0.6921  Eval Loss: 0.6856   Accuracy: 0.5574\n",
      "Epoch 29:  Train Loss: 0.6910  Eval Loss: 0.6856   Accuracy: 0.5583\n",
      "Epoch 30:  Train Loss: 0.6919  Eval Loss: 0.6855   Accuracy: 0.5579\n",
      "Epoch 31:  Train Loss: 0.6917  Eval Loss: 0.6855   Accuracy: 0.5550\n",
      "Epoch 32:  Train Loss: 0.6913  Eval Loss: 0.6844   Accuracy: 0.5603\n",
      "Epoch 33:  Train Loss: 0.6915  Eval Loss: 0.6841   Accuracy: 0.5642\n",
      "Epoch 34:  Train Loss: 0.6913  Eval Loss: 0.6842   Accuracy: 0.5510\n",
      "Epoch 35:  Train Loss: 0.6910  Eval Loss: 0.6840   Accuracy: 0.5653\n",
      "Epoch 36:  Train Loss: 0.6913  Eval Loss: 0.6838   Accuracy: 0.5552\n",
      "Epoch 37:  Train Loss: 0.6913  Eval Loss: 0.6838   Accuracy: 0.5576\n",
      "Epoch 38:  Train Loss: 0.6906  Eval Loss: 0.6837   Accuracy: 0.5552\n",
      "Epoch 39:  Train Loss: 0.6912  Eval Loss: 0.6837   Accuracy: 0.5686\n",
      "Epoch 40:  Train Loss: 0.6909  Eval Loss: 0.6832   Accuracy: 0.5548\n",
      "Epoch 41:  Train Loss: 0.6909  Eval Loss: 0.6829   Accuracy: 0.5643\n",
      "Epoch 42:  Train Loss: 0.6915  Eval Loss: 0.6830   Accuracy: 0.5578\n",
      "Epoch 43:  Train Loss: 0.6919  Eval Loss: 0.6830   Accuracy: 0.5632\n",
      "Epoch 44:  Train Loss: 0.6918  Eval Loss: 0.6829   Accuracy: 0.5605\n",
      "Epoch 45:  Train Loss: 0.6914  Eval Loss: 0.6838   Accuracy: 0.5462\n",
      "Epoch 46:  Train Loss: 0.6917  Eval Loss: 0.6837   Accuracy: 0.5634\n",
      "Epoch 47:  Train Loss: 0.6918  Eval Loss: 0.6842   Accuracy: 0.5643\n",
      "Epoch 48:  Train Loss: 0.6912  Eval Loss: 0.6837   Accuracy: 0.5642\n",
      "Epoch 49:  Train Loss: 0.6908  Eval Loss: 0.6836   Accuracy: 0.5618\n",
      "Epoch 50:  Train Loss: 0.6909  Eval Loss: 0.6832   Accuracy: 0.5616\n",
      "    Final Results: {'eval_loss': 0.6832424998283386, 'accuracy': 0.5615961925681859, 'best_accuracy': 0.5685520776130332}\n",
      "  Method: prefix\n",
      "Epoch 1:  Train Loss: 0.6964  Eval Loss: 0.6830   Accuracy: 0.5832\n",
      "Epoch 2:  Train Loss: 0.6803  Eval Loss: 0.6732   Accuracy: 0.5955\n",
      "Epoch 3:  Train Loss: 0.6729  Eval Loss: 0.6659   Accuracy: 0.6037\n",
      "Epoch 4:  Train Loss: 0.6678  Eval Loss: 0.6618   Accuracy: 0.5973\n",
      "Epoch 5:  Train Loss: 0.6634  Eval Loss: 0.6571   Accuracy: 0.6033\n",
      "Epoch 6:  Train Loss: 0.6579  Eval Loss: 0.6492   Accuracy: 0.6233\n",
      "Epoch 7:  Train Loss: 0.6559  Eval Loss: 0.6488   Accuracy: 0.6231\n",
      "Epoch 8:  Train Loss: 0.6564  Eval Loss: 0.6467   Accuracy: 0.6295\n",
      "Epoch 9:  Train Loss: 0.6564  Eval Loss: 0.6491   Accuracy: 0.6191\n",
      "Epoch 10:  Train Loss: 0.6530  Eval Loss: 0.6429   Accuracy: 0.6308\n",
      "Epoch 11:  Train Loss: 0.6517  Eval Loss: 0.6428   Accuracy: 0.6295\n",
      "Epoch 12:  Train Loss: 0.6513  Eval Loss: 0.6455   Accuracy: 0.6227\n",
      "Epoch 13:  Train Loss: 0.6515  Eval Loss: 0.6409   Accuracy: 0.6302\n",
      "Epoch 14:  Train Loss: 0.6501  Eval Loss: 0.6374   Accuracy: 0.6381\n",
      "Epoch 15:  Train Loss: 0.6491  Eval Loss: 0.6377   Accuracy: 0.6392\n",
      "Epoch 16:  Train Loss: 0.6499  Eval Loss: 0.6412   Accuracy: 0.6304\n",
      "Epoch 17:  Train Loss: 0.6501  Eval Loss: 0.6369   Accuracy: 0.6370\n",
      "Epoch 18:  Train Loss: 0.6487  Eval Loss: 0.6415   Accuracy: 0.6312\n",
      "Epoch 19:  Train Loss: 0.6497  Eval Loss: 0.6400   Accuracy: 0.6332\n",
      "Epoch 20:  Train Loss: 0.6482  Eval Loss: 0.6368   Accuracy: 0.6361\n",
      "Epoch 21:  Train Loss: 0.6493  Eval Loss: 0.6390   Accuracy: 0.6344\n",
      "Epoch 22:  Train Loss: 0.6494  Eval Loss: 0.6420   Accuracy: 0.6301\n",
      "Epoch 23:  Train Loss: 0.6495  Eval Loss: 0.6396   Accuracy: 0.6354\n",
      "Epoch 24:  Train Loss: 0.6485  Eval Loss: 0.6408   Accuracy: 0.6319\n",
      "Epoch 25:  Train Loss: 0.6493  Eval Loss: 0.6425   Accuracy: 0.6297\n",
      "Epoch 26:  Train Loss: 0.6491  Eval Loss: 0.6435   Accuracy: 0.6293\n",
      "Epoch 27:  Train Loss: 0.6493  Eval Loss: 0.6417   Accuracy: 0.6301\n",
      "Epoch 28:  Train Loss: 0.6485  Eval Loss: 0.6396   Accuracy: 0.6319\n",
      "Epoch 29:  Train Loss: 0.6478  Eval Loss: 0.6352   Accuracy: 0.6409\n",
      "Epoch 30:  Train Loss: 0.6485  Eval Loss: 0.6358   Accuracy: 0.6405\n",
      "Epoch 31:  Train Loss: 0.6473  Eval Loss: 0.6395   Accuracy: 0.6350\n",
      "Epoch 32:  Train Loss: 0.6485  Eval Loss: 0.6350   Accuracy: 0.6407\n",
      "Epoch 33:  Train Loss: 0.6481  Eval Loss: 0.6421   Accuracy: 0.6337\n",
      "Epoch 34:  Train Loss: 0.6479  Eval Loss: 0.6436   Accuracy: 0.6299\n",
      "Epoch 35:  Train Loss: 0.6481  Eval Loss: 0.6452   Accuracy: 0.6288\n",
      "Epoch 36:  Train Loss: 0.6485  Eval Loss: 0.6406   Accuracy: 0.6326\n",
      "Epoch 37:  Train Loss: 0.6487  Eval Loss: 0.6407   Accuracy: 0.6326\n",
      "Epoch 38:  Train Loss: 0.6491  Eval Loss: 0.6384   Accuracy: 0.6350\n",
      "Epoch 39:  Train Loss: 0.6484  Eval Loss: 0.6427   Accuracy: 0.6306\n",
      "Epoch 40:  Train Loss: 0.6491  Eval Loss: 0.6404   Accuracy: 0.6297\n",
      "Epoch 41:  Train Loss: 0.6494  Eval Loss: 0.6380   Accuracy: 0.6326\n",
      "Epoch 42:  Train Loss: 0.6490  Eval Loss: 0.6376   Accuracy: 0.6350\n",
      "Epoch 43:  Train Loss: 0.6482  Eval Loss: 0.6325   Accuracy: 0.6436\n",
      "Epoch 44:  Train Loss: 0.6501  Eval Loss: 0.6371   Accuracy: 0.6379\n",
      "Epoch 45:  Train Loss: 0.6488  Eval Loss: 0.6359   Accuracy: 0.6399\n",
      "Epoch 46:  Train Loss: 0.6493  Eval Loss: 0.6348   Accuracy: 0.6416\n",
      "Epoch 47:  Train Loss: 0.6476  Eval Loss: 0.6395   Accuracy: 0.6355\n",
      "Epoch 48:  Train Loss: 0.6492  Eval Loss: 0.6457   Accuracy: 0.6286\n",
      "Epoch 49:  Train Loss: 0.6489  Eval Loss: 0.6391   Accuracy: 0.6381\n",
      "Epoch 50:  Train Loss: 0.6487  Eval Loss: 0.6411   Accuracy: 0.6377\n",
      "    Final Results: {'eval_loss': 0.6410641471544901, 'accuracy': 0.6377448288486179, 'best_accuracy': 0.6436024162548051}\n",
      "  Method: full_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.6801  Eval Loss: 0.6648   Accuracy: 0.6334\n",
      "Epoch 2:  Train Loss: 0.6669  Eval Loss: 0.6578   Accuracy: 0.6297\n",
      "Epoch 3:  Train Loss: 0.6586  Eval Loss: 0.6477   Accuracy: 0.6423\n",
      "Epoch 4:  Train Loss: 0.6489  Eval Loss: 0.6433   Accuracy: 0.6383\n",
      "Epoch 5:  Train Loss: 0.6423  Eval Loss: 0.6303   Accuracy: 0.6526\n",
      "Epoch 6:  Train Loss: 0.6315  Eval Loss: 0.6216   Accuracy: 0.6517\n",
      "Epoch 7:  Train Loss: 0.6252  Eval Loss: 0.6180   Accuracy: 0.6517\n",
      "Epoch 8:  Train Loss: 0.6210  Eval Loss: 0.6145   Accuracy: 0.6562\n",
      "Epoch 9:  Train Loss: 0.6217  Eval Loss: 0.6155   Accuracy: 0.6560\n",
      "Epoch 10:  Train Loss: 0.6183  Eval Loss: 0.6075   Accuracy: 0.6678\n",
      "Epoch 11:  Train Loss: 0.6169  Eval Loss: 0.6047   Accuracy: 0.6690\n",
      "Epoch 12:  Train Loss: 0.6198  Eval Loss: 0.6103   Accuracy: 0.6652\n",
      "Epoch 13:  Train Loss: 0.6186  Eval Loss: 0.6073   Accuracy: 0.6707\n",
      "Epoch 14:  Train Loss: 0.6202  Eval Loss: 0.6134   Accuracy: 0.6647\n",
      "Epoch 15:  Train Loss: 0.6191  Eval Loss: 0.6113   Accuracy: 0.6639\n",
      "Epoch 16:  Train Loss: 0.6198  Eval Loss: 0.6023   Accuracy: 0.6711\n",
      "Epoch 17:  Train Loss: 0.6184  Eval Loss: 0.5968   Accuracy: 0.6778\n",
      "Epoch 18:  Train Loss: 0.6199  Eval Loss: 0.5946   Accuracy: 0.6808\n",
      "Epoch 19:  Train Loss: 0.6210  Eval Loss: 0.5946   Accuracy: 0.6817\n",
      "Epoch 20:  Train Loss: 0.6242  Eval Loss: 0.6024   Accuracy: 0.6703\n",
      "Epoch 21:  Train Loss: 0.6258  Eval Loss: 0.6011   Accuracy: 0.6786\n",
      "Epoch 22:  Train Loss: 0.6270  Eval Loss: 0.6039   Accuracy: 0.6727\n",
      "Epoch 23:  Train Loss: 0.6268  Eval Loss: 0.5956   Accuracy: 0.6831\n",
      "Epoch 24:  Train Loss: 0.6300  Eval Loss: 0.6000   Accuracy: 0.6762\n",
      "Epoch 25:  Train Loss: 0.6285  Eval Loss: 0.5999   Accuracy: 0.6731\n",
      "Epoch 26:  Train Loss: 0.6292  Eval Loss: 0.6030   Accuracy: 0.6716\n",
      "Epoch 27:  Train Loss: 0.6312  Eval Loss: 0.6005   Accuracy: 0.6736\n",
      "Epoch 28:  Train Loss: 0.6314  Eval Loss: 0.5984   Accuracy: 0.6773\n",
      "Epoch 29:  Train Loss: 0.6310  Eval Loss: 0.5944   Accuracy: 0.6868\n",
      "Epoch 30:  Train Loss: 0.6348  Eval Loss: 0.6032   Accuracy: 0.6729\n",
      "Epoch 31:  Train Loss: 0.6372  Eval Loss: 0.6057   Accuracy: 0.6716\n",
      "Epoch 32:  Train Loss: 0.6364  Eval Loss: 0.6005   Accuracy: 0.6815\n",
      "Epoch 33:  Train Loss: 0.6399  Eval Loss: 0.6026   Accuracy: 0.6848\n",
      "Epoch 34:  Train Loss: 0.6406  Eval Loss: 0.6051   Accuracy: 0.6758\n",
      "Epoch 35:  Train Loss: 0.6421  Eval Loss: 0.6107   Accuracy: 0.6703\n",
      "Epoch 36:  Train Loss: 0.6414  Eval Loss: 0.6050   Accuracy: 0.6798\n",
      "Epoch 37:  Train Loss: 0.6440  Eval Loss: 0.6106   Accuracy: 0.6762\n",
      "Epoch 38:  Train Loss: 0.6433  Eval Loss: 0.6070   Accuracy: 0.6778\n",
      "Epoch 39:  Train Loss: 0.6453  Eval Loss: 0.6108   Accuracy: 0.6707\n",
      "Epoch 40:  Train Loss: 0.6443  Eval Loss: 0.6089   Accuracy: 0.6764\n",
      "Epoch 41:  Train Loss: 0.6454  Eval Loss: 0.6082   Accuracy: 0.6745\n",
      "Epoch 42:  Train Loss: 0.6441  Eval Loss: 0.6058   Accuracy: 0.6740\n",
      "Epoch 43:  Train Loss: 0.6454  Eval Loss: 0.6095   Accuracy: 0.6733\n",
      "Epoch 44:  Train Loss: 0.6450  Eval Loss: 0.6135   Accuracy: 0.6626\n",
      "Epoch 45:  Train Loss: 0.6463  Eval Loss: 0.6092   Accuracy: 0.6718\n",
      "Epoch 46:  Train Loss: 0.6465  Eval Loss: 0.6107   Accuracy: 0.6712\n",
      "Epoch 47:  Train Loss: 0.6481  Eval Loss: 0.6116   Accuracy: 0.6727\n",
      "Epoch 48:  Train Loss: 0.6480  Eval Loss: 0.6067   Accuracy: 0.6744\n",
      "Epoch 49:  Train Loss: 0.6473  Eval Loss: 0.6056   Accuracy: 0.6733\n",
      "Epoch 50:  Train Loss: 0.6480  Eval Loss: 0.6076   Accuracy: 0.6758\n",
      "    Final Results: {'eval_loss': 0.6075581908226013, 'accuracy': 0.6758191469888339, 'best_accuracy': 0.6868021233754348}\n",
      "  Method: lora\n",
      "Epoch 1:  Train Loss: 0.7008  Eval Loss: 0.6859   Accuracy: 0.5532\n",
      "Epoch 2:  Train Loss: 0.6769  Eval Loss: 0.6672   Accuracy: 0.6407\n",
      "Epoch 3:  Train Loss: 0.6633  Eval Loss: 0.6541   Accuracy: 0.6440\n",
      "Epoch 4:  Train Loss: 0.6542  Eval Loss: 0.6458   Accuracy: 0.6445\n",
      "Epoch 5:  Train Loss: 0.6460  Eval Loss: 0.6380   Accuracy: 0.6463\n",
      "Epoch 6:  Train Loss: 0.6418  Eval Loss: 0.6366   Accuracy: 0.6454\n",
      "Epoch 7:  Train Loss: 0.6393  Eval Loss: 0.6352   Accuracy: 0.6480\n",
      "Epoch 8:  Train Loss: 0.6386  Eval Loss: 0.6348   Accuracy: 0.6429\n",
      "Epoch 9:  Train Loss: 0.6377  Eval Loss: 0.6320   Accuracy: 0.6443\n",
      "Epoch 10:  Train Loss: 0.6356  Eval Loss: 0.6298   Accuracy: 0.6460\n",
      "Epoch 11:  Train Loss: 0.6347  Eval Loss: 0.6284   Accuracy: 0.6487\n",
      "Epoch 12:  Train Loss: 0.6337  Eval Loss: 0.6271   Accuracy: 0.6528\n",
      "Epoch 13:  Train Loss: 0.6329  Eval Loss: 0.6305   Accuracy: 0.6465\n",
      "Epoch 14:  Train Loss: 0.6334  Eval Loss: 0.6306   Accuracy: 0.6471\n",
      "Epoch 15:  Train Loss: 0.6324  Eval Loss: 0.6230   Accuracy: 0.6548\n",
      "Epoch 16:  Train Loss: 0.6307  Eval Loss: 0.6244   Accuracy: 0.6550\n",
      "Epoch 17:  Train Loss: 0.6322  Eval Loss: 0.6296   Accuracy: 0.6482\n",
      "Epoch 18:  Train Loss: 0.6332  Eval Loss: 0.6263   Accuracy: 0.6528\n",
      "Epoch 19:  Train Loss: 0.6322  Eval Loss: 0.6204   Accuracy: 0.6557\n",
      "Epoch 20:  Train Loss: 0.6316  Eval Loss: 0.6226   Accuracy: 0.6551\n",
      "Epoch 21:  Train Loss: 0.6318  Eval Loss: 0.6244   Accuracy: 0.6546\n",
      "Epoch 22:  Train Loss: 0.6299  Eval Loss: 0.6201   Accuracy: 0.6562\n",
      "Epoch 23:  Train Loss: 0.6290  Eval Loss: 0.6185   Accuracy: 0.6581\n",
      "Epoch 24:  Train Loss: 0.6294  Eval Loss: 0.6213   Accuracy: 0.6550\n",
      "Epoch 25:  Train Loss: 0.6294  Eval Loss: 0.6202   Accuracy: 0.6551\n",
      "Epoch 26:  Train Loss: 0.6285  Eval Loss: 0.6234   Accuracy: 0.6548\n",
      "Epoch 27:  Train Loss: 0.6292  Eval Loss: 0.6235   Accuracy: 0.6546\n",
      "Epoch 28:  Train Loss: 0.6301  Eval Loss: 0.6225   Accuracy: 0.6557\n",
      "Epoch 29:  Train Loss: 0.6280  Eval Loss: 0.6218   Accuracy: 0.6557\n",
      "Epoch 30:  Train Loss: 0.6294  Eval Loss: 0.6289   Accuracy: 0.6511\n",
      "Epoch 31:  Train Loss: 0.6291  Eval Loss: 0.6214   Accuracy: 0.6575\n",
      "Epoch 32:  Train Loss: 0.6297  Eval Loss: 0.6231   Accuracy: 0.6562\n",
      "Epoch 33:  Train Loss: 0.6295  Eval Loss: 0.6200   Accuracy: 0.6603\n",
      "Epoch 34:  Train Loss: 0.6280  Eval Loss: 0.6204   Accuracy: 0.6595\n",
      "Epoch 35:  Train Loss: 0.6281  Eval Loss: 0.6247   Accuracy: 0.6533\n",
      "Epoch 36:  Train Loss: 0.6279  Eval Loss: 0.6166   Accuracy: 0.6604\n",
      "Epoch 37:  Train Loss: 0.6267  Eval Loss: 0.6200   Accuracy: 0.6592\n",
      "Epoch 38:  Train Loss: 0.6271  Eval Loss: 0.6233   Accuracy: 0.6571\n",
      "Epoch 39:  Train Loss: 0.6272  Eval Loss: 0.6161   Accuracy: 0.6617\n",
      "Epoch 40:  Train Loss: 0.6259  Eval Loss: 0.6154   Accuracy: 0.6615\n",
      "Epoch 41:  Train Loss: 0.6261  Eval Loss: 0.6267   Accuracy: 0.6507\n",
      "Epoch 42:  Train Loss: 0.6272  Eval Loss: 0.6171   Accuracy: 0.6593\n",
      "Epoch 43:  Train Loss: 0.6265  Eval Loss: 0.6188   Accuracy: 0.6559\n",
      "Epoch 44:  Train Loss: 0.6259  Eval Loss: 0.6180   Accuracy: 0.6566\n",
      "Epoch 45:  Train Loss: 0.6250  Eval Loss: 0.6151   Accuracy: 0.6599\n",
      "Epoch 46:  Train Loss: 0.6248  Eval Loss: 0.6188   Accuracy: 0.6539\n",
      "Epoch 47:  Train Loss: 0.6251  Eval Loss: 0.6184   Accuracy: 0.6555\n",
      "Epoch 48:  Train Loss: 0.6254  Eval Loss: 0.6219   Accuracy: 0.6526\n",
      "Epoch 49:  Train Loss: 0.6255  Eval Loss: 0.6152   Accuracy: 0.6560\n",
      "Epoch 50:  Train Loss: 0.6259  Eval Loss: 0.6199   Accuracy: 0.6540\n",
      "    Final Results: {'eval_loss': 0.619872530301412, 'accuracy': 0.6540362438220758, 'best_accuracy': 0.6617243272926964}\n",
      "  Method: ia3\n",
      "Epoch 1:  Train Loss: 0.6824  Eval Loss: 0.6751   Accuracy: 0.5808\n",
      "Epoch 2:  Train Loss: 0.6658  Eval Loss: 0.6576   Accuracy: 0.6312\n",
      "Epoch 3:  Train Loss: 0.6552  Eval Loss: 0.6518   Accuracy: 0.6229\n",
      "Epoch 4:  Train Loss: 0.6477  Eval Loss: 0.6391   Accuracy: 0.6463\n",
      "Epoch 5:  Train Loss: 0.6424  Eval Loss: 0.6350   Accuracy: 0.6449\n",
      "Epoch 6:  Train Loss: 0.6379  Eval Loss: 0.6340   Accuracy: 0.6390\n",
      "Epoch 7:  Train Loss: 0.6348  Eval Loss: 0.6304   Accuracy: 0.6392\n",
      "Epoch 8:  Train Loss: 0.6327  Eval Loss: 0.6284   Accuracy: 0.6434\n",
      "Epoch 9:  Train Loss: 0.6310  Eval Loss: 0.6249   Accuracy: 0.6498\n",
      "Epoch 10:  Train Loss: 0.6311  Eval Loss: 0.6275   Accuracy: 0.6431\n",
      "Epoch 11:  Train Loss: 0.6291  Eval Loss: 0.6270   Accuracy: 0.6438\n",
      "Epoch 12:  Train Loss: 0.6291  Eval Loss: 0.6237   Accuracy: 0.6473\n",
      "Epoch 13:  Train Loss: 0.6294  Eval Loss: 0.6205   Accuracy: 0.6491\n",
      "Epoch 14:  Train Loss: 0.6286  Eval Loss: 0.6277   Accuracy: 0.6445\n",
      "Epoch 15:  Train Loss: 0.6285  Eval Loss: 0.6240   Accuracy: 0.6469\n",
      "Epoch 16:  Train Loss: 0.6285  Eval Loss: 0.6251   Accuracy: 0.6460\n",
      "Epoch 17:  Train Loss: 0.6279  Eval Loss: 0.6227   Accuracy: 0.6485\n",
      "Epoch 18:  Train Loss: 0.6287  Eval Loss: 0.6243   Accuracy: 0.6480\n",
      "Epoch 19:  Train Loss: 0.6268  Eval Loss: 0.6240   Accuracy: 0.6478\n",
      "Epoch 20:  Train Loss: 0.6295  Eval Loss: 0.6222   Accuracy: 0.6507\n",
      "Epoch 21:  Train Loss: 0.6287  Eval Loss: 0.6193   Accuracy: 0.6559\n",
      "Epoch 22:  Train Loss: 0.6275  Eval Loss: 0.6181   Accuracy: 0.6568\n",
      "Epoch 23:  Train Loss: 0.6282  Eval Loss: 0.6229   Accuracy: 0.6507\n",
      "Epoch 24:  Train Loss: 0.6280  Eval Loss: 0.6190   Accuracy: 0.6551\n",
      "Epoch 25:  Train Loss: 0.6285  Eval Loss: 0.6231   Accuracy: 0.6498\n",
      "Epoch 26:  Train Loss: 0.6286  Eval Loss: 0.6181   Accuracy: 0.6566\n",
      "Epoch 27:  Train Loss: 0.6299  Eval Loss: 0.6171   Accuracy: 0.6573\n",
      "Epoch 28:  Train Loss: 0.6284  Eval Loss: 0.6217   Accuracy: 0.6522\n",
      "Epoch 29:  Train Loss: 0.6288  Eval Loss: 0.6221   Accuracy: 0.6509\n",
      "Epoch 30:  Train Loss: 0.6283  Eval Loss: 0.6222   Accuracy: 0.6502\n",
      "Epoch 31:  Train Loss: 0.6291  Eval Loss: 0.6241   Accuracy: 0.6485\n",
      "Epoch 32:  Train Loss: 0.6284  Eval Loss: 0.6155   Accuracy: 0.6581\n",
      "Epoch 33:  Train Loss: 0.6294  Eval Loss: 0.6203   Accuracy: 0.6522\n",
      "Epoch 34:  Train Loss: 0.6281  Eval Loss: 0.6184   Accuracy: 0.6544\n",
      "Epoch 35:  Train Loss: 0.6282  Eval Loss: 0.6254   Accuracy: 0.6467\n",
      "Epoch 36:  Train Loss: 0.6298  Eval Loss: 0.6213   Accuracy: 0.6517\n",
      "Epoch 37:  Train Loss: 0.6295  Eval Loss: 0.6222   Accuracy: 0.6522\n",
      "Epoch 38:  Train Loss: 0.6285  Eval Loss: 0.6188   Accuracy: 0.6557\n",
      "Epoch 39:  Train Loss: 0.6287  Eval Loss: 0.6189   Accuracy: 0.6533\n",
      "Epoch 40:  Train Loss: 0.6290  Eval Loss: 0.6192   Accuracy: 0.6550\n",
      "Epoch 41:  Train Loss: 0.6272  Eval Loss: 0.6184   Accuracy: 0.6560\n",
      "Epoch 42:  Train Loss: 0.6275  Eval Loss: 0.6175   Accuracy: 0.6571\n",
      "Epoch 43:  Train Loss: 0.6283  Eval Loss: 0.6183   Accuracy: 0.6568\n",
      "Epoch 44:  Train Loss: 0.6277  Eval Loss: 0.6202   Accuracy: 0.6555\n",
      "Epoch 45:  Train Loss: 0.6281  Eval Loss: 0.6251   Accuracy: 0.6491\n",
      "Epoch 46:  Train Loss: 0.6278  Eval Loss: 0.6195   Accuracy: 0.6555\n",
      "Epoch 47:  Train Loss: 0.6287  Eval Loss: 0.6194   Accuracy: 0.6566\n",
      "Epoch 48:  Train Loss: 0.6286  Eval Loss: 0.6172   Accuracy: 0.6582\n",
      "Epoch 49:  Train Loss: 0.6291  Eval Loss: 0.6243   Accuracy: 0.6524\n",
      "Epoch 50:  Train Loss: 0.6290  Eval Loss: 0.6203   Accuracy: 0.6560\n",
      "    Final Results: {'eval_loss': 0.6203002631664276, 'accuracy': 0.6560497894929526, 'best_accuracy': 0.6582463847702728}\n",
      "  Method: single_layer_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.7865  Eval Loss: 0.7484   Accuracy: 0.4428\n",
      "Epoch 2:  Train Loss: 0.7242  Eval Loss: 0.7109   Accuracy: 0.4589\n",
      "Epoch 3:  Train Loss: 0.6996  Eval Loss: 0.6864   Accuracy: 0.5405\n",
      "Epoch 4:  Train Loss: 0.6847  Eval Loss: 0.6749   Accuracy: 0.5812\n",
      "Epoch 5:  Train Loss: 0.6748  Eval Loss: 0.6610   Accuracy: 0.6143\n",
      "Epoch 6:  Train Loss: 0.6652  Eval Loss: 0.6552   Accuracy: 0.6220\n",
      "Epoch 7:  Train Loss: 0.6607  Eval Loss: 0.6528   Accuracy: 0.6231\n",
      "Epoch 8:  Train Loss: 0.6554  Eval Loss: 0.6454   Accuracy: 0.6293\n",
      "Epoch 9:  Train Loss: 0.6529  Eval Loss: 0.6397   Accuracy: 0.6374\n",
      "Epoch 10:  Train Loss: 0.6505  Eval Loss: 0.6409   Accuracy: 0.6317\n",
      "Epoch 11:  Train Loss: 0.6510  Eval Loss: 0.6402   Accuracy: 0.6326\n",
      "Epoch 12:  Train Loss: 0.6487  Eval Loss: 0.6365   Accuracy: 0.6381\n",
      "Epoch 13:  Train Loss: 0.6473  Eval Loss: 0.6332   Accuracy: 0.6462\n",
      "Epoch 14:  Train Loss: 0.6460  Eval Loss: 0.6323   Accuracy: 0.6410\n",
      "Epoch 15:  Train Loss: 0.6449  Eval Loss: 0.6304   Accuracy: 0.6463\n",
      "Epoch 16:  Train Loss: 0.6449  Eval Loss: 0.6304   Accuracy: 0.6445\n",
      "Epoch 17:  Train Loss: 0.6428  Eval Loss: 0.6320   Accuracy: 0.6427\n",
      "Epoch 18:  Train Loss: 0.6426  Eval Loss: 0.6277   Accuracy: 0.6487\n",
      "Epoch 19:  Train Loss: 0.6412  Eval Loss: 0.6300   Accuracy: 0.6474\n",
      "Epoch 20:  Train Loss: 0.6425  Eval Loss: 0.6247   Accuracy: 0.6531\n",
      "Epoch 21:  Train Loss: 0.6406  Eval Loss: 0.6265   Accuracy: 0.6495\n",
      "Epoch 22:  Train Loss: 0.6407  Eval Loss: 0.6227   Accuracy: 0.6546\n",
      "Epoch 23:  Train Loss: 0.6400  Eval Loss: 0.6270   Accuracy: 0.6485\n",
      "Epoch 24:  Train Loss: 0.6399  Eval Loss: 0.6327   Accuracy: 0.6438\n",
      "Epoch 25:  Train Loss: 0.6397  Eval Loss: 0.6258   Accuracy: 0.6504\n",
      "Epoch 26:  Train Loss: 0.6386  Eval Loss: 0.6279   Accuracy: 0.6487\n",
      "Epoch 27:  Train Loss: 0.6394  Eval Loss: 0.6252   Accuracy: 0.6515\n",
      "Epoch 28:  Train Loss: 0.6392  Eval Loss: 0.6278   Accuracy: 0.6485\n",
      "Epoch 29:  Train Loss: 0.6384  Eval Loss: 0.6300   Accuracy: 0.6462\n",
      "Epoch 30:  Train Loss: 0.6375  Eval Loss: 0.6268   Accuracy: 0.6498\n",
      "Epoch 31:  Train Loss: 0.6369  Eval Loss: 0.6259   Accuracy: 0.6511\n",
      "Epoch 32:  Train Loss: 0.6365  Eval Loss: 0.6308   Accuracy: 0.6445\n",
      "Epoch 33:  Train Loss: 0.6347  Eval Loss: 0.6273   Accuracy: 0.6509\n",
      "Epoch 34:  Train Loss: 0.6362  Eval Loss: 0.6225   Accuracy: 0.6546\n",
      "Epoch 35:  Train Loss: 0.6351  Eval Loss: 0.6198   Accuracy: 0.6557\n",
      "Epoch 36:  Train Loss: 0.6347  Eval Loss: 0.6234   Accuracy: 0.6551\n",
      "Epoch 37:  Train Loss: 0.6361  Eval Loss: 0.6218   Accuracy: 0.6560\n",
      "Epoch 38:  Train Loss: 0.6359  Eval Loss: 0.6200   Accuracy: 0.6579\n",
      "Epoch 39:  Train Loss: 0.6362  Eval Loss: 0.6217   Accuracy: 0.6568\n",
      "Epoch 40:  Train Loss: 0.6345  Eval Loss: 0.6190   Accuracy: 0.6566\n",
      "Epoch 41:  Train Loss: 0.6344  Eval Loss: 0.6214   Accuracy: 0.6562\n",
      "Epoch 42:  Train Loss: 0.6359  Eval Loss: 0.6203   Accuracy: 0.6559\n",
      "Epoch 43:  Train Loss: 0.6338  Eval Loss: 0.6242   Accuracy: 0.6520\n",
      "Epoch 44:  Train Loss: 0.6340  Eval Loss: 0.6238   Accuracy: 0.6522\n",
      "Epoch 45:  Train Loss: 0.6344  Eval Loss: 0.6229   Accuracy: 0.6528\n",
      "Epoch 46:  Train Loss: 0.6339  Eval Loss: 0.6232   Accuracy: 0.6520\n",
      "Epoch 47:  Train Loss: 0.6334  Eval Loss: 0.6172   Accuracy: 0.6581\n",
      "Epoch 48:  Train Loss: 0.6346  Eval Loss: 0.6230   Accuracy: 0.6517\n",
      "Epoch 49:  Train Loss: 0.6334  Eval Loss: 0.6202   Accuracy: 0.6535\n",
      "Epoch 50:  Train Loss: 0.6336  Eval Loss: 0.6189   Accuracy: 0.6581\n",
      "    Final Results: {'eval_loss': 0.6188903947671255, 'accuracy': 0.6580633351638294, 'best_accuracy': 0.6580633351638294}\n",
      "  Method: soft_prompt_lora\n",
      "Epoch 1:  Train Loss: 0.7012  Eval Loss: 0.6979   Accuracy: 0.5058\n",
      "Epoch 2:  Train Loss: 0.7015  Eval Loss: 0.6979   Accuracy: 0.5052\n",
      "Epoch 3:  Train Loss: 0.7011  Eval Loss: 0.6980   Accuracy: 0.5054\n",
      "Epoch 4:  Train Loss: 0.7012  Eval Loss: 0.6980   Accuracy: 0.5052\n",
      "Epoch 5:  Train Loss: 0.7011  Eval Loss: 0.6980   Accuracy: 0.5058\n",
      "Epoch 6:  Train Loss: 0.7013  Eval Loss: 0.6983   Accuracy: 0.5059\n",
      "Epoch 7:  Train Loss: 0.7018  Eval Loss: 0.6982   Accuracy: 0.5063\n",
      "Epoch 8:  Train Loss: 0.7013  Eval Loss: 0.6983   Accuracy: 0.5058\n",
      "Epoch 9:  Train Loss: 0.7018  Eval Loss: 0.6982   Accuracy: 0.5063\n",
      "Epoch 10:  Train Loss: 0.7016  Eval Loss: 0.6983   Accuracy: 0.5056\n",
      "Epoch 11:  Train Loss: 0.7018  Eval Loss: 0.6983   Accuracy: 0.5054\n",
      "Epoch 12:  Train Loss: 0.7014  Eval Loss: 0.6984   Accuracy: 0.5050\n",
      "Epoch 13:  Train Loss: 0.7017  Eval Loss: 0.6983   Accuracy: 0.5052\n",
      "Epoch 14:  Train Loss: 0.7015  Eval Loss: 0.6981   Accuracy: 0.5056\n",
      "Epoch 15:  Train Loss: 0.7014  Eval Loss: 0.6982   Accuracy: 0.5054\n",
      "Epoch 16:  Train Loss: 0.7017  Eval Loss: 0.6982   Accuracy: 0.5050\n",
      "Epoch 17:  Train Loss: 0.7016  Eval Loss: 0.6980   Accuracy: 0.5056\n",
      "Epoch 18:  Train Loss: 0.7010  Eval Loss: 0.6979   Accuracy: 0.5059\n",
      "Epoch 19:  Train Loss: 0.7013  Eval Loss: 0.6979   Accuracy: 0.5056\n",
      "Epoch 20:  Train Loss: 0.7011  Eval Loss: 0.6979   Accuracy: 0.5056\n",
      "Epoch 21:  Train Loss: 0.7015  Eval Loss: 0.6983   Accuracy: 0.5052\n",
      "Epoch 22:  Train Loss: 0.7013  Eval Loss: 0.6983   Accuracy: 0.5058\n",
      "Epoch 23:  Train Loss: 0.7013  Eval Loss: 0.6983   Accuracy: 0.5054\n",
      "Epoch 24:  Train Loss: 0.7016  Eval Loss: 0.6982   Accuracy: 0.5052\n",
      "Epoch 25:  Train Loss: 0.7016  Eval Loss: 0.6980   Accuracy: 0.5045\n",
      "Epoch 26:  Train Loss: 0.7010  Eval Loss: 0.6980   Accuracy: 0.5052\n",
      "Epoch 27:  Train Loss: 0.7009  Eval Loss: 0.6978   Accuracy: 0.5052\n",
      "Epoch 28:  Train Loss: 0.7010  Eval Loss: 0.6977   Accuracy: 0.5056\n",
      "Epoch 29:  Train Loss: 0.7005  Eval Loss: 0.6975   Accuracy: 0.5061\n",
      "Epoch 30:  Train Loss: 0.7003  Eval Loss: 0.6973   Accuracy: 0.5069\n",
      "Epoch 31:  Train Loss: 0.7008  Eval Loss: 0.6973   Accuracy: 0.5065\n",
      "Epoch 32:  Train Loss: 0.7004  Eval Loss: 0.6972   Accuracy: 0.5059\n",
      "Epoch 33:  Train Loss: 0.7005  Eval Loss: 0.6971   Accuracy: 0.5065\n",
      "Epoch 34:  Train Loss: 0.7001  Eval Loss: 0.6972   Accuracy: 0.5056\n",
      "Epoch 35:  Train Loss: 0.7005  Eval Loss: 0.6973   Accuracy: 0.5067\n",
      "Epoch 36:  Train Loss: 0.7008  Eval Loss: 0.6973   Accuracy: 0.5063\n",
      "Epoch 37:  Train Loss: 0.7006  Eval Loss: 0.6972   Accuracy: 0.5058\n",
      "Epoch 38:  Train Loss: 0.7002  Eval Loss: 0.6972   Accuracy: 0.5065\n",
      "Epoch 39:  Train Loss: 0.7006  Eval Loss: 0.6973   Accuracy: 0.5058\n",
      "Epoch 40:  Train Loss: 0.7000  Eval Loss: 0.6973   Accuracy: 0.5056\n",
      "Epoch 41:  Train Loss: 0.7002  Eval Loss: 0.6972   Accuracy: 0.5069\n",
      "Epoch 42:  Train Loss: 0.7003  Eval Loss: 0.6972   Accuracy: 0.5067\n",
      "Epoch 43:  Train Loss: 0.7004  Eval Loss: 0.6972   Accuracy: 0.5061\n",
      "Epoch 44:  Train Loss: 0.7000  Eval Loss: 0.6973   Accuracy: 0.5063\n",
      "Epoch 45:  Train Loss: 0.7002  Eval Loss: 0.6975   Accuracy: 0.5065\n",
      "Epoch 46:  Train Loss: 0.7006  Eval Loss: 0.6972   Accuracy: 0.5065\n",
      "Epoch 47:  Train Loss: 0.7001  Eval Loss: 0.6974   Accuracy: 0.5063\n",
      "Epoch 48:  Train Loss: 0.7004  Eval Loss: 0.6973   Accuracy: 0.5069\n",
      "Epoch 49:  Train Loss: 0.7006  Eval Loss: 0.6970   Accuracy: 0.5069\n",
      "Epoch 50:  Train Loss: 0.7004  Eval Loss: 0.6970   Accuracy: 0.5070\n",
      "    Final Results: {'eval_loss': 0.6969544490178426, 'accuracy': 0.5070474098480688, 'best_accuracy': 0.5070474098480688}\n",
      "  Method: prefix_lora\n",
      "Epoch 1:  Train Loss: 0.6800  Eval Loss: 0.6843   Accuracy: 0.5433\n",
      "Epoch 2:  Train Loss: 0.6801  Eval Loss: 0.6841   Accuracy: 0.5444\n",
      "Epoch 3:  Train Loss: 0.6800  Eval Loss: 0.6838   Accuracy: 0.5459\n",
      "Epoch 4:  Train Loss: 0.6793  Eval Loss: 0.6839   Accuracy: 0.5453\n",
      "Epoch 5:  Train Loss: 0.6795  Eval Loss: 0.6835   Accuracy: 0.5470\n",
      "Epoch 6:  Train Loss: 0.6785  Eval Loss: 0.6831   Accuracy: 0.5491\n",
      "Epoch 7:  Train Loss: 0.6794  Eval Loss: 0.6832   Accuracy: 0.5484\n",
      "Epoch 8:  Train Loss: 0.6784  Eval Loss: 0.6828   Accuracy: 0.5499\n",
      "Epoch 9:  Train Loss: 0.6785  Eval Loss: 0.6825   Accuracy: 0.5502\n",
      "Epoch 10:  Train Loss: 0.6780  Eval Loss: 0.6822   Accuracy: 0.5510\n",
      "Epoch 11:  Train Loss: 0.6782  Eval Loss: 0.6812   Accuracy: 0.5546\n",
      "Epoch 12:  Train Loss: 0.6779  Eval Loss: 0.6811   Accuracy: 0.5543\n",
      "Epoch 13:  Train Loss: 0.6776  Eval Loss: 0.6813   Accuracy: 0.5526\n",
      "Epoch 14:  Train Loss: 0.6779  Eval Loss: 0.6806   Accuracy: 0.5552\n",
      "Epoch 15:  Train Loss: 0.6780  Eval Loss: 0.6810   Accuracy: 0.5530\n",
      "Epoch 16:  Train Loss: 0.6774  Eval Loss: 0.6802   Accuracy: 0.5554\n",
      "Epoch 17:  Train Loss: 0.6770  Eval Loss: 0.6797   Accuracy: 0.5578\n",
      "Epoch 18:  Train Loss: 0.6767  Eval Loss: 0.6792   Accuracy: 0.5620\n",
      "Epoch 19:  Train Loss: 0.6760  Eval Loss: 0.6783   Accuracy: 0.5651\n",
      "Epoch 20:  Train Loss: 0.6754  Eval Loss: 0.6782   Accuracy: 0.5651\n",
      "Epoch 21:  Train Loss: 0.6753  Eval Loss: 0.6780   Accuracy: 0.5656\n",
      "Epoch 22:  Train Loss: 0.6753  Eval Loss: 0.6781   Accuracy: 0.5642\n",
      "Epoch 23:  Train Loss: 0.6761  Eval Loss: 0.6775   Accuracy: 0.5665\n",
      "Epoch 24:  Train Loss: 0.6750  Eval Loss: 0.6770   Accuracy: 0.5693\n",
      "Epoch 25:  Train Loss: 0.6742  Eval Loss: 0.6764   Accuracy: 0.5729\n",
      "Epoch 26:  Train Loss: 0.6743  Eval Loss: 0.6762   Accuracy: 0.5744\n",
      "Epoch 27:  Train Loss: 0.6740  Eval Loss: 0.6747   Accuracy: 0.5799\n",
      "Epoch 28:  Train Loss: 0.6737  Eval Loss: 0.6748   Accuracy: 0.5790\n",
      "Epoch 29:  Train Loss: 0.6736  Eval Loss: 0.6750   Accuracy: 0.5781\n",
      "Epoch 30:  Train Loss: 0.6732  Eval Loss: 0.6750   Accuracy: 0.5784\n",
      "Epoch 31:  Train Loss: 0.6735  Eval Loss: 0.6750   Accuracy: 0.5786\n",
      "Epoch 32:  Train Loss: 0.6733  Eval Loss: 0.6748   Accuracy: 0.5795\n",
      "Epoch 33:  Train Loss: 0.6734  Eval Loss: 0.6752   Accuracy: 0.5792\n",
      "Epoch 34:  Train Loss: 0.6738  Eval Loss: 0.6749   Accuracy: 0.5801\n",
      "Epoch 35:  Train Loss: 0.6737  Eval Loss: 0.6751   Accuracy: 0.5797\n",
      "Epoch 36:  Train Loss: 0.6730  Eval Loss: 0.6739   Accuracy: 0.5836\n",
      "Epoch 37:  Train Loss: 0.6729  Eval Loss: 0.6742   Accuracy: 0.5832\n",
      "Epoch 38:  Train Loss: 0.6737  Eval Loss: 0.6747   Accuracy: 0.5812\n",
      "Epoch 39:  Train Loss: 0.6733  Eval Loss: 0.6740   Accuracy: 0.5830\n",
      "Epoch 40:  Train Loss: 0.6734  Eval Loss: 0.6741   Accuracy: 0.5826\n",
      "Epoch 41:  Train Loss: 0.6732  Eval Loss: 0.6746   Accuracy: 0.5803\n",
      "Epoch 42:  Train Loss: 0.6736  Eval Loss: 0.6743   Accuracy: 0.5810\n",
      "Epoch 43:  Train Loss: 0.6739  Eval Loss: 0.6741   Accuracy: 0.5825\n",
      "Epoch 44:  Train Loss: 0.6728  Eval Loss: 0.6737   Accuracy: 0.5836\n",
      "Epoch 45:  Train Loss: 0.6734  Eval Loss: 0.6741   Accuracy: 0.5825\n",
      "Epoch 46:  Train Loss: 0.6730  Eval Loss: 0.6742   Accuracy: 0.5815\n",
      "Epoch 47:  Train Loss: 0.6734  Eval Loss: 0.6735   Accuracy: 0.5836\n",
      "Epoch 48:  Train Loss: 0.6724  Eval Loss: 0.6721   Accuracy: 0.5903\n",
      "Epoch 49:  Train Loss: 0.6723  Eval Loss: 0.6718   Accuracy: 0.5916\n",
      "Epoch 50:  Train Loss: 0.6731  Eval Loss: 0.6714   Accuracy: 0.5922\n",
      "    Final Results: {'eval_loss': 0.6714249054590861, 'accuracy': 0.5921654768442248, 'best_accuracy': 0.5921654768442248}\n",
      "==================================================\n",
      "\n",
      "Results for qnli:\n",
      "  Method: soft_prompt, Accuracy: 0.5616, Loss: 0.6832\n",
      "  Method: prefix, Accuracy: 0.6377, Loss: 0.6411\n",
      "  Method: full_fine_tuning, Accuracy: 0.6758, Loss: 0.6076\n",
      "  Method: lora, Accuracy: 0.6540, Loss: 0.6199\n",
      "  Method: ia3, Accuracy: 0.6560, Loss: 0.6203\n",
      "  Method: single_layer_fine_tuning, Accuracy: 0.6581, Loss: 0.6189\n",
      "  Method: soft_prompt_lora, Accuracy: 0.5070, Loss: 0.6970\n",
      "  Method: prefix_lora, Accuracy: 0.5922, Loss: 0.6714\n",
      "\n",
      "Results have been appended to peft_experiment_results.txt\n"
     ]
    }
   ],
   "source": [
    "results = run_peft_experiments(epsilon=8,dataset=['qnli'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc8af28-f1ab-4c55-912f-4f8775c3b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing dataset: qnli\n",
      "  Method: soft_prompt\n",
      "Epoch 1:  Train Loss: 0.6957  Eval Loss: 0.6940   Accuracy: 0.4981\n",
      "Epoch 2:  Train Loss: 0.6951  Eval Loss: 0.6933   Accuracy: 0.5023\n",
      "Epoch 3:  Train Loss: 0.6947  Eval Loss: 0.6924   Accuracy: 0.5142\n",
      "Epoch 4:  Train Loss: 0.6948  Eval Loss: 0.6924   Accuracy: 0.5173\n",
      "Epoch 5:  Train Loss: 0.6950  Eval Loss: 0.6916   Accuracy: 0.5310\n",
      "Epoch 6:  Train Loss: 0.6952  Eval Loss: 0.6916   Accuracy: 0.5219\n",
      "Epoch 7:  Train Loss: 0.6943  Eval Loss: 0.6903   Accuracy: 0.5310\n",
      "Epoch 8:  Train Loss: 0.6938  Eval Loss: 0.6913   Accuracy: 0.5239\n",
      "Epoch 9:  Train Loss: 0.6943  Eval Loss: 0.6913   Accuracy: 0.5222\n",
      "Epoch 10:  Train Loss: 0.6942  Eval Loss: 0.6912   Accuracy: 0.5191\n",
      "Epoch 11:  Train Loss: 0.6943  Eval Loss: 0.6909   Accuracy: 0.5277\n",
      "Epoch 12:  Train Loss: 0.6945  Eval Loss: 0.6908   Accuracy: 0.5340\n",
      "Epoch 13:  Train Loss: 0.6945  Eval Loss: 0.6909   Accuracy: 0.5279\n",
      "Epoch 14:  Train Loss: 0.6938  Eval Loss: 0.6905   Accuracy: 0.5288\n",
      "Epoch 15:  Train Loss: 0.6940  Eval Loss: 0.6910   Accuracy: 0.5222\n",
      "Epoch 16:  Train Loss: 0.6944  Eval Loss: 0.6904   Accuracy: 0.5308\n",
      "Epoch 17:  Train Loss: 0.6945  Eval Loss: 0.6901   Accuracy: 0.5257\n",
      "Epoch 18:  Train Loss: 0.6941  Eval Loss: 0.6899   Accuracy: 0.5268\n",
      "Epoch 19:  Train Loss: 0.6937  Eval Loss: 0.6901   Accuracy: 0.5301\n",
      "Epoch 20:  Train Loss: 0.6945  Eval Loss: 0.6906   Accuracy: 0.5208\n",
      "Epoch 21:  Train Loss: 0.6947  Eval Loss: 0.6907   Accuracy: 0.5193\n",
      "Epoch 22:  Train Loss: 0.6942  Eval Loss: 0.6903   Accuracy: 0.5248\n",
      "Epoch 23:  Train Loss: 0.6941  Eval Loss: 0.6894   Accuracy: 0.5393\n",
      "Epoch 24:  Train Loss: 0.6950  Eval Loss: 0.6894   Accuracy: 0.5277\n",
      "Epoch 25:  Train Loss: 0.6947  Eval Loss: 0.6893   Accuracy: 0.5307\n",
      "Epoch 26:  Train Loss: 0.6941  Eval Loss: 0.6886   Accuracy: 0.5383\n",
      "Epoch 27:  Train Loss: 0.6935  Eval Loss: 0.6888   Accuracy: 0.5420\n",
      "Epoch 28:  Train Loss: 0.6934  Eval Loss: 0.6878   Accuracy: 0.5491\n",
      "Epoch 29:  Train Loss: 0.6928  Eval Loss: 0.6873   Accuracy: 0.5484\n",
      "Epoch 30:  Train Loss: 0.6933  Eval Loss: 0.6871   Accuracy: 0.5475\n",
      "Epoch 31:  Train Loss: 0.6935  Eval Loss: 0.6868   Accuracy: 0.5497\n",
      "Epoch 32:  Train Loss: 0.6928  Eval Loss: 0.6864   Accuracy: 0.5468\n",
      "Epoch 33:  Train Loss: 0.6928  Eval Loss: 0.6854   Accuracy: 0.5546\n",
      "Epoch 34:  Train Loss: 0.6924  Eval Loss: 0.6856   Accuracy: 0.5493\n",
      "Epoch 35:  Train Loss: 0.6927  Eval Loss: 0.6856   Accuracy: 0.5524\n",
      "Epoch 36:  Train Loss: 0.6926  Eval Loss: 0.6855   Accuracy: 0.5513\n",
      "Epoch 37:  Train Loss: 0.6933  Eval Loss: 0.6857   Accuracy: 0.5524\n",
      "Epoch 38:  Train Loss: 0.6935  Eval Loss: 0.6860   Accuracy: 0.5523\n",
      "Epoch 39:  Train Loss: 0.6926  Eval Loss: 0.6856   Accuracy: 0.5578\n",
      "Epoch 40:  Train Loss: 0.6936  Eval Loss: 0.6856   Accuracy: 0.5559\n",
      "Epoch 41:  Train Loss: 0.6937  Eval Loss: 0.6855   Accuracy: 0.5559\n",
      "Epoch 42:  Train Loss: 0.6934  Eval Loss: 0.6857   Accuracy: 0.5524\n",
      "Epoch 43:  Train Loss: 0.6928  Eval Loss: 0.6852   Accuracy: 0.5495\n",
      "Epoch 44:  Train Loss: 0.6926  Eval Loss: 0.6847   Accuracy: 0.5568\n",
      "Epoch 45:  Train Loss: 0.6928  Eval Loss: 0.6849   Accuracy: 0.5519\n",
      "Epoch 46:  Train Loss: 0.6934  Eval Loss: 0.6854   Accuracy: 0.5541\n",
      "Epoch 47:  Train Loss: 0.6943  Eval Loss: 0.6853   Accuracy: 0.5543\n",
      "Epoch 48:  Train Loss: 0.6938  Eval Loss: 0.6853   Accuracy: 0.5510\n",
      "Epoch 49:  Train Loss: 0.6939  Eval Loss: 0.6855   Accuracy: 0.5565\n",
      "Epoch 50:  Train Loss: 0.6939  Eval Loss: 0.6850   Accuracy: 0.5541\n",
      "    Final Results: {'eval_loss': 0.6850443085034689, 'accuracy': 0.5540911587040088, 'best_accuracy': 0.5577521508328757}\n",
      "  Method: prefix\n",
      "Epoch 1:  Train Loss: 0.6994  Eval Loss: 0.6862   Accuracy: 0.5654\n",
      "Epoch 2:  Train Loss: 0.6852  Eval Loss: 0.6715   Accuracy: 0.6237\n",
      "Epoch 3:  Train Loss: 0.6765  Eval Loss: 0.6654   Accuracy: 0.6255\n",
      "Epoch 4:  Train Loss: 0.6700  Eval Loss: 0.6585   Accuracy: 0.6302\n",
      "Epoch 5:  Train Loss: 0.6643  Eval Loss: 0.6500   Accuracy: 0.6343\n",
      "Epoch 6:  Train Loss: 0.6614  Eval Loss: 0.6506   Accuracy: 0.6350\n",
      "Epoch 7:  Train Loss: 0.6597  Eval Loss: 0.6475   Accuracy: 0.6323\n",
      "Epoch 8:  Train Loss: 0.6565  Eval Loss: 0.6464   Accuracy: 0.6237\n",
      "Epoch 9:  Train Loss: 0.6548  Eval Loss: 0.6452   Accuracy: 0.6257\n",
      "Epoch 10:  Train Loss: 0.6539  Eval Loss: 0.6440   Accuracy: 0.6246\n",
      "Epoch 11:  Train Loss: 0.6543  Eval Loss: 0.6452   Accuracy: 0.6226\n",
      "Epoch 12:  Train Loss: 0.6550  Eval Loss: 0.6432   Accuracy: 0.6258\n",
      "Epoch 13:  Train Loss: 0.6544  Eval Loss: 0.6435   Accuracy: 0.6255\n",
      "Epoch 14:  Train Loss: 0.6558  Eval Loss: 0.6434   Accuracy: 0.6238\n",
      "Epoch 15:  Train Loss: 0.6539  Eval Loss: 0.6443   Accuracy: 0.6237\n",
      "Epoch 16:  Train Loss: 0.6541  Eval Loss: 0.6437   Accuracy: 0.6257\n",
      "Epoch 17:  Train Loss: 0.6547  Eval Loss: 0.6397   Accuracy: 0.6315\n",
      "Epoch 18:  Train Loss: 0.6543  Eval Loss: 0.6448   Accuracy: 0.6238\n",
      "Epoch 19:  Train Loss: 0.6561  Eval Loss: 0.6442   Accuracy: 0.6235\n",
      "Epoch 20:  Train Loss: 0.6538  Eval Loss: 0.6432   Accuracy: 0.6257\n",
      "Epoch 21:  Train Loss: 0.6539  Eval Loss: 0.6365   Accuracy: 0.6370\n",
      "Epoch 22:  Train Loss: 0.6532  Eval Loss: 0.6426   Accuracy: 0.6249\n",
      "Epoch 23:  Train Loss: 0.6532  Eval Loss: 0.6465   Accuracy: 0.6194\n",
      "Epoch 24:  Train Loss: 0.6537  Eval Loss: 0.6461   Accuracy: 0.6211\n",
      "Epoch 25:  Train Loss: 0.6541  Eval Loss: 0.6466   Accuracy: 0.6215\n",
      "Epoch 26:  Train Loss: 0.6546  Eval Loss: 0.6449   Accuracy: 0.6204\n",
      "Epoch 27:  Train Loss: 0.6540  Eval Loss: 0.6502   Accuracy: 0.6107\n",
      "Epoch 28:  Train Loss: 0.6534  Eval Loss: 0.6453   Accuracy: 0.6205\n",
      "Epoch 29:  Train Loss: 0.6552  Eval Loss: 0.6405   Accuracy: 0.6275\n",
      "Epoch 30:  Train Loss: 0.6553  Eval Loss: 0.6486   Accuracy: 0.6178\n",
      "Epoch 31:  Train Loss: 0.6534  Eval Loss: 0.6471   Accuracy: 0.6183\n",
      "Epoch 32:  Train Loss: 0.6554  Eval Loss: 0.6463   Accuracy: 0.6215\n",
      "Epoch 33:  Train Loss: 0.6539  Eval Loss: 0.6395   Accuracy: 0.6348\n",
      "Epoch 34:  Train Loss: 0.6543  Eval Loss: 0.6449   Accuracy: 0.6237\n",
      "Epoch 35:  Train Loss: 0.6533  Eval Loss: 0.6424   Accuracy: 0.6288\n",
      "Epoch 36:  Train Loss: 0.6527  Eval Loss: 0.6454   Accuracy: 0.6242\n",
      "Epoch 37:  Train Loss: 0.6534  Eval Loss: 0.6449   Accuracy: 0.6235\n",
      "Epoch 38:  Train Loss: 0.6529  Eval Loss: 0.6410   Accuracy: 0.6315\n",
      "Epoch 39:  Train Loss: 0.6531  Eval Loss: 0.6387   Accuracy: 0.6377\n",
      "Epoch 40:  Train Loss: 0.6537  Eval Loss: 0.6437   Accuracy: 0.6291\n",
      "Epoch 41:  Train Loss: 0.6523  Eval Loss: 0.6375   Accuracy: 0.6376\n",
      "Epoch 42:  Train Loss: 0.6517  Eval Loss: 0.6387   Accuracy: 0.6368\n",
      "Epoch 43:  Train Loss: 0.6520  Eval Loss: 0.6369   Accuracy: 0.6394\n",
      "Epoch 44:  Train Loss: 0.6526  Eval Loss: 0.6394   Accuracy: 0.6337\n",
      "Epoch 45:  Train Loss: 0.6512  Eval Loss: 0.6343   Accuracy: 0.6412\n",
      "Epoch 46:  Train Loss: 0.6523  Eval Loss: 0.6360   Accuracy: 0.6361\n",
      "Epoch 47:  Train Loss: 0.6515  Eval Loss: 0.6377   Accuracy: 0.6366\n",
      "Epoch 48:  Train Loss: 0.6515  Eval Loss: 0.6353   Accuracy: 0.6403\n",
      "Epoch 49:  Train Loss: 0.6518  Eval Loss: 0.6323   Accuracy: 0.6460\n",
      "Epoch 50:  Train Loss: 0.6527  Eval Loss: 0.6390   Accuracy: 0.6363\n",
      "    Final Results: {'eval_loss': 0.6389800210793813, 'accuracy': 0.6362804319970712, 'best_accuracy': 0.6459820611385686}\n",
      "  Method: full_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.6821  Eval Loss: 0.6649   Accuracy: 0.6220\n",
      "Epoch 2:  Train Loss: 0.6634  Eval Loss: 0.6506   Accuracy: 0.6403\n",
      "Epoch 3:  Train Loss: 0.6515  Eval Loss: 0.6398   Accuracy: 0.6480\n",
      "Epoch 4:  Train Loss: 0.6406  Eval Loss: 0.6317   Accuracy: 0.6498\n",
      "Epoch 5:  Train Loss: 0.6333  Eval Loss: 0.6171   Accuracy: 0.6647\n",
      "Epoch 6:  Train Loss: 0.6262  Eval Loss: 0.6156   Accuracy: 0.6601\n",
      "Epoch 7:  Train Loss: 0.6213  Eval Loss: 0.6149   Accuracy: 0.6632\n",
      "Epoch 8:  Train Loss: 0.6186  Eval Loss: 0.6130   Accuracy: 0.6621\n",
      "Epoch 9:  Train Loss: 0.6151  Eval Loss: 0.6139   Accuracy: 0.6588\n",
      "Epoch 10:  Train Loss: 0.6155  Eval Loss: 0.6129   Accuracy: 0.6630\n",
      "Epoch 11:  Train Loss: 0.6159  Eval Loss: 0.6079   Accuracy: 0.6690\n",
      "Epoch 12:  Train Loss: 0.6169  Eval Loss: 0.6089   Accuracy: 0.6639\n",
      "Epoch 13:  Train Loss: 0.6191  Eval Loss: 0.6050   Accuracy: 0.6663\n",
      "Epoch 14:  Train Loss: 0.6178  Eval Loss: 0.5964   Accuracy: 0.6758\n",
      "Epoch 15:  Train Loss: 0.6179  Eval Loss: 0.6065   Accuracy: 0.6636\n",
      "Epoch 16:  Train Loss: 0.6190  Eval Loss: 0.6041   Accuracy: 0.6665\n",
      "Epoch 17:  Train Loss: 0.6220  Eval Loss: 0.6074   Accuracy: 0.6621\n",
      "Epoch 18:  Train Loss: 0.6227  Eval Loss: 0.6047   Accuracy: 0.6659\n",
      "Epoch 19:  Train Loss: 0.6243  Eval Loss: 0.6076   Accuracy: 0.6630\n",
      "Epoch 20:  Train Loss: 0.6241  Eval Loss: 0.6142   Accuracy: 0.6590\n",
      "Epoch 21:  Train Loss: 0.6253  Eval Loss: 0.6113   Accuracy: 0.6643\n",
      "Epoch 22:  Train Loss: 0.6291  Eval Loss: 0.6173   Accuracy: 0.6597\n",
      "Epoch 23:  Train Loss: 0.6315  Eval Loss: 0.6178   Accuracy: 0.6606\n",
      "Epoch 24:  Train Loss: 0.6311  Eval Loss: 0.6182   Accuracy: 0.6566\n",
      "Epoch 25:  Train Loss: 0.6329  Eval Loss: 0.6212   Accuracy: 0.6539\n",
      "Epoch 26:  Train Loss: 0.6317  Eval Loss: 0.6168   Accuracy: 0.6571\n",
      "Epoch 27:  Train Loss: 0.6350  Eval Loss: 0.6167   Accuracy: 0.6595\n",
      "Epoch 28:  Train Loss: 0.6360  Eval Loss: 0.6140   Accuracy: 0.6599\n",
      "Epoch 29:  Train Loss: 0.6337  Eval Loss: 0.6166   Accuracy: 0.6562\n",
      "Epoch 30:  Train Loss: 0.6349  Eval Loss: 0.6128   Accuracy: 0.6665\n",
      "Epoch 31:  Train Loss: 0.6370  Eval Loss: 0.6171   Accuracy: 0.6615\n",
      "Epoch 32:  Train Loss: 0.6379  Eval Loss: 0.6123   Accuracy: 0.6595\n",
      "Epoch 33:  Train Loss: 0.6381  Eval Loss: 0.6137   Accuracy: 0.6579\n",
      "Epoch 34:  Train Loss: 0.6410  Eval Loss: 0.6173   Accuracy: 0.6566\n",
      "Epoch 35:  Train Loss: 0.6440  Eval Loss: 0.6182   Accuracy: 0.6550\n",
      "Epoch 36:  Train Loss: 0.6454  Eval Loss: 0.6236   Accuracy: 0.6504\n",
      "Epoch 37:  Train Loss: 0.6478  Eval Loss: 0.6187   Accuracy: 0.6550\n",
      "Epoch 38:  Train Loss: 0.6484  Eval Loss: 0.6214   Accuracy: 0.6522\n",
      "Epoch 39:  Train Loss: 0.6502  Eval Loss: 0.6202   Accuracy: 0.6551\n",
      "Epoch 40:  Train Loss: 0.6511  Eval Loss: 0.6247   Accuracy: 0.6467\n",
      "Epoch 41:  Train Loss: 0.6499  Eval Loss: 0.6303   Accuracy: 0.6348\n",
      "Epoch 42:  Train Loss: 0.6519  Eval Loss: 0.6216   Accuracy: 0.6535\n",
      "Epoch 43:  Train Loss: 0.6512  Eval Loss: 0.6183   Accuracy: 0.6531\n",
      "Epoch 44:  Train Loss: 0.6522  Eval Loss: 0.6252   Accuracy: 0.6471\n",
      "Epoch 45:  Train Loss: 0.6546  Eval Loss: 0.6259   Accuracy: 0.6539\n",
      "Epoch 46:  Train Loss: 0.6574  Eval Loss: 0.6293   Accuracy: 0.6447\n",
      "Epoch 47:  Train Loss: 0.6585  Eval Loss: 0.6289   Accuracy: 0.6504\n",
      "Epoch 48:  Train Loss: 0.6604  Eval Loss: 0.6316   Accuracy: 0.6416\n",
      "Epoch 49:  Train Loss: 0.6583  Eval Loss: 0.6281   Accuracy: 0.6498\n",
      "Epoch 50:  Train Loss: 0.6601  Eval Loss: 0.6274   Accuracy: 0.6522\n",
      "    Final Results: {'eval_loss': 0.6274055937925974, 'accuracy': 0.6522057477576423, 'best_accuracy': 0.6758191469888339}\n",
      "  Method: lora\n",
      "Epoch 1:  Train Loss: 0.6805  Eval Loss: 0.6708   Accuracy: 0.6011\n",
      "Epoch 2:  Train Loss: 0.6664  Eval Loss: 0.6599   Accuracy: 0.6176\n",
      "Epoch 3:  Train Loss: 0.6566  Eval Loss: 0.6488   Accuracy: 0.6247\n",
      "Epoch 4:  Train Loss: 0.6475  Eval Loss: 0.6387   Accuracy: 0.6355\n",
      "Epoch 5:  Train Loss: 0.6429  Eval Loss: 0.6358   Accuracy: 0.6363\n",
      "Epoch 6:  Train Loss: 0.6395  Eval Loss: 0.6360   Accuracy: 0.6319\n",
      "Epoch 7:  Train Loss: 0.6366  Eval Loss: 0.6297   Accuracy: 0.6385\n",
      "Epoch 8:  Train Loss: 0.6372  Eval Loss: 0.6346   Accuracy: 0.6321\n",
      "Epoch 9:  Train Loss: 0.6375  Eval Loss: 0.6360   Accuracy: 0.6277\n",
      "Epoch 10:  Train Loss: 0.6368  Eval Loss: 0.6397   Accuracy: 0.6237\n",
      "Epoch 11:  Train Loss: 0.6360  Eval Loss: 0.6303   Accuracy: 0.6346\n",
      "Epoch 12:  Train Loss: 0.6343  Eval Loss: 0.6288   Accuracy: 0.6343\n",
      "Epoch 13:  Train Loss: 0.6320  Eval Loss: 0.6324   Accuracy: 0.6334\n",
      "Epoch 14:  Train Loss: 0.6314  Eval Loss: 0.6285   Accuracy: 0.6355\n",
      "Epoch 15:  Train Loss: 0.6310  Eval Loss: 0.6254   Accuracy: 0.6381\n",
      "Epoch 16:  Train Loss: 0.6300  Eval Loss: 0.6259   Accuracy: 0.6359\n",
      "Epoch 17:  Train Loss: 0.6303  Eval Loss: 0.6269   Accuracy: 0.6363\n",
      "Epoch 18:  Train Loss: 0.6298  Eval Loss: 0.6273   Accuracy: 0.6366\n",
      "Epoch 19:  Train Loss: 0.6311  Eval Loss: 0.6264   Accuracy: 0.6372\n",
      "Epoch 20:  Train Loss: 0.6299  Eval Loss: 0.6224   Accuracy: 0.6442\n",
      "Epoch 21:  Train Loss: 0.6293  Eval Loss: 0.6187   Accuracy: 0.6496\n",
      "Epoch 22:  Train Loss: 0.6283  Eval Loss: 0.6217   Accuracy: 0.6449\n",
      "Epoch 23:  Train Loss: 0.6285  Eval Loss: 0.6231   Accuracy: 0.6456\n",
      "Epoch 24:  Train Loss: 0.6275  Eval Loss: 0.6209   Accuracy: 0.6495\n",
      "Epoch 25:  Train Loss: 0.6274  Eval Loss: 0.6220   Accuracy: 0.6467\n",
      "Epoch 26:  Train Loss: 0.6261  Eval Loss: 0.6170   Accuracy: 0.6546\n",
      "Epoch 27:  Train Loss: 0.6280  Eval Loss: 0.6158   Accuracy: 0.6564\n",
      "Epoch 28:  Train Loss: 0.6266  Eval Loss: 0.6192   Accuracy: 0.6507\n",
      "Epoch 29:  Train Loss: 0.6259  Eval Loss: 0.6165   Accuracy: 0.6566\n",
      "Epoch 30:  Train Loss: 0.6257  Eval Loss: 0.6208   Accuracy: 0.6480\n",
      "Epoch 31:  Train Loss: 0.6262  Eval Loss: 0.6169   Accuracy: 0.6546\n",
      "Epoch 32:  Train Loss: 0.6253  Eval Loss: 0.6161   Accuracy: 0.6542\n",
      "Epoch 33:  Train Loss: 0.6257  Eval Loss: 0.6167   Accuracy: 0.6557\n",
      "Epoch 34:  Train Loss: 0.6248  Eval Loss: 0.6176   Accuracy: 0.6533\n",
      "Epoch 35:  Train Loss: 0.6239  Eval Loss: 0.6179   Accuracy: 0.6528\n",
      "Epoch 36:  Train Loss: 0.6257  Eval Loss: 0.6165   Accuracy: 0.6535\n",
      "Epoch 37:  Train Loss: 0.6252  Eval Loss: 0.6184   Accuracy: 0.6506\n",
      "Epoch 38:  Train Loss: 0.6226  Eval Loss: 0.6153   Accuracy: 0.6533\n",
      "Epoch 39:  Train Loss: 0.6252  Eval Loss: 0.6155   Accuracy: 0.6531\n",
      "Epoch 40:  Train Loss: 0.6245  Eval Loss: 0.6167   Accuracy: 0.6537\n",
      "Epoch 41:  Train Loss: 0.6243  Eval Loss: 0.6173   Accuracy: 0.6531\n",
      "Epoch 42:  Train Loss: 0.6232  Eval Loss: 0.6160   Accuracy: 0.6553\n",
      "Epoch 43:  Train Loss: 0.6249  Eval Loss: 0.6139   Accuracy: 0.6581\n",
      "Epoch 44:  Train Loss: 0.6237  Eval Loss: 0.6118   Accuracy: 0.6606\n",
      "Epoch 45:  Train Loss: 0.6250  Eval Loss: 0.6126   Accuracy: 0.6584\n",
      "Epoch 46:  Train Loss: 0.6241  Eval Loss: 0.6130   Accuracy: 0.6584\n",
      "Epoch 47:  Train Loss: 0.6232  Eval Loss: 0.6146   Accuracy: 0.6581\n",
      "Epoch 48:  Train Loss: 0.6240  Eval Loss: 0.6219   Accuracy: 0.6520\n",
      "Epoch 49:  Train Loss: 0.6215  Eval Loss: 0.6083   Accuracy: 0.6656\n",
      "Epoch 50:  Train Loss: 0.6241  Eval Loss: 0.6126   Accuracy: 0.6606\n",
      "    Final Results: {'eval_loss': 0.6125987966855367, 'accuracy': 0.6606260296540363, 'best_accuracy': 0.6655683690280065}\n",
      "  Method: ia3\n",
      "Epoch 1:  Train Loss: 0.6773  Eval Loss: 0.6661   Accuracy: 0.6112\n",
      "Epoch 2:  Train Loss: 0.6632  Eval Loss: 0.6541   Accuracy: 0.6377\n",
      "Epoch 3:  Train Loss: 0.6562  Eval Loss: 0.6499   Accuracy: 0.6297\n",
      "Epoch 4:  Train Loss: 0.6503  Eval Loss: 0.6429   Accuracy: 0.6381\n",
      "Epoch 5:  Train Loss: 0.6457  Eval Loss: 0.6434   Accuracy: 0.6260\n",
      "Epoch 6:  Train Loss: 0.6426  Eval Loss: 0.6388   Accuracy: 0.6293\n",
      "Epoch 7:  Train Loss: 0.6388  Eval Loss: 0.6332   Accuracy: 0.6425\n",
      "Epoch 8:  Train Loss: 0.6373  Eval Loss: 0.6317   Accuracy: 0.6405\n",
      "Epoch 9:  Train Loss: 0.6345  Eval Loss: 0.6259   Accuracy: 0.6480\n",
      "Epoch 10:  Train Loss: 0.6340  Eval Loss: 0.6274   Accuracy: 0.6469\n",
      "Epoch 11:  Train Loss: 0.6337  Eval Loss: 0.6263   Accuracy: 0.6474\n",
      "Epoch 12:  Train Loss: 0.6321  Eval Loss: 0.6284   Accuracy: 0.6412\n",
      "Epoch 13:  Train Loss: 0.6307  Eval Loss: 0.6249   Accuracy: 0.6460\n",
      "Epoch 14:  Train Loss: 0.6295  Eval Loss: 0.6201   Accuracy: 0.6529\n",
      "Epoch 15:  Train Loss: 0.6293  Eval Loss: 0.6250   Accuracy: 0.6471\n",
      "Epoch 16:  Train Loss: 0.6300  Eval Loss: 0.6200   Accuracy: 0.6517\n",
      "Epoch 17:  Train Loss: 0.6303  Eval Loss: 0.6223   Accuracy: 0.6487\n",
      "Epoch 18:  Train Loss: 0.6299  Eval Loss: 0.6223   Accuracy: 0.6491\n",
      "Epoch 19:  Train Loss: 0.6302  Eval Loss: 0.6219   Accuracy: 0.6487\n",
      "Epoch 20:  Train Loss: 0.6295  Eval Loss: 0.6210   Accuracy: 0.6500\n",
      "Epoch 21:  Train Loss: 0.6300  Eval Loss: 0.6205   Accuracy: 0.6507\n",
      "Epoch 22:  Train Loss: 0.6293  Eval Loss: 0.6229   Accuracy: 0.6434\n",
      "Epoch 23:  Train Loss: 0.6296  Eval Loss: 0.6239   Accuracy: 0.6414\n",
      "Epoch 24:  Train Loss: 0.6284  Eval Loss: 0.6185   Accuracy: 0.6533\n",
      "Epoch 25:  Train Loss: 0.6290  Eval Loss: 0.6197   Accuracy: 0.6520\n",
      "Epoch 26:  Train Loss: 0.6283  Eval Loss: 0.6198   Accuracy: 0.6528\n",
      "Epoch 27:  Train Loss: 0.6279  Eval Loss: 0.6207   Accuracy: 0.6517\n",
      "Epoch 28:  Train Loss: 0.6279  Eval Loss: 0.6190   Accuracy: 0.6535\n",
      "Epoch 29:  Train Loss: 0.6285  Eval Loss: 0.6196   Accuracy: 0.6517\n",
      "Epoch 30:  Train Loss: 0.6284  Eval Loss: 0.6207   Accuracy: 0.6500\n",
      "Epoch 31:  Train Loss: 0.6281  Eval Loss: 0.6219   Accuracy: 0.6498\n",
      "Epoch 32:  Train Loss: 0.6268  Eval Loss: 0.6214   Accuracy: 0.6507\n",
      "Epoch 33:  Train Loss: 0.6277  Eval Loss: 0.6218   Accuracy: 0.6504\n",
      "Epoch 34:  Train Loss: 0.6278  Eval Loss: 0.6185   Accuracy: 0.6548\n",
      "Epoch 35:  Train Loss: 0.6269  Eval Loss: 0.6198   Accuracy: 0.6533\n",
      "Epoch 36:  Train Loss: 0.6267  Eval Loss: 0.6199   Accuracy: 0.6537\n",
      "Epoch 37:  Train Loss: 0.6266  Eval Loss: 0.6165   Accuracy: 0.6593\n",
      "Epoch 38:  Train Loss: 0.6263  Eval Loss: 0.6180   Accuracy: 0.6542\n",
      "Epoch 39:  Train Loss: 0.6277  Eval Loss: 0.6166   Accuracy: 0.6581\n",
      "Epoch 40:  Train Loss: 0.6268  Eval Loss: 0.6150   Accuracy: 0.6593\n",
      "Epoch 41:  Train Loss: 0.6278  Eval Loss: 0.6165   Accuracy: 0.6564\n",
      "Epoch 42:  Train Loss: 0.6277  Eval Loss: 0.6129   Accuracy: 0.6619\n",
      "Epoch 43:  Train Loss: 0.6254  Eval Loss: 0.6156   Accuracy: 0.6584\n",
      "Epoch 44:  Train Loss: 0.6244  Eval Loss: 0.6189   Accuracy: 0.6522\n",
      "Epoch 45:  Train Loss: 0.6264  Eval Loss: 0.6165   Accuracy: 0.6559\n",
      "Epoch 46:  Train Loss: 0.6264  Eval Loss: 0.6148   Accuracy: 0.6551\n",
      "Epoch 47:  Train Loss: 0.6259  Eval Loss: 0.6193   Accuracy: 0.6517\n",
      "Epoch 48:  Train Loss: 0.6263  Eval Loss: 0.6127   Accuracy: 0.6579\n",
      "Epoch 49:  Train Loss: 0.6258  Eval Loss: 0.6139   Accuracy: 0.6571\n",
      "Epoch 50:  Train Loss: 0.6259  Eval Loss: 0.6147   Accuracy: 0.6571\n",
      "    Final Results: {'eval_loss': 0.6146639982859293, 'accuracy': 0.6571480871316127, 'best_accuracy': 0.6619073768991397}\n",
      "  Method: single_layer_fine_tuning\n",
      "Epoch 1:  Train Loss: 0.7192  Eval Loss: 0.6932   Accuracy: 0.5420\n",
      "Epoch 2:  Train Loss: 0.6952  Eval Loss: 0.6787   Accuracy: 0.5773\n",
      "Epoch 3:  Train Loss: 0.6831  Eval Loss: 0.6641   Accuracy: 0.6127\n",
      "Epoch 4:  Train Loss: 0.6720  Eval Loss: 0.6559   Accuracy: 0.6216\n",
      "Epoch 5:  Train Loss: 0.6611  Eval Loss: 0.6475   Accuracy: 0.6299\n",
      "Epoch 6:  Train Loss: 0.6544  Eval Loss: 0.6390   Accuracy: 0.6429\n",
      "Epoch 7:  Train Loss: 0.6518  Eval Loss: 0.6379   Accuracy: 0.6438\n",
      "Epoch 8:  Train Loss: 0.6493  Eval Loss: 0.6389   Accuracy: 0.6399\n",
      "Epoch 9:  Train Loss: 0.6470  Eval Loss: 0.6386   Accuracy: 0.6387\n",
      "Epoch 10:  Train Loss: 0.6466  Eval Loss: 0.6350   Accuracy: 0.6438\n",
      "Epoch 11:  Train Loss: 0.6439  Eval Loss: 0.6319   Accuracy: 0.6478\n",
      "Epoch 12:  Train Loss: 0.6440  Eval Loss: 0.6304   Accuracy: 0.6496\n",
      "Epoch 13:  Train Loss: 0.6406  Eval Loss: 0.6327   Accuracy: 0.6440\n",
      "Epoch 14:  Train Loss: 0.6395  Eval Loss: 0.6349   Accuracy: 0.6416\n",
      "Epoch 15:  Train Loss: 0.6406  Eval Loss: 0.6370   Accuracy: 0.6377\n",
      "Epoch 16:  Train Loss: 0.6404  Eval Loss: 0.6356   Accuracy: 0.6381\n",
      "Epoch 17:  Train Loss: 0.6396  Eval Loss: 0.6327   Accuracy: 0.6423\n",
      "Epoch 18:  Train Loss: 0.6374  Eval Loss: 0.6311   Accuracy: 0.6440\n",
      "Epoch 19:  Train Loss: 0.6375  Eval Loss: 0.6305   Accuracy: 0.6445\n",
      "Epoch 20:  Train Loss: 0.6374  Eval Loss: 0.6275   Accuracy: 0.6487\n",
      "Epoch 21:  Train Loss: 0.6368  Eval Loss: 0.6268   Accuracy: 0.6507\n",
      "Epoch 22:  Train Loss: 0.6377  Eval Loss: 0.6265   Accuracy: 0.6493\n",
      "Epoch 23:  Train Loss: 0.6362  Eval Loss: 0.6277   Accuracy: 0.6478\n",
      "Epoch 24:  Train Loss: 0.6356  Eval Loss: 0.6285   Accuracy: 0.6482\n",
      "Epoch 25:  Train Loss: 0.6359  Eval Loss: 0.6275   Accuracy: 0.6493\n",
      "Epoch 26:  Train Loss: 0.6363  Eval Loss: 0.6279   Accuracy: 0.6480\n",
      "Epoch 27:  Train Loss: 0.6344  Eval Loss: 0.6273   Accuracy: 0.6478\n",
      "Epoch 28:  Train Loss: 0.6343  Eval Loss: 0.6288   Accuracy: 0.6467\n",
      "Epoch 29:  Train Loss: 0.6343  Eval Loss: 0.6298   Accuracy: 0.6456\n",
      "Epoch 30:  Train Loss: 0.6350  Eval Loss: 0.6252   Accuracy: 0.6506\n",
      "Epoch 31:  Train Loss: 0.6336  Eval Loss: 0.6232   Accuracy: 0.6513\n",
      "Epoch 32:  Train Loss: 0.6319  Eval Loss: 0.6220   Accuracy: 0.6528\n",
      "Epoch 33:  Train Loss: 0.6324  Eval Loss: 0.6253   Accuracy: 0.6491\n",
      "Epoch 34:  Train Loss: 0.6327  Eval Loss: 0.6270   Accuracy: 0.6484\n",
      "Epoch 35:  Train Loss: 0.6326  Eval Loss: 0.6258   Accuracy: 0.6493\n",
      "Epoch 36:  Train Loss: 0.6325  Eval Loss: 0.6233   Accuracy: 0.6518\n",
      "Epoch 37:  Train Loss: 0.6338  Eval Loss: 0.6267   Accuracy: 0.6507\n",
      "Epoch 38:  Train Loss: 0.6317  Eval Loss: 0.6199   Accuracy: 0.6559\n",
      "Epoch 39:  Train Loss: 0.6321  Eval Loss: 0.6232   Accuracy: 0.6531\n",
      "Epoch 40:  Train Loss: 0.6327  Eval Loss: 0.6170   Accuracy: 0.6573\n",
      "Epoch 41:  Train Loss: 0.6316  Eval Loss: 0.6239   Accuracy: 0.6526\n",
      "Epoch 42:  Train Loss: 0.6317  Eval Loss: 0.6217   Accuracy: 0.6537\n",
      "Epoch 43:  Train Loss: 0.6302  Eval Loss: 0.6205   Accuracy: 0.6555\n",
      "Epoch 44:  Train Loss: 0.6325  Eval Loss: 0.6246   Accuracy: 0.6531\n",
      "Epoch 45:  Train Loss: 0.6318  Eval Loss: 0.6255   Accuracy: 0.6511\n",
      "Epoch 46:  Train Loss: 0.6315  Eval Loss: 0.6271   Accuracy: 0.6498\n",
      "Epoch 47:  Train Loss: 0.6311  Eval Loss: 0.6291   Accuracy: 0.6493\n",
      "Epoch 48:  Train Loss: 0.6316  Eval Loss: 0.6266   Accuracy: 0.6489\n",
      "Epoch 49:  Train Loss: 0.6309  Eval Loss: 0.6245   Accuracy: 0.6495\n",
      "Epoch 50:  Train Loss: 0.6315  Eval Loss: 0.6222   Accuracy: 0.6520\n",
      "    Final Results: {'eval_loss': 0.6222140789031982, 'accuracy': 0.652022698151199, 'best_accuracy': 0.657331136738056}\n",
      "  Method: soft_prompt_lora\n",
      "Epoch 1:  Train Loss: 0.6998  Eval Loss: 0.7013   Accuracy: 0.4915\n",
      "Epoch 2:  Train Loss: 0.7002  Eval Loss: 0.7013   Accuracy: 0.4911\n",
      "Epoch 3:  Train Loss: 0.6995  Eval Loss: 0.7013   Accuracy: 0.4909\n",
      "Epoch 4:  Train Loss: 0.6997  Eval Loss: 0.7015   Accuracy: 0.4917\n",
      "Epoch 5:  Train Loss: 0.6997  Eval Loss: 0.7014   Accuracy: 0.4904\n",
      "Epoch 6:  Train Loss: 0.6997  Eval Loss: 0.7015   Accuracy: 0.4908\n",
      "Epoch 7:  Train Loss: 0.6998  Eval Loss: 0.7013   Accuracy: 0.4909\n",
      "Epoch 8:  Train Loss: 0.6995  Eval Loss: 0.7011   Accuracy: 0.4900\n",
      "Epoch 9:  Train Loss: 0.6996  Eval Loss: 0.7011   Accuracy: 0.4906\n",
      "Epoch 10:  Train Loss: 0.6996  Eval Loss: 0.7011   Accuracy: 0.4904\n",
      "Epoch 11:  Train Loss: 0.6997  Eval Loss: 0.7011   Accuracy: 0.4908\n",
      "Epoch 12:  Train Loss: 0.6998  Eval Loss: 0.7011   Accuracy: 0.4904\n",
      "Epoch 13:  Train Loss: 0.6998  Eval Loss: 0.7010   Accuracy: 0.4902\n",
      "Epoch 14:  Train Loss: 0.7001  Eval Loss: 0.7010   Accuracy: 0.4897\n",
      "Epoch 15:  Train Loss: 0.6997  Eval Loss: 0.7009   Accuracy: 0.4900\n",
      "Epoch 16:  Train Loss: 0.6997  Eval Loss: 0.7010   Accuracy: 0.4900\n",
      "Epoch 17:  Train Loss: 0.6997  Eval Loss: 0.7010   Accuracy: 0.4900\n",
      "Epoch 18:  Train Loss: 0.6996  Eval Loss: 0.7010   Accuracy: 0.4902\n",
      "Epoch 19:  Train Loss: 0.6994  Eval Loss: 0.7008   Accuracy: 0.4900\n",
      "Epoch 20:  Train Loss: 0.6993  Eval Loss: 0.7008   Accuracy: 0.4906\n",
      "Epoch 21:  Train Loss: 0.6995  Eval Loss: 0.7008   Accuracy: 0.4900\n",
      "Epoch 22:  Train Loss: 0.6995  Eval Loss: 0.7006   Accuracy: 0.4906\n",
      "Epoch 23:  Train Loss: 0.6993  Eval Loss: 0.7007   Accuracy: 0.4900\n",
      "Epoch 24:  Train Loss: 0.6990  Eval Loss: 0.7004   Accuracy: 0.4898\n",
      "Epoch 25:  Train Loss: 0.6998  Eval Loss: 0.7004   Accuracy: 0.4897\n",
      "Epoch 26:  Train Loss: 0.6991  Eval Loss: 0.7002   Accuracy: 0.4900\n",
      "Epoch 27:  Train Loss: 0.6994  Eval Loss: 0.7003   Accuracy: 0.4895\n",
      "Epoch 28:  Train Loss: 0.6992  Eval Loss: 0.7004   Accuracy: 0.4895\n",
      "Epoch 29:  Train Loss: 0.6992  Eval Loss: 0.7003   Accuracy: 0.4897\n",
      "Epoch 30:  Train Loss: 0.6991  Eval Loss: 0.7002   Accuracy: 0.4893\n",
      "Epoch 31:  Train Loss: 0.6991  Eval Loss: 0.7003   Accuracy: 0.4902\n",
      "Epoch 32:  Train Loss: 0.6991  Eval Loss: 0.7002   Accuracy: 0.4906\n",
      "Epoch 33:  Train Loss: 0.6993  Eval Loss: 0.7002   Accuracy: 0.4902\n",
      "Epoch 34:  Train Loss: 0.6993  Eval Loss: 0.7004   Accuracy: 0.4902\n",
      "Epoch 35:  Train Loss: 0.6992  Eval Loss: 0.7007   Accuracy: 0.4902\n",
      "Epoch 36:  Train Loss: 0.6995  Eval Loss: 0.7008   Accuracy: 0.4913\n",
      "Epoch 37:  Train Loss: 0.6990  Eval Loss: 0.7012   Accuracy: 0.4906\n",
      "Epoch 38:  Train Loss: 0.6995  Eval Loss: 0.7011   Accuracy: 0.4909\n",
      "Epoch 39:  Train Loss: 0.6996  Eval Loss: 0.7010   Accuracy: 0.4917\n",
      "Epoch 40:  Train Loss: 0.6994  Eval Loss: 0.7011   Accuracy: 0.4917\n",
      "Epoch 41:  Train Loss: 0.6997  Eval Loss: 0.7010   Accuracy: 0.4917\n",
      "Epoch 42:  Train Loss: 0.6996  Eval Loss: 0.7008   Accuracy: 0.4906\n",
      "Epoch 43:  Train Loss: 0.6990  Eval Loss: 0.7007   Accuracy: 0.4906\n",
      "Epoch 44:  Train Loss: 0.6990  Eval Loss: 0.7006   Accuracy: 0.4909\n",
      "Epoch 45:  Train Loss: 0.6991  Eval Loss: 0.7007   Accuracy: 0.4908\n",
      "Epoch 46:  Train Loss: 0.6994  Eval Loss: 0.7007   Accuracy: 0.4911\n",
      "Epoch 47:  Train Loss: 0.6996  Eval Loss: 0.7007   Accuracy: 0.4908\n",
      "Epoch 48:  Train Loss: 0.6991  Eval Loss: 0.7007   Accuracy: 0.4906\n",
      "Epoch 49:  Train Loss: 0.6993  Eval Loss: 0.7007   Accuracy: 0.4906\n",
      "Epoch 50:  Train Loss: 0.6993  Eval Loss: 0.7003   Accuracy: 0.4893\n",
      "    Final Results: {'eval_loss': 0.7003275652726492, 'accuracy': 0.48929159802306427, 'best_accuracy': 0.49167124290682773}\n",
      "  Method: prefix_lora\n",
      "Epoch 1:  Train Loss: 0.6953  Eval Loss: 0.6867   Accuracy: 0.5144\n",
      "Epoch 2:  Train Loss: 0.6951  Eval Loss: 0.6865   Accuracy: 0.5155\n",
      "Epoch 3:  Train Loss: 0.6949  Eval Loss: 0.6863   Accuracy: 0.5160\n",
      "Epoch 4:  Train Loss: 0.6952  Eval Loss: 0.6862   Accuracy: 0.5173\n",
      "Epoch 5:  Train Loss: 0.6949  Eval Loss: 0.6861   Accuracy: 0.5175\n",
      "Epoch 6:  Train Loss: 0.6947  Eval Loss: 0.6861   Accuracy: 0.5175\n",
      "Epoch 7:  Train Loss: 0.6948  Eval Loss: 0.6858   Accuracy: 0.5178\n",
      "Epoch 8:  Train Loss: 0.6946  Eval Loss: 0.6856   Accuracy: 0.5178\n",
      "Epoch 9:  Train Loss: 0.6941  Eval Loss: 0.6858   Accuracy: 0.5177\n",
      "Epoch 10:  Train Loss: 0.6945  Eval Loss: 0.6857   Accuracy: 0.5178\n",
      "Epoch 11:  Train Loss: 0.6948  Eval Loss: 0.6856   Accuracy: 0.5180\n",
      "Epoch 12:  Train Loss: 0.6945  Eval Loss: 0.6856   Accuracy: 0.5175\n",
      "Epoch 13:  Train Loss: 0.6947  Eval Loss: 0.6854   Accuracy: 0.5177\n",
      "Epoch 14:  Train Loss: 0.6948  Eval Loss: 0.6855   Accuracy: 0.5171\n",
      "Epoch 15:  Train Loss: 0.6942  Eval Loss: 0.6855   Accuracy: 0.5175\n",
      "Epoch 16:  Train Loss: 0.6943  Eval Loss: 0.6854   Accuracy: 0.5184\n",
      "Epoch 17:  Train Loss: 0.6944  Eval Loss: 0.6855   Accuracy: 0.5182\n",
      "Epoch 18:  Train Loss: 0.6940  Eval Loss: 0.6853   Accuracy: 0.5193\n",
      "Epoch 19:  Train Loss: 0.6940  Eval Loss: 0.6855   Accuracy: 0.5180\n",
      "Epoch 20:  Train Loss: 0.6943  Eval Loss: 0.6856   Accuracy: 0.5178\n",
      "Epoch 21:  Train Loss: 0.6944  Eval Loss: 0.6856   Accuracy: 0.5173\n",
      "Epoch 22:  Train Loss: 0.6943  Eval Loss: 0.6855   Accuracy: 0.5188\n",
      "Epoch 23:  Train Loss: 0.6944  Eval Loss: 0.6856   Accuracy: 0.5182\n",
      "Epoch 24:  Train Loss: 0.6941  Eval Loss: 0.6856   Accuracy: 0.5191\n",
      "Epoch 25:  Train Loss: 0.6943  Eval Loss: 0.6855   Accuracy: 0.5188\n",
      "Epoch 26:  Train Loss: 0.6940  Eval Loss: 0.6851   Accuracy: 0.5199\n",
      "Epoch 27:  Train Loss: 0.6939  Eval Loss: 0.6852   Accuracy: 0.5199\n",
      "Epoch 28:  Train Loss: 0.6938  Eval Loss: 0.6850   Accuracy: 0.5197\n",
      "Epoch 29:  Train Loss: 0.6937  Eval Loss: 0.6849   Accuracy: 0.5213\n",
      "Epoch 30:  Train Loss: 0.6936  Eval Loss: 0.6852   Accuracy: 0.5204\n",
      "Epoch 31:  Train Loss: 0.6938  Eval Loss: 0.6851   Accuracy: 0.5200\n",
      "Epoch 32:  Train Loss: 0.6939  Eval Loss: 0.6848   Accuracy: 0.5211\n",
      "Epoch 33:  Train Loss: 0.6937  Eval Loss: 0.6846   Accuracy: 0.5211\n",
      "Epoch 34:  Train Loss: 0.6931  Eval Loss: 0.6845   Accuracy: 0.5215\n",
      "Epoch 35:  Train Loss: 0.6933  Eval Loss: 0.6843   Accuracy: 0.5215\n",
      "Epoch 36:  Train Loss: 0.6933  Eval Loss: 0.6843   Accuracy: 0.5210\n",
      "Epoch 37:  Train Loss: 0.6936  Eval Loss: 0.6842   Accuracy: 0.5211\n",
      "Epoch 38:  Train Loss: 0.6933  Eval Loss: 0.6844   Accuracy: 0.5200\n",
      "Epoch 39:  Train Loss: 0.6936  Eval Loss: 0.6844   Accuracy: 0.5210\n",
      "Epoch 40:  Train Loss: 0.6937  Eval Loss: 0.6842   Accuracy: 0.5221\n",
      "Epoch 41:  Train Loss: 0.6932  Eval Loss: 0.6843   Accuracy: 0.5217\n",
      "Epoch 42:  Train Loss: 0.6933  Eval Loss: 0.6842   Accuracy: 0.5228\n",
      "Epoch 43:  Train Loss: 0.6928  Eval Loss: 0.6838   Accuracy: 0.5235\n",
      "Epoch 44:  Train Loss: 0.6926  Eval Loss: 0.6837   Accuracy: 0.5235\n",
      "Epoch 45:  Train Loss: 0.6927  Eval Loss: 0.6836   Accuracy: 0.5219\n",
      "Epoch 46:  Train Loss: 0.6927  Eval Loss: 0.6834   Accuracy: 0.5241\n",
      "Epoch 47:  Train Loss: 0.6927  Eval Loss: 0.6829   Accuracy: 0.5241\n",
      "Epoch 48:  Train Loss: 0.6922  Eval Loss: 0.6831   Accuracy: 0.5246\n",
      "Epoch 49:  Train Loss: 0.6924  Eval Loss: 0.6831   Accuracy: 0.5250\n",
      "Epoch 50:  Train Loss: 0.6917  Eval Loss: 0.6828   Accuracy: 0.5263\n",
      "    Final Results: {'eval_loss': 0.682756374279658, 'accuracy': 0.5262676185246201, 'best_accuracy': 0.5262676185246201}\n",
      "==================================================\n",
      "\n",
      "Results for qnli:\n",
      "  Method: soft_prompt, Accuracy: 0.5541, Loss: 0.6850\n",
      "  Method: prefix, Accuracy: 0.6363, Loss: 0.6390\n",
      "  Method: full_fine_tuning, Accuracy: 0.6522, Loss: 0.6274\n",
      "  Method: lora, Accuracy: 0.6606, Loss: 0.6126\n",
      "  Method: ia3, Accuracy: 0.6571, Loss: 0.6147\n",
      "  Method: single_layer_fine_tuning, Accuracy: 0.6520, Loss: 0.6222\n",
      "  Method: soft_prompt_lora, Accuracy: 0.4893, Loss: 0.7003\n",
      "  Method: prefix_lora, Accuracy: 0.5263, Loss: 0.6828\n",
      "\n",
      "Results have been appended to peft_experiment_results.txt\n"
     ]
    }
   ],
   "source": [
    "results = run_peft_experiments(epsilon=0,dataset=['qnli'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf886c6f-34c2-404f-b4fa-4167a844b848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
